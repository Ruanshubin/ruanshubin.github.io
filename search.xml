<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PostgreSQL]]></title>
    <url>%2F2019%2F11%2F02%2FPostgreSQL%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[准备编译环境1234567891011# 检查服务器上是否存在gcc-c++的环境，使用命令：rpm -qa | grep gcc-c++# 若无，则访问镜像网站获取：http://mirrors.aliyun.com/centos/7/os/x86_64/Packages/rpm -Uvh *.rpm --nodeps --force# 查看gcc版本和g++版本，会看到详细的版本信息，安装完成gcc -vg++ -v 编译postgresql源码包，并安装访问 https://www.postgresql.org/ftp/source/，选择对应版本： 点击之后，下载对应的tar.gz源码包，然后将其上传到服务器指定路径。 123456789101112131415161718192021222324252627282930313233343536373839[root@test postgresql]# tar -zvxf postgresql-9.6.9.tar.gz # 进入解压后目录，通过命令 ./configure --help 可以看到配置相关的帮助信息[root@test postgresql]# cd postgresql-9.6.9/[root@test postgresql-9.6.9]# ./configure --help# 其中，--prefix=dir 可以指定安装目录：[root@test software]# mkdir pgsql[root@test postgresql-9.6.9]# ./configure --prefix=/usr/software/pgsql# 此时，会报以下错误：configure: error: readline library not foundIf you have readline already installed, see config.log for details on thefailure. It is possible the compiler isn&apos;t looking in the proper directory.Use --without-readline to disable readline support.# 安装缺少的包即可[root@test outrpm]# rpm -ivh ncurses-devel-5.9-14.20130511.el7_4.x86_64.rpm [root@test outrpm]# rpm -ivh readline-devel-6.2-10.el7.x86_64.rpm [root@test outrpm]# rpm -ivh zlib-1.2.7-18.el7.x86_64.rpm # 安装zlib会与原来的zlib冲突[root@test outrpm]# rpm -ivh zlib-1.2.7-18.el7.x86_64.rpm warning: zlib-1.2.7-18.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEYPreparing... ################################# [100%] file /usr/lib64/libz.so.1.2.7 from install of zlib-1.2.7-18.el7.x86_64 conflicts with file from package zlib-1.2.7-17.el7.x86_64# 添加--force参数强制更新 --nodeps 为不考虑依赖[root@test outrpm]# rpm -ivh zlib-1.2.7-18.el7.x86_64.rpm --force[root@tcd-test outrpm]# rpm -ivh zlib-devel-1.2.7-18.el7.x86_64.rpm # 然后，重新注册即可[root@test postgresql-9.6.9]# ./configure --prefix=/usr/software/pgsql[root@tcd-test postgresql-9.6.9]# make[root@tcd-test postgresql-9.6.9]# make install 相关配置创建用户1234567891011[root@tcd-test ~]# groupadd postgres[root@tcd-test ~]# useradd postgres -g postgres[root@tcd-test ~]# passwd postgres# 在安装目录创建data和log目录[root@tcd-test ~]# cd /usr/software/pgsql/[root@tcd-test pgsql]# mkdir data[root@tcd-test pgsql]# mkdir log# 设定权限[root@tcd-test ~]# chown -R postgres:postgres /usr/software/pgsql/ 环境变量配置12345678vim /etc/profile# 底部添加以下内容：export PGDATA=/usr/software/pgsql/dataexport PG_HOME=/usr/software/pgsqlexport PATH=$PATH:$PG_HOME/binsource /etc/profile 初始化数据库12# 初始化数据库的帮助信息[root@tcd-test pgsql]# initdb --help 由于之前在配置文件中已经设定了环境变量 PGDATA ，因此可以直接使用命令 initdb 来完成数据库初始化操作。 切换为postgres用户,初始化数据库。 注意，如果root用户下执行数据库初始化操作： 1234567[root@tcd-test pgsql]# initdb initdb: cannot be run as rootPlease log in (using, e.g., &quot;su&quot;) as the (unprivileged) user that willown the server process.[root@tcd-test pgsql]# su postgres[postgres@tcd-test pgsql]$ initdb 配置数据库进入*/pgsql/data 目录，使用命令vim pg_hba.conf，配置对数据库的访问控制(设置为可以通过密码访问); 12[postgres@tcd-test pgsql]$ cd /usr/software/pgsql/data[postgres@tcd-test data]$ vim ./pg_hba.conf 1[postgres@tcd-test data]$ vim ./postgresql.conf 关闭防火墙(root用户)123456# 查看防火墙状态systemctl status firewalld# 关闭防火墙systemctl stop firewalld# 设置开机不启动systemctl disable firewalld 配置系统服务(root用户)进入postgresql源码包的解压目录； 执行命令 cp contrib/start-scripts/linux /etc/init.d/postgresql； 然后vim /etc/init.d/postgresql，进行配置修改： 123[root@tcd-test ~]# cd /usr/software/postgresql/postgresql-9.6.9/[root@tcd-test postgresql-9.6.9]# cp contrib/start-scripts/linux /etc/init.d/postgresqlvim /etc/init.d/postgresql 使用命令chmod +x /etc/init.d/postgresql，赋予该文件执行权限; 另外，还可以使用命令chkconfig —add postgresql，设置服务开机自启。 启动启动数据库服务1234[root@tcd-test ~]# service postgresql statuspg_ctl: no server running[root@tcd-test ~]# service postgresql startStarting PostgreSQL: ok 本地连接启动成功后，可以通过postgresql自带的客户端工具psql来进行连接； postgresql用户直接输入psql看到版本信息则说明连接成功。 然后，使用 “\password”，设置密码。 1234567891011121314151617181920[root@tcd-test ~]# su postgres[postgres@tcd-test root]$ psqlcould not change directory to &quot;/root&quot;: Permission deniedpsql (9.6.9)Type &quot;help&quot; for help.postgres=# \passwordEnter new password: Enter it again: postgres=# postgres=# \l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+-------------+-------------+----------------------- postgres | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | template0 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres(3 rows) 远程连接]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>PostgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git私服搭建]]></title>
    <url>%2F2019%2F11%2F01%2Fgit%E7%A7%81%E6%9C%8D%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[系统环境系统： Linux：CentOS 7.2 64位 由于CentOS已经内置了OpenSSH,如果您的系统没有，请自行安装。 查看ssh版本： 1234[root@ruanshubin ~]# ssh -V# 输出以下表示没问题，可以继续。 版本可能不一致，能用即可。OpenSSH_7.4p1, OpenSSL 1.0.2k-fips 26 Jan 2017 避免系统环境和其他的不一致，请核对您系统的版本，其他发行版请对应修改。 安装git建议以下操作都切换到root: 12345678# 请确保您切换到了root账户$ su root$ yum install -y git# 验证是否安装成功$ git --version# 输出如下内容表示成功：git version x.x.x.x 添加git的管理的账户和设置密码设置专门管理git的账号非必须，但是建议这么操作。 123456789101112131415# 添加git账户$ adduser git# 修改git的密码$ passwd git# 然后两次输入git的密码确认后。# 查看git是否安装成功$ cd /home &amp;&amp; ls -al# 如果已经有了git，那么表示成，参考如下：drwxr-xr-x. 5 root root 4096 Apr 4 15:03 .dr-xr-xr-x. 19 root root 4096 Apr 4 15:05 ..drwx------ 10 git git 4096 Apr 4 00:26 git# 默认还给我们分配一个名字叫git的组。 git的权限管理git仓库的权限管理，我们可以手动进行管理和配置，也可以通过其他辅助工具。如果小团队的话，直接通过ssh公钥进行管理即可，如果大点的团队，最好用gitolite 或者 gitosis，两者都差不多，一个是Perl开发，一个是Python开发。 以下我分别介绍手动管理权限和使用gitolite管理的方式，注意两者不兼容，不能混用。 git的手动权限管理经过以上步骤，其实服务器的基本已经配置好，但是需要设置权限和配置远程访问git仓库的方式。我们只介绍ssh的方式，https不做介绍。 配置服务端的ssh访问切换到git账号,并创建ssh的默认目录和校验公钥的配置文件 123456789101112131415# 1.切换到git账号$ su git# 2.进入 git账户的主目录$ cd /home/git# 3.创建.ssh的配置，如果此文件夹已经存在请忽略此步。$ mkdir .ssh# 4. 进入刚创建的.ssh目录并创建authorized_keys文件,此文件存放客户端远程访问的 ssh的公钥。$ cd /home/git/.ssh$ touch authorized_keys# 5. 设置权限，此步骤不能省略，而且权限值也不要改，不然会报错。$ chmod 700 /home/git/.ssh/$ chmod 600 /home/git/.ssh/authorized_keys 此时，服务端的配置基本完成。接下需要把客户端的公钥拷贝到authorized_keys文件中。 配置客户端的ssh私钥并上传服务器以下是客户端创建ssh私钥和拷贝的过程，如果您有私钥越过创建私钥的过程。 请用您的客户端进入终端（如果只有一台电脑，可以用不同的账号模拟不同客户端） 第一步： 创建客户端的ssh私钥和公钥 检查是否已经拥有ssh公钥和私钥：进入用户的主目录。 用户主目录：Windows系统：C:\Users\用户名Linux系统：/home/用户名Mac系统：/Users/用户名 然后查看是否有.ssh文件夹，此文件夹下是否有如下几个文件。 1234# 用户主目录的.ssh文件夹下.ssh├── id_rsa└── id_rsa.pub # 我们要用的私钥 如果没有，那么用ssh-keygen创建ssh的私钥。 123$ ssh-keygen -t rsa# 接下来，三个回车默认即可。 创建私钥成功后，在查看用户目录是否有意加有了公钥文件id_rsa.pub 第二步： 拷贝私钥到git的服务器 如何把客户端的文件拷贝到服务器端，我建议用scp命令进行拷贝。 以下以mac系统为例： 1234567# 首先进入我的用户主目录的.ssh目录下，注意用户名xxx替换成自己的$ cd /Users/xxx/.ssh# 以下命令是：把本地的id_rsa.pub文件拷贝到 aicoder.com服务器，登录aicoder.com服务的账号是git。# 冒号后面默认就是git账号的主目录，最后文件被保存成laoma.pub# 注意：把域名换成你自己的或者ip，最后的文件名可以自己定，后面还有用。$ scp ./id_rsa.pub git@aicoder.com:.ssh/laoma.pub 服务器端添加客户端的SSH公钥切换到服务器端，把刚才上传的laoma.pub文件的内容添加到 authorized_keys中，就可以允许客户端ssh访问了。 1234567891011121314# 切换到git账户$ su git$ cd /home/git/.ssh$ ls -al# 查看一下.ssh目录是否有authorized_keys和laoma.pub文件# .# |-- authorized_keys# `-- laoma.pub# 如果有，那么进行下面的把laoma.pub文件中的内容添加到authorized_keys中.$ cat laoma.pub &gt;&gt; authorized_keys# &gt;&gt; 是在文件后面追加的意思，主要如果用其他编辑器，每个ssh的pub要单独一行，建议用cat命令方便简单。 到此为止，您配置的客户端应该可以ssh的方式直接用git账号登录服务器。(当然不安全，后面可以控制) 1234# 在客户端用ssh测试连接远程服务器,请将域名aicoder.com换成你的ip地址或者域名$ ssh git@aicoder.com # 第一次连接有警告，输入yes继续即可。如果可以连接上，那么恭喜你的ssh配置已经可以了。 服务器端创建测试git仓库进入服务器的终端。 12345678910111213# 切换到git账号$ su git# 进入git账号的用户主目录。$ cd /home/git# 在用户主目录下创建 test.git仓库的文件夹$ mkdir test.git &amp;&amp; cd test.git# 在test.git目录下初始化git仓库$ git init --bare# 输出如下内容，表示成功Initialized empty Git repository in /home/git/test.git/ git init —bare 是在当前目录创建一个裸仓库，也就是说没有工作区的文件，直接把git仓库隐藏的文件放在当前目录下，此目录仅用于存储仓库的历史版本等数据。 此时，客户端就可以进行clone或者remote add此仓库了。 客户端测试连接git远程仓库客户端，可以新建一个文件夹，初始化一个仓库，然后跟远程服务器上的空仓库建立连接。 1234567891011121314# 以下shell代码，纯手写没有验证，如果有错误请自行纠正。$ mkdir demos &amp;&amp; cd demos$ git init$ touch a.txt$ echo &apos;aicoder.com&apos; &gt;&gt; a.txt$ git add .$ git commit -m &apos;the first commit&apos;# 把当前仓库跟远程仓库添映射$ git remote add origin git@aicoder.com:test.git# 把当前仓库push到远程仓库。$ git push -u origin master 到此为止，我们就可以尽情的享用git私服了，但是！但是！但是！客户端可以直接ssh登录啊，这是bug，也是不安全的隐患，且看下面怎么禁用git账号的shell登录。 修改Git remote add时使用的远程仓库方法一： git remote rm origingit remote add origin git@github.com:Liutos/foobar.git 方法二： git remote set-url origin 把替换成新的url地址。 方法三： 直接修改.git/config文件 禁止客户端shell登录因为前面我们添加了客户端的ssh的公钥到远程服务器，所以客户端可以直接通过shell远程登录服务器，这不安全，也不是我们想要的。且看下面如何禁用shell登录： 第一步：给 /home/git 下面创建git-shell-commands目录，并把目录的拥有者设置为git账户。可以直接用git账号登录服务器终端操作。 12$ su git$ mkdir /home/git/git-shell-commands 此文件夹是git-shell用到的目录，需要我们手动创建，不然报错：fatal: Interactive git shell is not enabled. hint: ~/git-shell-commands should exist and have read and execute access. 第二步：修改/etc/passwd文件，修改: 12345678910111213$ vim /etc/passwd# 可以通过 vim的正则搜索快速定位到这行， 命名模式下 :/git:x# 找到这句, 注意1000可能是别的数字git:x:1000:1000::/home/git:/bin/bash# 改为：git:x:1000:1000::/home/git:/bin/git-shell# 最好不要直接改，可以先复制一行，然后注释掉一行，修改一行，保留原始的，这就是经验！！！# vim快捷键： 命令模式下：yy复制行， p 粘贴 0光标到行首 $到行尾 x删除一个字符 i进入插入模式 # 修改完后退出保存： esc进入命令模式， 输入：:wq! 保存退出。 好了，此时我们就不用担心客户端通过shell登录，只允许使用git-shell进行管理git的仓库。 如果有其他小伙伴要连接git服务器，仅需要把他的公钥也添加到authorized_keys即可。 git的自动权限管理：gitolite如果团队大点的，我们可以用gitolite管理，而且使用很方便。 gitolite的安装和配置以下配置此承接第5，如果第6步您已经操作，请注意第二步的说明。 第一步：添加gitolite依赖的perl的包 1$ yum install &apos;perl(Data::Dumper)&apos; 第二步：清空服务器端配置的ssh的公钥 确保：~/.ssh/authorized_keys文件是空的，或者不存在。如果已经存在，建议你把他改名即可，比如：authorized_keys.bak 第三步：上传管理员的客户端的ssh公钥到服务器 把你管理员电脑的ssh的id_rsa.pub文件拷贝到服务器的： $HOME/YourName.pub YourName可以自定义，最好根据不同伙伴的名字命名。 参考： 12# mac客户端$ scp /Users/fly/.ssh/id_rsa.pub git@aicoder.com:malun.pub 第四步：安装配置gitolite 用git账号登录，并执行如下命令。 12345678910111213141516171819202122232425262728293031323334# 切换到git账号$ su git# 进入git主目录$ cd /home/git# 下载gitolite的仓库$ git clone https://github.com/sitaramc/gitolite# 创建bin文件夹，必须！！！$ mkdir -p $HOME/bin# 用下载下来的仓库中的insall执行安装操作，指向的目录就是上一命令行创建的目录$ ./gitolite二进制/install -to $HOME/bin# 把上传到服务器的 管理员的公钥setup到gitolite中，注意：YourName.pub改成你自己的文件名。$ ~/bin/gitolite setup -pk ~/YourName.pub# 此时安装配完成后，查看git主目录$ ls /home/gitdrwxr-xr-x 7 git git 4096 Apr 3 23:50 bin # 我们创建的存放gitolite二进制drwxrwxr-x 6 git git 4096 Apr 3 23:40 gitolitedrwx------ 6 git git 4096 Apr 3 23:52 .gitolite-rw------- 1 git git 7130 Apr 3 23:52 .gitolite.rc-rw------- 1 git git 398 Apr 3 23:39 malun.pub # 管理员的公钥drwxrw---- 3 git git 4096 Apr 3 23:40 .pki-rw------- 1 git git 19 Apr 4 00:26 projects.list # 仓库列表（gitolite自动创建）drwx------ 5 git git 4096 Apr 4 00:26 repositories # 存放所有仓库文件夹drwx------ 2 git git 4096 Apr 4 15:50 .ssh# repositories目录下已经有了两个git仓库了。# .# |-- gitolite-admin.git # 管理配置权限的仓库# `-- testing.git # 测试仓库 好了，到此位置，管理员就可以直接把默认的远程管理的仓库gitolite-admin直接clone到本地进行管理git服务了。 第五步：管理员在本地管理和配置服务器端的仓库 下载服务器端的远程管理仓库 123456789# 下载远程管理仓库, 请把aicoder.com换成你自己服务器的域名或者ip$ git clone git@aicoder.com:gitolite-admin$ cd gitolite-admin# 目录结构如下：# .# ├── conf # 配置文件夹# │ └── gitolite.conf # 配置权限的文件# └── keydir # 客户端的公钥文件夹，所有伙伴的公钥要放到此目录下# └── malun.pub gitolite的权限配置 添加其他开发的小伙伴 把小伙伴的公钥发给管理员。管理员添加到gitolite-admin仓库的keydir目录下,注意文件名字格式为username.pub,username就是配置权限时的用户名。 配置用户对仓库的读写权限 直接修改conf文件夹下的，gitolite.conf文件。简单解释下几个用法： repo代表仓库的意思，如果新添加一个repo，代表服务端新建一个空仓库，仓库push到服务端后会自动创建。 RW 代表可读可写 @all 代表所有人。 master和 dev代表分支 参考： 12345678910111213@admin = malun @om = malun bcd repo gitolite-admin RW+ = malun repo testing RW+ = @all repo om RW+ = @admin RW+ master = @admin RW+ dev = @om 应用修改到服务器端 做好配置后，由管理员把修改push到服务器端，会自动处理。 1234$ git add conf$ git add keydir$ git commit -m &quot;added foo, gave access to alice, bob, carol&quot;$ git push]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab搭建]]></title>
    <url>%2F2019%2F11%2F01%2Fgitlab%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[安装步骤 配置yum源 1vim /etc/yum.repos.d/gitlab-ce.repo 复制以下内容： 123456[gitlab-ce]name=gitlab-cebaseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el6Repo_gpgcheck=0Enabled=1Gpgkey=https://packages.gitlab.com/gpg.key 更新本地yum缓存 1sudo yum makecache 安装GitLab社区版 12sudo yum install -y gitlab-ce --nogpgcheck #自动安装最新版sudo yum install gitlab-ce-x.x.x #安装指定版本 GitLab常用命令 12345678sudo gitlab-ctl start # 启动所有 gitlab 组件；sudo gitlab-ctl stop # 停止所有 gitlab 组件；sudo gitlab-ctl restart # 重启所有 gitlab 组件；sudo gitlab-ctl status # 查看服务状态；sudo gitlab-ctl reconfigure # 启动服务；sudo vim /etc/gitlab/gitlab.rb # 修改默认的配置文件；gitlab-rake gitlab:check SANITIZE=true --trace # 检查gitlab；sudo gitlab-ctl tail # 查看日志； 安装问题 yum安装软件时报错libmysqlclient.so.18()(64bit) 环境：CentOS 7.2，使用网易yum的网络源问题：使用yum安装软件时报错…2:postfix-2.10.1-6.el7.x86_64 has missing requires of libmysqlclient.so.18()(64bit)2:postfix-2.10.1-6.el7.x86_64 has missing requires of libmysqlclient.so.18(libmysqlclient_18)(64bit)重点关注：libmysqlclient.so.18()(64bit)解决:缺少Percona-XtraDB-Cluster-shared-55-5.5.37-25.10.756.el6.x86_64.rpm这个包 12# wget http://www.percona.com/redir/downloads/Percona-XtraDB-Cluster/5.5.37-25.10/RPM/rhel6/x86_64/Percona-XtraDB-Cluster-shared-55-5.5.37-25.10.756.el6.x86_64.rpm# rpm -ivh Percona-XtraDB-Cluster-shared-55-5.5.37-25.10.756.el6.x86_64.rpm 安装后访问报502 解决方案为修改默认端口号： 1234567891011[root@ianly]# vim /etc/gitlab/gitlab.rb 修改两个冲突端口号external_url &apos;http://ip:8899&apos;unicorn[&apos;port&apos;] = 8088# 启动GitLab[root@ianly]# gitlab-ctl reconfigure[root@ianly]# gitlab-ctl restart# 访问http://ip:8899 忘记root密码 12345[root@ruanshubin gitlab]# gitlab-rails console productionirb(main):01:0&gt; user = User.where(id:1).firstirb(main):02:0&gt; user.password=&apos;Administrator&apos;irb(main):03:0&gt; user.save!]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot自定义Starter]]></title>
    <url>%2F2019%2F10%2F31%2FSpringboot%E8%87%AA%E5%AE%9A%E4%B9%89Starter%2F</url>
    <content type="text"><![CDATA[在springboot中，使用的最多的就是starter。starter可以理解为一个可拔插式的插件，例如，你想使用jdbc插件，那么可以使用spring-boot-starter-jdbc；如果想使用mongodb，可以使用spring-boot-starter-data-mongodb。 下面介绍如何自定义Starter。 自定义Starter创建maven工程 命名规范 注意artifactId的命名规则，Spring官方Starter通常命名为spring-boot-starter-{name}如 spring-boot-starter-web， Spring官方建议非官方Starter命名应遵循{name}-spring-boot-starter的格式, 如mybatis-spring-boot-starter。这里创建的项目的artifactId为helloworld-spring-boot-starter。 引入必要依赖 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt; XxxProperties在使用Spring官方的Starter时通常可以在application.properties中来配置参数覆盖掉默认的值，例如在使用redis时一般就会有对应的RedisProperties 12345678@ConfigurationProperties(prefix = &quot;spring.redis&quot;)public class RedisProperties &#123; private int database = 0; private String url; private String host = &quot;localhost&quot;; private String password; private int port = 6379;&#125; 我们来模仿来定义自己的Properties类: 1234567891011@ConfigurationProperties(prefix = &quot;spring.person&quot;)public class PersonProperties &#123; // 姓名 private String name; // 年龄 private int age; // 性别 private String sex = &quot;M&quot;; // Getter &amp; Setter&#125; 核心服务类每个starter都有自己的功能，例如在spring-boot-starter-jdbc中最重要的类时JdbcTemplate，每个starter中的核心业务类明白都不同，也没什么规律（像spring-boot-starter-data-xxx的命名是比较有规律的），这里使用PersonService来定义helloworld-spring-boot-starter的功能，这里通过一个sayHello来模拟一个功能。 1234567891011121314public class PersonService &#123; private PersonProperties properties; public PersonService() &#123; &#125; public PersonService(PersonProperties properties) &#123; this.properties = properties; &#125; public void sayHello()&#123; System.out.println(&quot;大家好，我叫：&quot; + properties.getName() + &quot;,今年&quot; + properties.getAge() + &quot;岁&quot;); &#125;&#125; 自动配置类一般每个starter都至少会有一个自动配置类，一般命名规则使用XxxAutoConfiguration, 例如RedisAutoConfiguration 123456789101112131415161718192021222324252627282930@Configuration@ConditionalOnClass(&#123; JedisConnection.class, RedisOperations.class, Jedis.class &#125;)@EnableConfigurationProperties(RedisProperties.class)public class RedisAutoConfiguration &#123; @Configuration @ConditionalOnClass(GenericObjectPool.class) protected static class RedisConnectionConfiguration &#123; private final RedisProperties properties; @Bean @ConditionalOnMissingBean(RedisConnectionFactory.class) public JedisConnectionFactory redisConnectionFactory() throws UnknownHostException &#123; return applyProperties(createJedisConnectionFactory()); &#125; &#125; @Configuration protected static class RedisConfiguration &#123; @Bean @ConditionalOnMissingBean(name = &quot;redisTemplate&quot;) public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;Object, Object&gt;(); template.setConnectionFactory(redisConnectionFactory); return template; &#125;&#125; 这里我们定义自己的自动配置PersonServiceAutoConfiguration，并将核心功能类PersonService放入到Spring Context容器中 12345678910111213141516@Configuration@EnableConfigurationProperties(PersonProperties.class)@ConditionalOnClass(PersonService.class)@ConditionalOnProperty(prefix = &quot;spring.person&quot;, value = &quot;enabled&quot;, matchIfMissing = true)public class PersonServiceAutoConfiguration &#123; @Autowired private PersonProperties properties; @Bean @ConditionalOnMissingBean(PersonService.class) // 当容器中没有指定Bean的情况下，自动配置PersonService类 public PersonService personService()&#123; PersonService personService = new PersonService(properties); return personService; &#125;&#125; @ConditionalOnClass：当类路径classpath下有指定的类的情况下进行自动配置 @ConditionalOnMissingBean:当容器(Spring Context)中没有指定Bean的情况下进行自动配置 @ConditionalOnProperty(prefix = “example.service”, value = “enabled”, matchIfMissing = true)，当配置文件中example.service.enabled=true时进行自动配置，如果没有设置此值就默认使用matchIfMissing对应的值 @ConditionalOnMissingBean，当Spring Context中不存在该Bean时。 @ConditionalOnBean:当容器(Spring Context)中有指定的Bean的条件下 @ConditionalOnMissingClass:当类路径下没有指定的类的条件下 @ConditionalOnExpression:基于SpEL表达式作为判断条件 @ConditionalOnJava:基于JVM版本作为判断条件 @ConditionalOnJndi:在JNDI存在的条件下查找指定的位置 @ConditionalOnNotWebApplication:当前项目不是Web项目的条件下 @ConditionalOnWebApplication:当前项目是Web项目的条件下 @ConditionalOnResource:类路径下是否有指定的资源 @ConditionalOnSingleCandidate:当指定的Bean在容器中只有一个，或者在有多个Bean的情况下，用来指定首选的Bean src/main/resources/META-INF/spring.factories注意：META-INF是自己手动创建的目录，spring.factories也是手动创建的文件,在该文件中配置自己的自动配置类 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.ruanshubin.config.PersonServiceAutoConfiguration 测试 打包mvn clean install 创建一个Spring Boot工程并引入依赖 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruanshubin.springboot&lt;/groupId&gt; &lt;artifactId&gt;helloworld-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置application.properties 12spring.person.name=mengdayspring.person.age=28 test 12345678910111213@RunWith(SpringRunner.class)@SpringBootTestpublic class MystarterApplicationTests &#123; @Autowired private PersonService personService; @Test public void testHelloWorld() &#123; personService.sayHello(); &#125;&#125; 从使用者的角度来看，自己并没有将PersonService放入到Spring容器中，就直接来使用了，进行注入进来了。 工作原理总结下Starter的工作原理： Spring Boot在启动时扫描项目所依赖的JAR包，寻找包含spring.factories文件的JAR包， 然后读取spring.factories文件获取配置的自动配置类AutoConfiguration， 然后将自动配置类下满足条件(@ConditionalOnXxx)的@Bean放入到Spring容器中(Spring Context) 这样使用者就可以直接用来注入，因为该类已经在容器中了 @ConfigurationProperties: 注解主要用来把properties配置文件转化为对应的XxxProperties来使用的,并不会把该类放入到IOC容器中，如果想放入到容器中可以在XxxProperties上使用@Component来标注，也可以使用@EnableConfigurationProperties(XxxProperties.class)统一配置到Application上来，这种方式可以在Application上来统一开启指定的属性，这样也没必要在每个XxxProperties上使用@Component @EnableConfigurationProperties(XxxProperties.class) 注解的作用是@ConfigurationProperties注解生效。如果只配置@ConfigurationProperties注解，在IOC容器中是获取不到properties配置文件转化的bean的 如果在每个Properties上都使用@Component来标注，那么在XxxApplication上也不需要使用@EnableConfigurationProperties({XxxProperties.class})来标注了，同样也可以在spring上下文容器中也能获取到XxxProperties对应的bean]]></content>
      <categories>
        <category>Springboot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK系统研究]]></title>
    <url>%2F2019%2F10%2F30%2FELK%E7%B3%BB%E7%BB%9F%E7%A0%94%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[引言需求背景 业务发展越来越庞大，服务器越来越多; 各种访问日志、应用日志、错误日志量越来越多，导致运维人员无法很好的去管理日志; 开发人员排查问题，需要到服务器上查日志，不方便; 运营人员需要一些数据，需要我们运维到服务器上分析日志。 为什么要用到ELK一般我们需要进行日志分析场景：直接在日志文件中grep、awk 就可以获得自己想要的信息。但在规模较大也就是日志量多而复杂的场景中，此方法效率低下，面临问题包括日志量太大如何归档、文本搜索太慢怎么办、如何多维度查询。需要集中化的日志管理，所有服务器上的日志收集汇总。常见解决思路是建立集中式日志收集系统，将所有节点上的日志统一收集，管理，访问。 大型系统通常都是一个分布式部署的架构，不同的服务模块部署在不同的服务器上，问题出现时，大部分情况需要根据问题暴露的关键信息，定位到具体的服务器和服务模块，构建一套集中式日志系统，可以提高定位问题的效率。 一个完整的集中式日志系统，需要包含以下几个主要特点： 收集－能够采集多种来源的日志数据; 传输－能够稳定的把日志数据传输到中央系统; 存储－如何存储日志数据; 分析－可以支持UI分析; 警告－能够提供错误报告，监控机制。 而ELK则提供了一整套解决方案，并且都是开源软件，之间互相配合使用，完美衔接，高效的满足了很多场合的应用。是目前主流的一种日志系统。 ELK简介ELK是三个开源软件的缩写，分别为：Elasticsearch 、 Logstash以及Kibana , 它们都是开源软件。不过现在还新增了一个Beats，它是一个轻量级的日志收集处理工具(Agent)，Beats占用资源少，适合于在各个服务器上搜集日志后传输给Logstash，官方也推荐此工具，目前由于原本的ELK Stack成员中加入了Beats工具所以已改名为Elastic Stack。 Elastic Stack包含： Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。详细可参考Elasticsearch权威指南; Logstash主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去; Kibana也是一个开源和免费的工具，Kibana可以为Logstash和ElasticSearch 提供的日志分析友好的Web界面，可以帮助汇总、分析和搜索重要数据日志; Beats在这里是一个轻量级日志采集器，其实Beats家族有6个成员，早期的ELK架构中使用Logstash收集、解析日志，但是Logstash对内存、cpu、io等资源消耗比较高。相比Logstash，Beats所占系统的CPU和内存几乎可以忽略不计。 ELK Stack （5.0版本之后）—&gt; Elastic Stack == （ELK Stack + Beats）。目前Beats包含六种工具： Packetbeat： 网络数据（收集网络流量数据）; Metricbeat： 指标 （收集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）; Filebeat： 日志文件（收集文件数据）; Winlogbeat： windows事件日志（收集 Windows 事件日志数据）; Auditbeat：审计数据 （收集审计日志）; Heartbeat：运行时间监控 （收集系统运行时的数据）。 ELK部署下载：https://www.elastic.co/cn/downloads/ Elasticsearch安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111# 解压es的安装包[root@sumo elasticsearch-6.6.2]# tar -zvxf elasticsearch-6.6.2-linux-x86_64.tar.gz [root@sumo elasticsearch-6.6.2]# cd elasticsearch-6.6.2/[root@sumo elasticsearch-6.6.2]# cd config/[root@sumo config]# vim elasticsearch.yml# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:#cluster.name: ELK## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:#node.name: node-1## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):##path.data: /path/to/data## Path to log files:##path.logs: /path/to/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:##bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):#network.host: 10.194.224.83## Set a custom port for HTTP:#http.port: 9200## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when this node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]##discovery.seed_hosts: [&quot;host1&quot;, &quot;host2&quot;]## Bootstrap the cluster using an initial set of master-eligible nodes:##cluster.initial_master_nodes: [&quot;node-1&quot;, &quot;node-2&quot;]cluster.initial_master_nodes: [&quot;node-1&quot;]## For more information, consult the discovery and cluster formation module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: true# 创建es账户[root@sumo config]# groupadd elsearch[root@sumo config]# useradd elsearch -g elsearch -p elsearch[root@sumo config]# chown -R elsearch:elsearch es根目录# 切换到elsearch用户[root@sumo config]# su elsearch[elsearch@sumo config]$ # 启动es[elsearch@sumo config]$ /usr/software/es/elasticsearch-6.6.2/bin/elasticsearch -d# 加了-d是后台启动，不加是前台启动，第一次不建议后台启动，前台启动可以直观的看到日志信息 前台启动后，报以下3个错： 123[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144][3]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured Elasticsearch：max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 1234567[root@sumo config]# vim /etc/security/limits.conf 增加以下配置：* soft nofile 65536* hard nofile 65536重新连接服务器，查看配置是否生效：ulimit -Suulimit -Hu Elasticsearch：max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] elasticsearch用户拥有的内存权限太小，至少需要262144； 123456789[root@sumo ~]# vim /etc/sysctl.conf# 添加以下配置：vm.max_map_count=262144# 使配置生效：[root@sumo ~]# sysctl -p# 查看[root@sumo ~]# sysctl -a|grep vm.max_map_count [1]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured 123[elsearch@sumo config]$ vim /usr/software/es/elasticsearch-6.6.2/config/elasticsearch.yml 将 #cluster.initial_master_nodes: [&quot;node-1&quot;, &quot;node-2&quot;] 修改为 cluster.initial_master_nodes: [&quot;node-1&quot;] 浏览器访问: http://xxx.xxx.xxx.xxx:9200/ 1234567891011121314151617&#123; &quot;name&quot; : &quot;node-1&quot;, &quot;cluster_name&quot; : &quot;ELK&quot;, &quot;cluster_uuid&quot; : &quot;1l1qU4KPRqaafaPTrZAy-w&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.6.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;e4efcb5&quot;, &quot;build_date&quot; : &quot;2019-04-29T12:56:03.145736Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.0.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.7.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 其他可能的报错及解决方案: Elasticsearch：Failed to obtain node lock 123# 节点被已有的es进程占用，需要杀掉重启ps aux | grep &apos;java&apos;kill -9 &lt;属于es的PID&gt; elk的3个组件均不能通过ip:port的形式访问 将各自组件的yml配置文件中的host修改为0.0.0.0。 Cerebro安装Cerebro是一款Elasticsearch监控工具。 https://github.com/lmenezes/cerebro 1234567891011121314151617181920212223[root@sumo cerebro]# tar -zvxf cerebro-0.8.3.tgz [root@sumo cerebro]# cd /usr/software/cerebro/cerebro-0.8.3/conf/[root@sumo conf]# vim application.conf hosts = [ #&#123; # host = &quot;http://localhost:9200&quot; # name = &quot;Some Cluster&quot; #&#125;, # Example of host with authentication #&#123; # host = &quot;http://some-authenticated-host:9200&quot; # name = &quot;Secured Cluster&quot; # auth = &#123; # username = &quot;username&quot; # password = &quot;secret-password&quot; # &#125; #&#125; &#123; host = &quot;http://xxx.xxx.xxx.xxx:9200&quot; name = &quot;elk&quot; &#125;] 启动Cerebro: 1[root@sumo bin]# nohup ./cerebro -Dhttp.port=1234 -Dhttp.address=10.194.224.112 &gt; /dev/null &amp; Kibana安装 1234567891011121314151617181920[root@sumo kibana]# tar -zvxf kibana-6.6.2-linux-x86_64.tar.gz [root@sumo kibana]# cd kibana-6.6.2-linux-x86_64/config/[root@sumo config]# vim kibana.yml server.port: 5602server.host: &quot;0.0.0.0&quot;elasticsearch.hosts: [&quot;http://10.194.224.83:9200&quot;][root@sumo config]# nohup ../kibana &gt; /dev/null &amp;# 如何关闭kibana# 查询kibana的PIDps -ef | grep node netstat -tunlp|grep 5602root 777 1 0 2018 ? 00:00:00 /usr/sbin/mcelog --ignorenodev --daemon --syslogroot 11323 1 1 May21 ? 00:17:06 ./../node/bin/node --no-warnings --max-http-header-size=65536 ./../src/cliroot 76232 63850 0 11:48 pts/1 00:00:00 grep --color=auto nodekill -9 11323 Logstash安装12345678910111213141516171819202122232425262728[root@sumo logstash]# tar -zvxf logstash-6.6.2.tar.gz [root@sumo logstash]# cd /usr/software/logstash/logstash-6.6.2/config[root@sumo config]# vim std_to_es.conf # 安装logstash-codec-json_lines插件[root@sumo config]# ../bin/logstash-plugin install logstash-codec-json_linesinput &#123; tcp &#123; host =&gt; &quot;xxx.xxx.xxx.xxx&quot; port =&gt; 4560 mode =&gt; &quot;server&quot; tags =&gt; [&quot;tags&quot;] codec =&gt; json_lines &#125;&#125;output&#123; elasticsearch &#123; action =&gt; &quot;index&quot; hosts =&gt; [&quot;xxx.xxx.xxx.xxx:9200&quot;] index =&gt; &quot;%&#123;[appname]&#125;&quot;&#125; stdout &#123; codec =&gt; rubydebug &#125;&#125;# 启动[root@sumo config]# nohup ../bin/logstash -f ./std_to_es.conf &gt; /dev/null &amp; filebeat使用12345678910111213[root@sumo filebeat-6.6.2-linux-x86_64]# vim filebeat.ymlfilebeat.inputs:- type: log paths: - /usr/software/data/filebeat-dataset.logsetup.template.name: &quot;tcd&quot;setup.template.pattern: &quot;tcd-*&quot;output.elasticsearch: hosts: [&quot;xxx.xxx.xxx.xxx:9200&quot;] index: &quot;tcd-%&#123;+yyyy.MM.dd&#125;&quot;[root@sumo filebeat-6.6.2-linux-x86_64]# ./filebeat -e -c filebeat.yml -d &quot;publish&quot; filebeat监控多个文件,并且写入elasticsearch的不同index的中 12345678910111213141516171819202122filebeat.inputs:- type: log paths: - /usr/software/data/tcd-as.log fields: index: &apos;tcd-as&apos;- type: log paths: - /usr/software/data/tcd-dm.log fields: index: &apos;tcd-dm&apos;output.elasticsearch: hosts: [&quot;xxx.xxx.xxx.xxx:9200&quot;] indices: - index: &quot;tcd-as&quot; when: contains: fields.index: &quot;tcd-as&quot; - index: &quot;tcd-dm&quot; when: contains: fields.index: &quot;tcd-dm&quot; logback.xml: 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration&gt;&lt;configuration&gt; &lt;appender name=&quot;LOGSTASH&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt; &lt;destination&gt;xxx.xxx.xxx.xxx:4560&lt;/destination&gt; &lt;encoder charset=&quot;UTF-8&quot; class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot;&gt; &lt;!-- 注意：index的名称必须小写，且只允许下划线，中划线会导致消息进入不到es里面 --&gt; &lt;customFields&gt;&#123;&quot;appname&quot;:&quot;applog&quot;&#125;&lt;/customFields&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;include resource=&quot;org/springframework/boot/logging/logback/base.xml&quot;/&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;LOGSTASH&quot; /&gt; &lt;appender-ref ref=&quot;CONSOLE&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt;]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>基础</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器配置代理上网]]></title>
    <url>%2F2019%2F10%2F29%2FLinux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86%E4%B8%8A%E7%BD%91%2F</url>
    <content type="text"><![CDATA[代理服务器选择了CCproxy，下载并安装CCProxy，配置所要代理的协议，并选择能够联外网的网卡ip； 账号管理根据个人需要进行配置，我这边选择的是允许所有（建议最好为虚拟机配置账号，方便以后调试和监控）。 在CentOS中配置全局代理 1234567vim /etc/profileexport http_proxy=&quot;http://202.169.100.196:8089&quot;export https_proxy=&quot;http://202.169.100.196:8089&quot;export ftp_proxy=$http_proxysource /etc/profile 配置yum代理 123vim /etc/yum.confproxy=http://202.169.100.196:8089 配置wget代理 12345vim /etc/wgetrchttp_proxy = http://202.169.100.196:8089ftp_proxy = http://202.169.100.196:8089https_proxy = http://202.169.100.196:8089 测试 12curl -k https://www.baidu.comwget https://www.baidu.com]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的线程池]]></title>
    <url>%2F2019%2F10%2F28%2FJava%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[创建线程的方法常见的创建线程的方法，主要有以下3种: 继承Thread类; 实现Runnable接口; 实现Callable接口. 需要有返回值时，可以使用Callable创建多线程，使用FutureTask的get()来取得该返回值。 上述3种方法创建的线程在运行结束后均会被虚拟机销毁，如果线程数量多的话，频繁的创建和销毁线程会大大浪费时间和效率，更重要的是浪费内存，因为正常来说，线程执行完毕后死亡，线程对象变成垃圾。 是否有1种方法能让线程运行完不立即销毁，而是让线程重复使用，继续执行其他的任务呢? 线程池可解决上述问题。 线程池线程池参数线程池的最上层接口是Executor。 123public interface Executor &#123; void execute(Runnable command);&#125; execute最后由ThreadPoolExecutor类实现，该方法用于传入任务，而ThreadPoolExecutor是线程池的核心类，此类的构造方法如下: 1234567891011public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory);public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler);public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); 构造方法的参数及意义: corePoolSize 核心线程池的大小，如果核心线程池有空闲位置，新的任务就会被核心线程池新建1个线程执行，执行完毕后不会销毁线程，线程会进入缓存队列等待再次被运行； maximumPoolSize 线程池能创建最大的线程数量，如果核心线程池和缓存队列都已经满了，新的任务进来就会创建新的线程来执行，但是数量不能超过maximumPoolSize，否则会采取拒绝接受任务策略； keepAliveTime 非核心线程能够空闲的最长时间，超过时间，线程终止。该参数默认在线程数量超过核心线程池大小时才会起作用； unit 时间单位，和keepAliveTime配合使用； workQueue 缓存队列，用于存放等待被执行的任务； threadFactory 线程工厂，用于创建线程，一般有3种选择策略； 123ArrayBlockingQueue;LinkedBlockingQueue;SynchronousQueue; handler 拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种策略为： 1234ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 Executor接口有一个子接口ExecutorService，ExecutorService的实现类为AbstracExecutorService，而ThreadPoolExcutor正是AbstrcExecutorService的子类。 ThreadPoolExecutor还有两个常用的方法shutdown()和shutdownNow()，两者都用来关闭线程池，但是后者有一个结果返回。 线程池实现原理 线程池图: 12345678910111213141516171819202122232425262728293031323334353637// 任务的后备队列private final BlockingQueue&lt;Runnable&gt; workQueue;// 锁private final ReentrantLock mainLock = new ReentrantLock();// 用来支持等待中断的private final Condition termination = mainLock.newCondition();// 存放的工作线程，只有当获取到锁的时候才能访问这个 Setprivate final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();// 线程池最大数量private int largestPoolSize;// 完成的线程数，只有在获取锁的时候才能更新这个值private long completedTaskCount;//==============================================================================// 这里有提到用户自定义的变量我们都是用 volatile 来修饰 以保证获取到最新的值//==============================================================================// 线程创建工厂类private volatile ThreadFactory threadFactory;// 当任务队列饱和或者线程池关闭后 再往里面提交任务时候的执行策略private volatile RejectedExecutionHandler handler;// 默认的执行策略是采用的 AbortPolicy (这是一个函数式接口的子类，里面实现的方法默认是抛异常)private static final RejectedExecutionHandler defaultHandler = new AbortPolicy();// 非核心线程的存活时间private volatile long keepAliveTime;// 是否允许核心线程具有存活时间，允许则上面的参数也会作用于核心线程private volatile boolean allowCoreThreadTimeOut;// 核心线程的大小private volatile int corePoolSize;// 最大线程数private volatile int maximumPoolSize;// 池控参数 非常重要！！！！private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));// ctl 的解包 -&gt; workerCount 和 runStateprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;// 打包操作 两个变量或一下private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 其中比较重要的属性有: workQueue(任务队列)、一个Set(线程集合)、池参数、线程工厂类、拒绝策略、池控参数。 其中池控参数是将两个变量都打包进去，分别是workerCount和runState。 workerCount为有效线程数，runState表明线程池的状态是否为运行。为了方便表示，我们把 workerCount和runState打包到了1个变量里面就是ctl。 12345678910111213COUNT_BITS = 29CAPACITY = 0001 1111 1111 1111 1111 1111 1111 1111RUNNING = 111 0 0000 0000 0000 0000 0000 0000 0000SHUTDOWN = 000 0 0000 0000 0000 0000 0000 0000 0000STOP = 001 0 0000 0000 0000 0000 0000 0000 0000TIDYING = 010 0 0000 0000 0000 0000 0000 0000 0000TERMINATED = 011 0 0000 0000 0000 0000 0000 0000 0000 高3位作为状态值，低29位作为工作线程总数。 线程池状态 线程池和线程一样拥有自己的状态，在ThreadPoolExecutor类中定义了一个volatile变量runState来表示线程池的状态，线程池有以下状态: RUNNING：接受新任务并处理排队的任务 SHUTDOWN：不接受新任务，但处理排队的任务 STOP：不接受新任务，不处理排队的任务，并中断正在进行的任务 TIDYING：所有任务都已终止，workerCount为零，线程转换到状态TIDYING 将运行terminate() 勾子 TERMINATED：terminated()已完成 并且这些值之间顺序很重要，以允许有序的比较。 runState在整个过程中是单调递增的但不需要经过每一个状态，具体规律如下： RUNNING -&gt; SHUTDOWN 在执行 shutdown()的时候 (RUNNING or SHUTDOWN) -&gt; STOP 在执行shutdownNow() SHUTDOWN -&gt; TIDYING 当任务队列和线程池为空的时候 STOP -&gt; TIDYING 当池为空的时候 TIDYING -&gt; TERMINATED 钩子方法调用完毕 Excute方法1234567891011121314151617181920212223242526272829public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; // 如果工作线程少于corePoolSize，则尝试增加新核心线程处理command if (addWorker(command, true)) // 新核心线程增加成功，则直接返回 return; // 新核心线程增加不成功，重新获取池控参数 c = ctl.get(); &#125; // 如果线程池处于Running，则将当前command增加到任务队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 重新获取池化参数 int recheck = ctl.get(); // 如果线程池关闭了，我们需要做回退动作，也就是撤销刚才放入的任务 // 如果撤销成功，执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果撤销失败，并且没有工作线程不管他 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 若排队失败，增加非核心线程处理command // 若线程添加失败，则说明线程池关闭或者处于饱和状态 else if (!addWorker(command, false)) reject(command);&#125; addWorker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 如果工作线程数量大于CAPACITY // 或者工作线程数量大于最大值(若core为true，最大值为corePoolSize，否则为maximumPoolSize) if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 若工作线程数目增加成功，退出最外层自旋 if (compareAndIncrementWorkerCount(c)) break retry; // 重新读取池控参数，若状态发生变化，继续自旋 c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; shutdown123456789101112131415161718public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 调用checkShutdownAccess方法检查每一个线程池的线程是否有可以ShutDown的权限 checkShutdownAccess(); // 调用advanceRunState函数通过自旋的CAS操作来将ctl中的状态变为SHUTDOWN advanceRunState(SHUTDOWN); // 调用interruptIdleWorkers方法，将所有Idle状态的线程都调用interrupt方法，中断线程。而判断idle状态使用Worker中的ReentrantLock来调用tryLock尝试加锁，看Worker线程是否已经获取了锁，如果Worker的锁已经被加了的话，那么tryLock返回的就是false interruptIdleWorkers(); // 通过onShutDown()方法告知子类，线程池要处于ShutDown状态了 onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; // 调用tryTermiante的方法尝试终止线程池 tryTerminate();&#125; shutdownNow123456789101112131415public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(STOP); interruptWorkers(); tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks;&#125; ShutDownNow方法和ShutDown方法差不多，这两个方法的区别有： shutDownNow方法会返回未完成的任务队列中的任务列表 advanceRunState方法中传入的是STOP，而不是SHUTDOWN。 interruptIdleWorkers1234567891011121314151617181920212223242526272829private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; // 如果线程未被中断，尝试获取worker的锁 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; // 中断线程 t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; // 如果onlyOne为True，则只中断1个空闲工作线程 if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125;// 默认中断所有空闲工作线程private void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125; tryTerminate123456789101112131415161718192021222324252627282930313233final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); // 判断当前线程池是否正在运行，或者当前线程池的状态比TIDYING（整理中）要大（也就是处于TIDYING或者TERMINATED状态），或者当前线程状态处于SHUTDOWN并且任务队列不为空的话，那么就直接return if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 如果当前的WorkerCount不为0，那么就会调用interruptedIdleWorkers(true)，并且返回 if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 通过CAS操作将ctl设置成TIDYING，如果设置成功之后就会调用terminated方法， 告知子类，要终止了，终止完之后，就会将ctl的状态设置成TERMINATED，以及workerCount为0 try &#123; if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; terminated(); &#125; finally &#123; ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125; processWorkerExit12345678910111213141516171819202122232425262728293031323334private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 如果是意外退出的话，那么就需要把WorkerCount-- if (completedAbruptly) // If abrupt, then workerCount wasn&apos;t adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 加完锁后，同步将completedTaskCount进行增加，表示总共完成的任务数，并且从WorkerSet中将对应的Worker移除 try &#123; completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); int c = ctl.get(); // 判断当前的线程池状态，如果当前线程池状态比STOP大的话，就不处理 if (runStateLessThan(c, STOP)) &#123; // 判断是否是意外退出，如果不是意外退出的话，那么就会判断最少要保留的核心线程数，如果allowCoreThreadTimeOut被设置为true的话，那么说明核心线程在设置的KeepAliveTime之后，也会被销毁 if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; // 如果最少保留的Worker数为0的话，那么就会判断当前的任务队列是否为空，如果任务队列不为空的话而且线程池没有停止，那么说明至少还需要1个线程继续将任务完成 if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; // 判断当前的Worker是否大于min，也就是说当前的Worker总数大于最少需要的Worker数的话，那么就直接返回，因为剩下的Worker会继续从WorkQueue中获取任务执行 if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; // 如果当前运行的Worker数比当前所需要的Worker数少的话，那么就会调用addWorker，添加新的Worker，也就是新开启线程继续处理任务 addWorker(null, false); &#125;&#125; getPoolSize1234567891011public int getPoolSize() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 若线程池状态大于等于TIDYING，则线程池大小为0，否则为workers.size() return runStateAtLeast(ctl.get(), TIDYING) ? 0 : workers.size(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; getActiveCount获取活跃线程总数。 1234567891011121314public int getActiveCount() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; int n = 0; for (Worker w : workers) // 若该线程被锁定，说明正在处理任务，属于活跃线程 if (w.isLocked()) ++n; return n; &#125; finally &#123; mainLock.unlock(); &#125;&#125; getTaskCount获取任务总数。 12345678910111213141516public long getTaskCount() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; long n = completedTaskCount; for (Worker w : workers) &#123; n += w.completedTasks; if (w.isLocked()) ++n; &#125; // 各线程已完成的任务之和+当前正在进行的任务+任务队列的大小作为任务总数 return n + workQueue.size(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; getCompletedTaskCount获取完成的任务总数。 12345678910111213public long getCompletedTaskCount() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; long n = completedTaskCount; // 遍历工作线程，叠加每个线程的completedTasks for (Worker w : workers) n += w.completedTasks; return n; &#125; finally &#123; mainLock.unlock(); &#125;&#125;]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志框架简述]]></title>
    <url>%2F2019%2F10%2F28%2F%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6%E7%AE%80%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[Java日志简述对于一个应用程序来说日志记录是必不可少的一部分。线上问题追踪，基于日志的业务逻辑统计分析等都离不日志。java领域存在多种日志框架，目前常用的日志框架包括Log4j 1，Log4j 2，Commons Logging，Slf4j，Logback，Jul。 Log4j Apache Log4j是一个基于Java的日志记录工具。它是由Ceki Gülcü首创的，现在则是Apache软件基金会的一个项目。 Log4j是几种Java日志框架之一。 Log4j 2 Apache Log4j 2是apache开发的一款Log4j的升级产品。 Commons Logging Apache基金会所属的项目，是一套Java日志接口，之前叫Jakarta Commons Logging，后更名为Commons Logging。 Slf4j 类似于Commons Logging，是一套简易Java日志门面，本身并无日志的实现。（Simple Logging Facade for Java，缩写Slf4j）。 Logback 一套日志组件的实现(Slf4j阵营)。 Jul (Java Util Logging),自Java1.4以来的官方日志实现。 Java常用日志框架历史 1996年早期，欧洲安全电子市场项目组决定编写它自己的程序跟踪API(Tracing API)。经过不断的完善，这个API终于成为一个十分受欢迎的Java日志软件包，即Log4j。后来Log4j成为Apache基金会项目中的一员。 期间Log4j近乎成了Java社区的日志标准。据说Apache基金会还曾经建议Sun引入Log4j到java的标准库中，但Sun拒绝了。 2002年Java1.4发布，Sun推出了自己的日志库JUL(Java Util Logging),其实现基本模仿了Log4j的实现。在JUL出来以前，Log4j就已经成为一项成熟的技术，使得Log4j在选择上占据了一定的优势。 接着，Apache推出了Jakarta Commons Logging，JCL只是定义了一套日志接口(其内部也提供一个Simple Log的简单实现)，支持运行时动态加载日志组件的实现，也就是说，在你应用代码里，只需调用Commons Logging的接口，底层实现可以是Log4j，也可以是Java Util Logging。 后来(2006年)，Ceki Gülcü不适应Apache的工作方式，离开了Apache。然后先后创建了Slf4j(日志门面接口，类似于Commons Logging)和Logback(Slf4j的实现)两个项目，并回瑞典创建了QOS公司，QOS官网上是这样描述Logback的：The Generic，Reliable Fast&amp;Flexible Logging Framework(一个通用，可靠，快速且灵活的日志框架)。 现今，Java日志领域被划分为两大阵营：Commons Logging阵营和Slf4j阵营。 Commons Logging在Apache大树的笼罩下，有很大的用户基数。但有证据表明，形式正在发生变化。2013年底有人分析了GitHub上30000个项目，统计出了最流行的100个Libraries，可以看出Slf4j的发展趋势更好： Apache眼看有被Logback反超的势头，于2012-07重写了Log4j 1.x，成立了新的项目Log4j 2, Log4j 2具有Logback的所有特性。 Java常用日志框架之间的关系 Log4j 2与Log4j 1发生了很大的变化，Log4j 2不兼容Log4j 1。 Commons Logging和Slf4j是日志门面(门面模式是软件工程中常用的一种软件设计模式，也被称为正面模式、外观模式。它为子系统中的一组接口提供一个统一的高层接口，使得子系统更容易使用)。Log4j和Logback则是具体的日志实现方案。可以简单的理解为接口与接口的实现，调用者只需要关注接口而无需关注具体的实现，做到解耦。 比较常用的组合使用方式是Slf4j与Logback组合使用，Commons Logging与Log4j组合使用。 Logback必须配合Slf4j使用。由于Logback和Slf4j是同一个作者，其兼容性不言而喻。 选择日志框架如果是在一个新的项目中建议使用Slf4j与Logback组合，这样有如下的几个优点。 Slf4j实现机制决定Slf4j限制较少，使用范围更广。由于Slf4j在编译期间，静态绑定本地的LOG库使得通用性要比Commons Logging要好。 Logback拥有更好的性能。Logback声称：某些关键操作，比如判定是否记录一条日志语句的操作，其性能得到了显著的提高。这个操作在Logback中需要3纳秒，而在Log4J中则需要30纳秒。LogBack创建记录器（logger）的速度也更快：13毫秒，而在Log4J中需要23毫秒。更重要的是，它获取已存在的记录器只需94纳秒，而Log4J需要2234纳秒，时间减少到了1/23。跟JUL相比的性能提高也是显著的。 Commons Logging开销更高 Logback文档免费。Logback的所有文档是全面免费提供的，不象Log4J那样只提供部分免费文档而需要用户去购买付费文档。 SLF4J用法Slf4j与其它日志组件的关系说明 Slf4j的设计思想比较简洁，使用了Facade设计模式，Slf4j本身只提供了一个slf4j-api-version.jar包，这个jar中主要是日志的抽象接口，jar中本身并没有对抽象出来的接口做实现。 对于不同的日志实现方案(例如Logback，Log4j…)，封装出不同的桥接组件(例如logback-classic-version.jar，slf4j-log4j12-version.jar)，这样使用过程中可以灵活的选取自己项目里的日志实现。 Slf4j与其它日志组件调用关系图 Slf4j与其他各种日志组件的桥接说明]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的持久化]]></title>
    <url>%2F2019%2F10%2F26%2FJava%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[持久化方案发展过程序列化当断电或者系统故障宕机时，内存中Java创建的对象将荡然无存，解决该问题的初始方式为—序列化。 序列化 将内存中的对象转换为二进制文件存储到硬盘。 反序列化 将二进制文件加载为内存中的对象。 序列化的缺点是效率低，对象少的时候还可以，如果需要对大规模的对象进行存储、查询则就捉襟见肘了。 比如想选取age&gt;26的所有Person对象，则需要把所有序列化之后的Person对象都装入内存，然后逐个比对年龄，效率慢到爆炸。 解决上述问题的方式为—使用关系型数据库存储大规模数据。 ORM关系型数据库用类似二维表格的形式来存储数据。并提供中间层SQL来支持关系代数、关系演算等，屏蔽了具体的实现细节和各个数据库之间的差异。 为了将Java对象映射到数据库的二维表格上去，需要将对象的属性变成数据库的行/列，该种过程称之为Object-Relational Mapping，实现该种过程的一系列框架称之为ORM框架。 对象映射到数据库的表上之后，需要建立与数据库的连接，由于各种数据库的底层实现千差万别，所以Java仅提供接口，然后由各数据库厂商去各自实现该接口，该接口即为Java Database Connectivity，简称JDBC。 EJB时代JDBC是一个非常”低级”的接口。程序员需要处理太多的细节，冗余代码太多，写一个简单的查询： 123451、打开Connection2、创建Statement3、执行SQL4、遍历ResultSet5、关闭Connection 在安全、事务、分布式、可伸缩性、高可用等高级功能场景下，操作系统及应用程序均不想承接这些脏活累活。 那交给谁呢？ 答案是—中间件(Middleware)，它专门负责底层操作系统和上层应用程序都不愿意做的事情。 Java充分发挥制定标准的特长，制订了J2EE规范，其涵盖了大部分企业开发的需求，把通用、复杂的服务交给中间件提供商去搞定，让开发人员集中精力在业务逻辑的开发上。 其中一个标准就是EJB，使用EJB即可不用写繁琐的JDBC代码了，数据的创建、读取、查询均可以用面向对象的风格搞定，并且EJB实例可以在一个集群上分布式的运行。 当然，EJB的缺点也非常明显，它过于笨重了，且开发繁琐、难以测试、性能低下。 是到了变革的时候了！ 轻量级ORM框架2001年，Gavin King发明了Hibernate，意为冬眠。 冬眠？冬天让内存中的数据进入数据库冬眠，春天来了从冬眠中醒来，进入内存工作。 同年，iBatis也出现了。 2004年，Rod Johnson给了EJB致命一击，他编写了Export One-on-One J2EE Development without EJB一书,公开宣扬抛弃笨重的EJB，使用由他开发出的轻量框架Spring。 Spring不但自己提供了轻量级的访问数据库的方法JdbcTemplate，还可轻松集成Hibernate、IBatis等一系列ORM框架，所以受到越来越多Java开发者的欢迎，EJB已名存实亡。 JPA后面出现的EJB3.0虽然兼收并蓄，融合了Hibernate的优点，但其笨重的底子是难以被改变的，最终还是被Java开发者无情地抛弃了。 EJB3.0定义的ORM标准却神奇地活了下来，也就是Java Persistence API(JPA)，Hibernate、EclipseLink、OpenJPA等明星框架均提供了针对JPA的实现，由于其简便性，收到了一部分开发者的喜爱。 JDBC发展过程 Socket 最开始数据库仅能支持网络访问，即通过Socket的方式获取数据库中的数据。 这种方式可以实现业务功能，但是业务层需要更换数据库时，由于各个数据库提供的接口不统一，则需要将业务代码的相关部分重写，统一接口迫在眉睫。 JDBC 继续抽象，用Connection来代表与数据库的连接，Statement中书写SQL代码，返回的结果统一用ResultSet来表示。 接口的具体实现由各数据库完成。 Driver 但还不够彻底，由于各数据库的实现类不同，更换数据库的时候还是需要更改相应代码。 继续抽象。 1234567891011121314public class Driver&#123; public static Connection getConnection(String dbType, Properties info)&#123; if(&quot;mysql&quot;.equals(dbType))&#123; return new MySqlConnentionImpl(info); &#125; if(&quot;oracle&quot;.equals(dbType))&#123; return new OracleConnentionImpl(info); &#125; if(&quot;db2&quot;.equals(dbType))&#123; return new DB2ConnentionImpl(info); &#125; throw new RuntimeException(&quot;unsupport db type: &quot; + dbType); &#125;&#125; 但还是存在问题，比如需要增加新的数据库，则需要频繁修改Driver代码，如果Driver已经打包到JDK里，则就无法修改了。 解决的方式也很简单，基于反射的方式从外部读取配置，然后创建相应的Connection实现类。 12345678910111213141516171819// Connection-type.properties// mysql = com.mysql.jdbc.MySqlConnectionImplpublic class Driver&#123; public static Connection getConnection(String dbType, Properties info)&#123; Class&lt;?&gt; clz = getConnectionImplClass(dbType); try&#123; Constructor&lt;?&gt; c = clz.getConstructor(Properties.class); return (Connection) c.newInstance(info); &#125;catch(Exception e)&#123; e.printStackTrace(); return null; &#125; &#125; private static Class&lt;?&gt; getConnectionImplClass(String dbType)&#123; // 读取配置文件，从中根据dbType来读取相应的Connection实现类，过程略 &#125;&#125; 但是，创建实现类的过程不应该被暴露出来。应该让各个厂商在各自的.jar中去创建各自的Connection实例对象。 使用工厂方法： 1234567891011// 属于JDK的Driver类public interface Driver&#123; public Connection getConnection(Properties info);&#125;// 属于mysql-jdbc.jar的MySqlDriver类public class MySqlDriver implements Driver&#123; @override public Connection getConnection(Properties info)&#123; return new MySqlConnentionImpl(info); &#125;&#125; 此时，Driver变成了接口，由各数据库厂商去具体实现。 业务层调用的时候通过反射的方式来进行Connection实现类的加载： 123Class&lt;?&gt; clz = Class.forName(&quot;com.mysql.MySqlDriver&quot;);Driver driver = (Driver)clz.newInstance();Connection conn = driver.getConnection(info); 进一步简化，将上面的脏活累活交给DriverManager。 123456789101112131415161718192021public class DriverManager&#123; private static List&lt;Driver&gt; registeredDrivers = new ArrayList&lt;&gt;(); public static Connection getConnection(String url, String user, String password)&#123; Properties info = new Properties(); info.put(&quot;user&quot;, user); info.put(&quot;password&quot;, password); for(Driver driver : registeredDrivers)&#123; Connection conn = driver.getConnection(url, info); if(conn != null)&#123; return conn; &#125; &#125; thow new RuntimeExecption(&quot;can&apos;t create a connection&quot;) &#125; public static void register(Driver driver)&#123; if(!registeredDrivers.contains(driver))&#123; registeredDrivers.add(driver); &#125; &#125;&#125; 例如，MySqlDriver的实现： 123456789101112131415public class MySqlDriver implements Driver&#123; static&#123; DriverManager.register(new MySqlDriver()) &#125; public Connection getConnection(String url, Properties info)&#123; if(acceptsURL(url))&#123; return new MySqlConnectionImpl(info); &#125; return null; &#125; public boolean acceptURL(String url)&#123; return url.startsWith(&quot;jdbc:mysql&quot;); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ是什么]]></title>
    <url>%2F2019%2F10%2F25%2FRabbitMQ%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[引言首先，明确一下MQ是啥？ MQ是Message Queue的简称，意即消息队列，队列可以理解成管道，即通过管道来进行消息的传递， 接着想一下MQ可以用来解决什么问题？ 双十一秒杀场景，瞬间来了海量请求，服务器短时间处理不过来，可以先给用户一个返回结果，然后将未处理的请求先放入消息队列，后台慢慢处理队列中的消息，整个过程是异步的。 MQ既然很有用，各大厂商们便开始考虑构建符合自己业务需求的MQ组件。 如同TCP协议、HTTP协议一样，业界也存在MQ协议，我们将其称之为AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。 AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全，其基本架构如下： 可以看出，AMQP协议主要分为3大部分： Producer: 消息生产者； Broker: 消息队列的服务实体； Exchange: 消息交换机，相当于消息的转发中心； Binding: 关系绑定，作用是建立Exchange与Queue的映射； Queue: 队列，消息的队列载体，每条消息都会由Exchange投递到一个或多个Queue中； Consumer: 消息消费者。 由于，RabbitMQ是AMQP的标准实现，下面我们通过RabbitMQ来具体讲解上述协议的各个组件。 QueueQueue（队列）是RabbitMQ的内部对象，用于存储消息，用下图表示： RabbitMQ中的消息都只能存储在Queue中，生产者（下图中的P）生产消息并最终投递到Queue中，消费者（下图中的C）可以从Queue中获取消息并消费。 多个消费者可以订阅同一个Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理。 这里可能会存在一个问题，就是假设同一个Queue的多个消费者对消息的处理速度不一致，就会出现有的消费者忙的不堪重负，而有的消费者则闲的一直喝茶，造成消费速度缓慢、系统资源浪费等问题。 为解决上述问题，RabbitMQ引入了Prefetch count参数，可以通过设置prefetchCount来限制Queue每次发送给每个消费者的消息数，比如我们设置prefetchCount=1，则Queue每次给每个消费者发送一条消息；消费者处理完这条消息后，Queue再给该消费者发送一条消息，从而实现了“能者多劳”。 可以看到，上面Producer将消息直接投递到Queue，然后Consumer去相应Queue去取数据，看起来问题不大，但上述模式下的生产者和消费者存在严重的耦合。 比如以下场景： ConsumerA和ConsumerB均想获取ProducerA发送的全部消息，由于Queue的特性，必须构建2个队列QueueA及QueueB，然后由Producer将数据分别投递到QueueA及QueueB。 假设后面又有一个ConsumerC想获取ProducerA发送的全部消息，此时，我们不但要创建一个QueueC，而且要修改Producer端的代码，使其将数据分别投递到QueueA、QueueB、QueueC。 此时，每来一个消费者，我们就得修改一次Producer端的代码，生产和消费紧耦合。 如何解耦呢，套用软件界有名的一句话： 12计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决！Any problem in computer science can be solved by another layer of indirection！ 所以，AMQP引入Exchange来将消息的Producer和Consumer解耦。 ExchangeAMQP 协议中的核心思想就是生产者和消费者的解耦，生产者从不直接将消息发送给队列。生产者通常不知道是否一个消息会被发送到队列中，只是将消息发送到一个交换机。先由 Exchange 来接收，然后 Exchange 按照特定的策略转发到 Queue 进行存储。Exchange 就类似于一个交换机，将各个消息分发到相应的队列中。 在实际应用中我们只需要定义好 Exchange 的路由策略，而生产者则不需要关心消息会发送到哪个 Queue 或被哪些 Consumer 消费。在这种模式下生产者只面向 Exchange 发布消息，消费者只面向 Queue 消费消息，Exchange 定义了消息路由到 Queue 的规则，将各个层面的消息传递隔离开，使每一层只需要关心自己面向的下一层，降低了整体的耦合度。 Binding及RoutingKeyBinding负责建立Exchange与Queue之间的映射，绑定需要依赖一个额外的参数:RoutingKey，Exchange根据RoutingKey与当前所有绑定的Binding匹配，若满足匹配，则往Exchange所绑定的Queue发送消息。 向RabbitMQ发送一次消息，可以将其分发到不同的Queue，而RoutingKey的意义依赖于Exchange的类型。 Exchange主要有三种类型：Fanout、Direct 和Topic。 Direct Exchange Direct Exchange是RabbitMQ默认的Exchange，完全根据RoutingKey来路由消息。设置Exchange和Queue的Binding时需指定RoutingKey（一般为Queue Name），发消息时也指定一样的RoutingKey，消息就会被路由到对应的Queue。 现在我们考虑只把重要的日志消息写入磁盘文件，例如只把Error级别的日志发送给负责记录写入磁盘文件的Queue。这种场景下我们可以使用指定的RoutingKey（例如 error）将写入磁盘文件的Queue绑定到Direct Exchange上。 Fanout Exchange Fanout Exchange会忽略RoutingKey的设置，直接将Message广播到所有绑定的Queue中。 以日志系统为例：假设我们定义了一个Exchange来接收日志消息，同时定义了两个Queue来存储消息：一个记录将被打印到控制台的日志消息；另一个记录将被写入磁盘文件的日志消息。我们希望Exchange接收到的每一条消息都会同时被转发到两个Queue，这种场景下就可以使用FanoutExchange来广播消息到所有绑定的Queue。 Topic Exchange Topic Exchange和Direct Exchange类似，也需要通过RoutingKey来路由消息，区别在于Direct Exchange对Routing Key是精确匹配，而Topic Exchange支持模糊匹配。分别支持和#通配符，表示匹配一个单词，#则表示匹配没有或者多个单词。 假设我们的消息路由规则除了需要根据日志级别来分发之外还需要根据消息来源分发，可以将RoutingKey定义为消息来源.级别如 order.info、user.error等。处理所有来源为user的Queue就可以通过user. 绑定到Topic Exchange上，而处理所有日志级别为info的Queue可以通过 .info 绑定到Exchange上。 除此以外，还有2种特殊的Exchange。 Headers ExchangeHeaders Exchange会忽略RoutingKey而根据消息中的Headers和创建绑定关系时指定的Arguments来匹配决定路由到哪些Queue。 Headers Exchange的性能比较差，而且Direct Exchange完全可以代替它，所以不建议使用。 Default ExchangeDefault Exchange是一种特殊的Direct Exchange。当你手动创建一个队列时，后台会自动将这个队列绑定到一个名称为空的Direct Exchange 上，绑定RoutingKey与队列名称相同。有了这个默认的交换机和绑定，使我们只关心队列这一层即可，这个比较适合做一些简单的应用。 相当于直接往Queue里发送消息。 参考文献： 1.https://www.sojson.com/blog/48.html2.https://blog.csdn.net/y4x5M0nivSrJaY3X92c/article/details/80416996#]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>基础</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何正确使用RabbitMQ]]></title>
    <url>%2F2019%2F10%2F25%2F%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8RabbitMQ%2F</url>
    <content type="text"><![CDATA[在介绍RabbitMQ的使用之前，我们再具体阐述RabbitMQ里面的一些相关参数，有利于以后使用过程中排坑。 首先，深入聊一下Queues: QueuesRabbitMQ的Queue存储着Consumer待消费的消息，其与Exchange基于Binding Key进行绑定，除了Binding相关参数外，Queue还有以下重要属性： name 队列名支持最多255字节的UTF-8字符。应用程序在声明队列的时候可以自己指定队列名，或者当应用程序指定name属性为空时，代理（broker）会自动地为其生成一个唯一的队列名。 需要注意的是，以”amq.”开头的队列名是由AMQP内部使用的命名前缀，请开发者不要使用，否则将抛出403异常。 durability durability属性对应两种情况，分别是durable（持久的）和transient（短暂的）。durable类型的队列会持久化至硬盘上，所以当代理（broker）重启之后，它依然存在。相反地，当代理重启之后，transient类型的队列就消失了。 需要注意的是，队列的持久化是相对队列而言，对存储在持久化队列中的消息来说，当代理重启之后：队列还存在、消息则不存在。 所以，当broker重启之后，如果想让消息仍然存在，这就是消息持久化机制干的事了，后面再说消息属性的相关内容。 Queue创建需要注意的是，队列在使用之前必须先声明。声明之前，如果该队列不存在，那么声明之后就会创建一个队列；如果该队列已经存在了，并且声明的队列与存在的队列属性相同，则不产生任何影响；如果该队列已经存在了，但是声明的队列与存在的队列属性不同，则会抛出一个错误码为406（PRECONDITION_FAILED）的异常。 Binding队列获取来自交换器的消息的前提是该队列必须先与交换器进行绑定。绑定之后，交换器才能将消息按照特定的规则，路由至相应的队列中去。随后，消费者才能从队列中消费消息。 如果生产者生产的某条消息，没有与之匹配的任何一个队列可供路由（比如，没有任何队列与交换器绑定）。那么，根据该条消息的属性，该消息要么丢弃，要么返回至生产者。 连接及通道连接AMQP是一个应用层协议，并且是基于TCP可靠传输的应用层协议。除此之外，AMQP也提供了加密传输的机制（使用TSL或SSL），让消息传递更加安全。 当需要断开AMQP代理时，正确的做法是关闭AMQP连接，而不是粗鲁的直接断开其底层的TCP连接。 通道有的应用程序需要与AMQP broker建立多个连接。在AMQP模型中，我们不需要通过建立太多的TCP连接来实现。假如针对每一个AMQP连接都建立一个TCP连接的话，会占用大量的系统资源。对此，AMQP提供了通道（channel）机制。即，共享一个TCP连接，可创建多个通道。 在多线程/进程的应用程序中正确做法是，对于每一个线程/进程，应分别建立一个通道，而不是多个线程/进程之间去共享一个通道。 虚拟机AMQP使用了虚拟机的概念，在一个broker上面划分出多个隔离的环境（各环境下的用户、交换器以及队列等互不影响）。这样一来，AMQP客户端们在进行连接的时候，需要协商指定同一个vhost才能进行正常的往来业务。 Message接下来，看一下消息的生产、传输、消费相关的机制。 Message acknowledgements试想一下这个问题：如果消费者应用程序在处理某个消息的时候突然奔溃了，那么这条消息该何去何从？再进一步的说，AMQP消息代理要在什么时候将某条消息从队列中移除？对此，AMQP给出了两种处理办法：一是，当消息代理（broker）将一条消息发送给消费者应用程序之后就将其从队列中移除；二是，当消费者应用程序返还一条确认信息之后（类似于TCP三次握手中的ack确认）就将其从队列中移除。 第一种处理方法是自动确认的，称为automatic acknowledgement；第二种处理方法则需要由消费者进行确认操作，称为explicit acknowledgement。针对第二种处理方法，消费者在何时返回ack也是比较灵活的。比如，消费者可以在接收到消息的第一时间就返回一个ack，或者在将消息持久化到硬盘之后返回ack，又或者在消息完全处理完之后返回ack。 如果一个接收到消息的消费者在没有返回ack之前就挂掉了，那么，AMQP消息代理将会将这条消息发送给其他能匹配上的消费者。但是，若没有任何消费者能够匹配上这条消息，AMQP代理将会一直等待，直到有能匹配上的消费者出现，再将该消息投递给它。 Rejecting messages消费者应用程序在处理消息失败时，应用程序可以通知broker：消息处理失败，拒绝消息。当拒绝消息时，消费者应用程序可以要求broker丢弃或重新发送该消息。 Prefetching messages多个消费者从一个队列中消费消息时，可以指定每个消费者在返回下一个ack之前，每次发送给他们的消息数量，即预取消息的数量。这可以当做一个简单的负载均衡技术来使用， 也可以在批量生产消息的情景下提高吞吐量。 Message attributes and payloadAMQP模型中的消息实体各种属性，比如： content type content encoding routing key delivery mode(persistent or not) message priority message publish timestamp expiration period publisher application id等。 消息的属性是在消息被生产时设置的。 AMQP消息除了属性之外还有一个有效负载（可以理解为消息体，即它携带的数据），AMQP视这些负载数据为一个不透明的字节数组。并且，AMQP代理不会去窥探和改变这些负载的数据。对于这些负载的数据，你可以使用例如JSON这样的序列化格式来存储。 如果将消息属性设置为持久化，AMQP代理将会将这些持久化的消息写入磁盘，这可以保证当服务重启之后，消息不会丢失。 仍需要啰嗦的一点是：如果仅仅将一个消息生产到一个持久化的交换器，或者将这条消息路由到一个持久化的队列中去，并不能使这个消息本身变成持久化消息。消息的持久化与否主要取决于消息本身的属性设置。 参考资料： http://dulishu.top/rabbitmq-amqp/ http://www.rabbitmq.com/tutorials/amqp-concepts.html]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>基础</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下安装MongoDB]]></title>
    <url>%2F2019%2F10%2F24%2FCentos%E4%B8%8B%E5%AE%89%E8%A3%85MongoDB%2F</url>
    <content type="text"><![CDATA[查看MongoDB的版本，到https://www.mongodb.com/download-center#community下，选择Community Server后选择linux，之后再选择对应版本。 如果装的是Amazon的，启动mongodb时会出现Error parsing INI config file: unrecognised option ‘nohttpinterface’ 错误，所以选择RHEL版本。 1weget http://downloads.mongodb.org/linux/mongodb-linux-x86_64-rhel70-latest.tgz 解压 1tar -zvxf mongodb-linux-x86_64-rhel70-latest.tgz 创建数据库目录 12mkdir -p /usr/local/software/mongodb/dbmkdir -p /usr/local/software/mongodb/log 创建配置文件mongodb.conf 12345678910设置数据文件的存放目录 dbpath = /usr/local/software/mongodb/db 设置日志文件的存放目录及其日志文件名 logpath = /usr/local/software/mongodb/log/mongodb.log 设置端口号（默认的端口号是 27017） port = 27017 设置为以守护进程的方式运行，即在后台运行 fork = true 关闭http接口，默认关闭27018端口访问 nohttpinterface = true 启动 123456# 命令行启动mongod --dbpath=/usr/local/software/mongodb/db --logpath=/usr/local/software/mongodb/log/mongodb.log &amp;# 配置文件启动./mongod --config mongodb.conf# 守护进程启动mongod --dbpath=/usr/local/software/mongodb/db --logpath=/usr/local/software/mongodb/log/mongodb.log --fork --port 27017]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch入门]]></title>
    <url>%2F2019%2F10%2F24%2FElasticsearch%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[数据对象一个文档不仅仅包含它的数据 ，也包含元数据——有关文档的信息。 三个必须的元数据元素如下： _index 文档在哪存放 。一个索引应该是因共同的特性被分组到一起的文档集合。索引名必须小写，不能以下划线开头，不能包含逗号； _type 文档表示的对象类别； _id 文档唯一标识。 Elasticsearch 支持 RESTFUL 风格 API，其 API 基本格式如下： 1http://&lt;ip&gt;:&lt;port&gt;/&lt;索引&gt;/&lt;类型&gt;/&lt;文档id&gt; 创建/删除索引123post http://&lt;ip&gt;:&lt;port&gt;/index/type/id # 手动指定id或者post http://&lt;ip&gt;:&lt;port&gt;/index/type # es自动生成id 请记住， _index 、 _type 和 _id 的组合可以唯一标识一个文档。所以，确保创建一个新文档的最简单办法是，使用索引请求的 POST 形式让 Elasticsearch 自动生成唯一 _id : 如果已经有自己的 _id ，那么我们必须告诉 Elasticsearch ，只有在相同的 _index 、 _type 和 _id 不存在时才接受我们的索引请求。 123post http://&lt;ip&gt;:&lt;port&gt;/index/type/id?op_type=createpost http://&lt;ip&gt;:&lt;port&gt;/index/type/id/_create 如果创建新文档的请求成功执行，Elasticsearch 会返回元数据和一个 201 Created 的 HTTP 响应码。 另一方面，如果具有相同的 _index 、 _type 和 _id 的文档已经存在，Elasticsearch 将会返回 409 Conflict 响应码，以及如下的错误信息： 12345678910111213141516171819&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[employee][1]: version conflict, document already exists (current version [4])&quot;, &quot;index_uuid&quot;: &quot;lo-6VdTHQWKAYVuMu3djQg&quot;, &quot;shard&quot;: &quot;3&quot;, &quot;index&quot;: &quot;megacorp&quot; &#125; ], &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[employee][1]: version conflict, document already exists (current version [4])&quot;, &quot;index_uuid&quot;: &quot;lo-6VdTHQWKAYVuMu3djQg&quot;, &quot;shard&quot;: &quot;3&quot;, &quot;index&quot;: &quot;megacorp&quot; &#125;, &quot;status&quot;: 409&#125; 删除一个索引，需要使用 DELETE 请求。 1delete http://&lt;ip&gt;:&lt;port&gt;/index/type/id 插入数据put请求。 查找数据 GET方式简单搜索 查询指定ID的数据，使用 GET 请求。 查询id是1的雇员信息，执行： 1[GET] http://39.106.195.92:9200/megacorp/employee/1 返回结果： 12345678910111213141516&#123; &quot;_index&quot;: &quot;megacorp&quot;, &quot;_type&quot;: &quot;employee&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, //表示文档被找到 &quot;_source&quot;: &#123; &quot;first_name&quot;: &quot;Douglas&quot;, &quot;last_name&quot;: &quot;Fir&quot;, &quot;age&quot;: 35, &quot;about&quot;: &quot;I like to build cabinets&quot;, &quot;interests&quot;: [ &quot;forestry&quot; ] &#125;&#125; 查询文档的一部分（只查询名字）: 1[GET] http://39.106.195.92:9200/megacorp/employee/1?_source=first_name,last_name 查询所有信息，不指定id，使用_search,执行： 1[GET] http://39.106.195.92:9200/megacorp/employee/_search 按条件查询，仍然在请求路径中使用 _search 端点，并将查询本身赋值给参数 q= ，执行： 1[GET] http://39.106.195.92:9200/megacorp/employee/_search?q=last_name:Smith 查询文档是否存在，把GET方式换位HEAD方式就可以了，HEAD 请求没有返回体，只返回一个 HTTP 请求报头： 存在返回200，否在返回404。 POST方式搜索 GET条件查询的方式虽然方便，但有很大的局限性，ES提供了POST的方式查询语言–查询表达式，它支持构建更加复杂和健壮的查询。 POST方式的搜索url都相同，只是body不同: 1[POST] http://39.106.195.92:9200/megacorp/employee/_search 请求参数：使用 JSON 构造，并使用了一个 match 查询（属于查询类型之一,这里match不能匹配多个字段。匹配多个字段要使用multi_match ） 查找 last_name= “Smith”： 1234567&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;last_name&quot; : &quot;Smith&quot; //只能写一个 &#125; &#125;&#125; 复杂的搜索 使用过滤器filter搜索姓氏为 Smith 的雇员 且年龄大于30，使用的是range过滤器，其中 gt 表示_大于 ： 12345678910111213141516&#123; &quot;query&quot; : &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match&quot; : &#123; &quot;last_name&quot; : &quot;smith&quot; &#125; &#125;, &quot;filter&quot;: &#123; &quot;range&quot; : &#123; &quot;age&quot; : &#123; &quot;gt&quot; : 30 &#125; &#125; &#125; &#125; &#125;&#125; 全文搜索 使用match全文搜索，Elasticsearch 默认按照相关性得分排序，即每个文档跟查询的匹配程度: 1234567&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;about&quot; : &quot;rock climbing&quot; &#125; &#125;&#125; 短语搜索 使用match_phrase短语搜索（准确搜索） 1234567&#123; &quot;query&quot; : &#123; &quot;match_phrase&quot; : &#123; &quot;about&quot; : &quot;rock climbing&quot; &#125; &#125;&#125; 高亮搜索 123456789101112&#123; &quot;query&quot; : &#123; &quot;match_phrase&quot; : &#123; &quot;about&quot; : &quot;rock climbing&quot; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot; : &#123; &quot;about&quot; : &#123;&#125; &#125; &#125;&#125; 分析 Elasticsearch 有一个功能叫聚合（aggregations），允许我们基于数据生成一些精细的分析结果。聚合与 SQL 中的 GROUP BY 类似但更强大。 挖掘出雇员中最受欢迎的兴趣爱好： 1234567&#123; &quot;aggs&quot;: &#123; &quot;all_interests&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;interests&quot; &#125; &#125; &#125;&#125; mget批量查询 1234567891011121314151617[POST] http://39.106.195.92:9200/_mget&#123; &quot;docs&quot; : [ &#123; &quot;_index&quot; : &quot;megacorp&quot;, &quot;_type&quot; : &quot;employee&quot;, &quot;_id&quot; : 2 &#125;, &#123; &quot;_index&quot; : &quot;website&quot;, //没有索引的话，会报错搜索不到该索引的内容 &quot;_type&quot; : &quot;employee&quot;, &quot;_id&quot; : 1, &quot;_source&quot;: &quot;age&quot; &#125; ]&#125; 更新数据 文档全部更新 123456789101112131415[PUT] http://39.106.195.92:9200/megacorp/employee/1&#123; &quot;_index&quot;: &quot;megacorp&quot;, &quot;_type&quot;: &quot;employee&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 3, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: false //这里变成了false,表示是更新&#125; 文档部分更新 1[POST] http://39.106.195.92:9200/megacorp/employee/1/_update 请求参数： 12345&#123; &quot;doc&quot;: &#123; &quot;age&quot;: &quot;88&quot; &#125;&#125; es的并发控制在数据库领域中，有两种方法通常被用来确保并发更新时变更不会丢失： 悲观并发控制 这种方法被关系型数据库广泛使用，它假定有变更冲突可能发生，因此阻塞访问资源以防止冲突。 一个典型的例子是读取一行数据之前先将其锁住，确保只有放置锁的线程能够对这行数据进行修改。 乐观并发控制 Elasticsearch 中使用的这种方法假定冲突是不可能发生的，并且不会阻塞正在尝试的操作。 然而，如果源数据在读写当中被修改，更新将会失败。应用程序接下来将决定该如何解决冲突。 例如，可以重试更新、使用新的数据、或者将相关情况报告给用户。 lasticsearch 是分布式的。当文档创建、更新或删除时， 新版本的文档必须复制到集群中的其他节点。Elasticsearch 也是异步和并发的，这意味着这些复制请求被并行发送，并且到达目的地时也许 顺序是乱的 。 Elasticsearch 需要一种方法确保文档的旧版本不会覆盖新的版本。 当我们之前讨论 index ， GET 和 delete 请求时，我们指出每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。 Elasticsearch 使用这个 _version 号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略。 我们可以利用 _version 号来确保 应用中相互冲突的变更不会导致数据丢失。我们通过指定想要修改文档的 version 号来达到这个目的。 如果该版本不是当前版本号，我们的请求将会失败。]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark与Springboot的集成]]></title>
    <url>%2F2019%2F10%2F23%2FSpark%E4%B8%8ESpringboot%E7%9A%84%E9%9B%86%E6%88%90%2F</url>
    <content type="text"><![CDATA[项目配置pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spark-springboot&lt;/artifactId&gt; &lt;groupId&gt;com.ruanshubin.spark&lt;/groupId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;spark-demo&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--ELK系统--&gt; &lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;5.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--kafka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ElasticSearch--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--服务监控--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.postgresql&lt;/groupId&gt; &lt;artifactId&gt;postgresql&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--spark--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-catalyst_2.11&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-resources&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/conf&lt;/outputDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;includeScope&gt;runtime&lt;/includeScope&gt; &lt;excludeScope&gt;provided,test&lt;/excludeScope&gt; &lt;excludeArtifactIds&gt;junit,dbunit,mockito-all&lt;/excludeArtifactIds&gt; &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt; &lt;outputDirectory&gt; $&#123;project.build.directory&#125;/lib &lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;finalName&gt;tcd-data-manager-1.0-jar-with-dependencies&lt;/finalName&gt; &lt;keepDependenciesWithProvidedScope&gt;true&lt;/keepDependenciesWithProvidedScope&gt; &lt;createDependencyReducedPom&gt;true&lt;/createDependencyReducedPom&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;artifactSet&gt; &lt;excludes&gt; &lt;exclude&gt;org.apache.spark:*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/artifactSet&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.springframework.boot.maven.PropertiesMergingResourceTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.factories&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.tooling&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot;/&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;mainClass&gt;xxx.xxx.xxx.Application&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;descriptors&gt; &lt;descriptor&gt;src/assembly/assembly.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; assembly.xml123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;assembly xmlns=&quot;http://maven.apache.org/ASSEMBLY/2.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd&quot;&gt; &lt;id&gt;build&lt;/id&gt; &lt;formats&gt; &lt;format&gt;tar.gz&lt;/format&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;directory&gt;target&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;*dependencies.jar&lt;/include&gt; &lt;include&gt;/conf/**&lt;/include&gt; &lt;/includes&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;directoryMode&gt;0755&lt;/directoryMode&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 部署自定义Spark的依赖包 启动Spark任务时，在没有配置spark.yarn.archive或者spark.yarn.jars时， 会看到不停地上传jar，非常耗时；使用spark.yarn.archive可以大大地减少任务的启动时间；同时，也可以在不污染原有spark环境的前提下，解决包冲突的问题。整个处理过程如下: 在本地创建zip文件 12hzlishuming@hadoop691:~/env/spark$ cd jars/hzlishuming@hadoop691:~/env/spark$ zip spark2.1.1-hadoop2.7.3.zip ./* 上传至HDFS并更改权限 123hzlishuming@hadoop691:~/env/spark$ /usr/ndp/current/hdfs_client/bin/hdfs dfs -mkdir /tmp/spark-archivehzlishuming@hadoop691:~/env/spark$ /usr/ndp/current/hdfs_client/bin/hdfs dfs -put ./spark2.1.1-hadoop2.7.3.zip /tmp/spark-archivehzlishuming@hadoop691:~/env/spark$ /usr/ndp/current/hdfs_client/bin/hdfs dfs -chmod 775 /tmp/spark-archive/spark2.1.1-hadoop2.7.3.zip 配置spark-defaut.conf 1spark.yarn.archive hdfs:///tmp/spark-archive/spark2.1.1-hadoop2.7.3.zip 也可以在提交任务的时候指定： 1234567891011121314151617./bin/spark-submit \--class xxx.xxx.xxx.Application \--name XXXApplication \--master yarn \--deploy-mode cluster \--queue root.root \--driver-cores 1 \--driver-memory 2g \--executor-cores 4 \--executor-memory 2g \--num-executors 4 \--driver-java-options &apos;-XX:MaxDirectMemorySize=128M -XX:NewRatio=1 -XX:SurvivorRatio=8 -XX:TargetSurvivorRatio=90 -XX:MaxTenuringThreshold=8 -XX:+UseConcMarkSweepGC -XX:ConcGCThreads=4 -XX:ParallelGCThreads=4 -XX:+CMSScavengeBeforeRemark -XX:PretenureSizeThreshold=64m -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=50 -XX:CMSMaxAbortablePrecleanTime=6000 -XX:+CMSParallelRemarkEnabled -XX:+ParallelRefProcEnabled -XX:-OmitStackTraceInFastThrow&apos; \--files hdfs://&#123;ip&#125;:&#123;port&#125;/xxx/xxx/xxx/bootstrap.yml,hdfs://&#123;ip&#125;:&#123;port&#125;/xxx/xxx/xxx/logback.xml \--conf spark.yarn.driver.memoryOverhead=1024 \--conf spark.yarn.executor.memoryOverhead=384 \--conf spark.yarn.archive=hdfs://&#123;ip&#125;:&#123;port&#125;/spark/yarn/spark2.4.0-hadoop2.6.0.zip \hdfs://&#123;ip&#125;:&#123;port&#125;/apps/xxx-jar-with-dependencies.jar 冲突包解决当Spark的jars目录下的相关jar包与应用中的依赖jar包冲突时，程序会报类找不到的Error。 12345678910111213141516# spark中需要替换的jar包snakeyaml-1.15.jar --&gt; snakeyaml-1.19.jarvalidation-api-1.1.0.Final.jar --&gt; validation-api-2.0.1.Final.jargson-2.2.4.jar --&gt; gson-2.8.5.jar# 日志相关apache-log4j-extras-1.2.17.jar --&gt; log4j-over-slf4j-1.7.23.jarcommons-logging-1.1.3.jar --&gt; logback-access-1.2.1.jarlog4j-1.2.17.jar --&gt; logback-classic-1.2.1.jarslf4j-log4j12-1.7.16.jar --&gt; logback-core-1.2.1.jar# Swagger相关guava-14.0.1.jar --&gt; guava-20.0.jar# hadoop需要替换的包(不一定需要)rm -rf /usr/lib/LOCALCLUSTER/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jarSwagger上yarn的话，需要将SwaggerHeaderFilter的配置删除掉，否则拉取不到配置。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive入门]]></title>
    <url>%2F2019%2F10%2F22%2FHive%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[环境搭建Mysql安装 处理系统环境 1234567891011rpm -qa | grep mariadbrpm -e --nodeps mariadb-libs-5.5.56-2.el7.x86_64# 暂时没有用到groupadd mysqluseradd -g mysql mysql -d /home/mysqlpasswd mysqlmkdir /home/mysql/3306/datamkdir -p /home/mysql/3306/logmkdir -p /home/mysql/3306/tmp Mysql安装 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111tar -xvf mysql-8.0.13-1.el7.x86_64.rpm-bundle.tar rpm -ivh mysql-community-common-8.0.13-1.el7.x86_64.rpm rpm -ivh mysql-community-libs-8.0.13-1.el7.x86_64.rpm rpm -ivh mysql-community-client-8.0.13-1.el7.x86_64.rpm rpm -ivh mysql-community-server-8.0.13-1.el7.x86_64.rpm service mysqld statusservice mysqld start# 获取初始密码grep &apos;temporary password&apos; /var/log/mysqld.log# 若在log文件中找不到初始密码# 说明原来的mysql未删除干净rm -rf /var/lib/mysqlsystemctl restart mysqld# 修改密码等级 + 修改密码[root@tcd-test ~]# mysql -u root -pEnter password: 初始密码Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 8Server version: 8.0.13Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; set global validate_password.policy=0;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global validate_password.length=6;Query OK, 0 rows affected (0.00 sec)mysql&gt; ALTER USER root@localhost IDENTIFIED BY &apos;123456&apos;;Query OK, 0 rows affected (0.11 sec)mysql&gt; show global variables like &apos;%validate_password%&apos;;+--------------------------------------+-------+| Variable_name | Value |+--------------------------------------+-------+| validate_password.check_user_name | ON || validate_password.dictionary_file | || validate_password.length | 6 || validate_password.mixed_case_count | 1 || validate_password.number_count | 1 || validate_password.policy | LOW || validate_password.special_char_count | 1 |+--------------------------------------+-------+7 rows in set (0.08 sec)# 此时，只支持host为localhost连接，需要修改远程连接权限mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select user, host, authentication_string from user;+------------------+-----------+------------------------------------------------------------------------+| user | host | authentication_string |+------------------+-----------+------------------------------------------------------------------------+| mysql.infoschema | localhost | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED || mysql.session | localhost | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED || mysql.sys | localhost | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED || root | localhost | $A$005$MBKK=R,oircXwk~2HHEqJ6ko9c/Lx1iVMERob7DXAoWi6bXyC0w19dJLnQx9 |+------------------+-----------+------------------------------------------------------------------------+4 rows in set (0.00 sec)mysql&gt; update user set host = &quot;%&quot; where user=&apos;root&apos;;Query OK, 1 row affected (0.09 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select user, host, authentication_string from user;+------------------+-----------+------------------------------------------------------------------------+| user | host | authentication_string |+------------------+-----------+------------------------------------------------------------------------+| root | % | $A$005$MBKK=R,oircXwk~2HHEqJ6ko9c/Lx1iVMERob7DXAoWi6bXyC0w19dJLnQx9 || mysql.infoschema | localhost | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED || mysql.session | localhost | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED || mysql.sys | localhost | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED |+------------------+-----------+------------------------------------------------------------------------+4 rows in set (0.00 sec)mysql&gt; grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; with grant option;Query OK, 0 rows affected (0.13 sec)或者：GRANT ALL ON *.* TO &apos;root&apos;@&apos;%&apos;; # 两个在不同机器上都成功过，但是不能同时成功，都试一下吧。# Navicat连接linux上的mysql报2059 Authentication plugin &apos;caching_sha2_password&apos;cannot be loaded# 从mysql5.7版本之后，默认采用了caching_sha2_password验证方式。# 在linux服务器中，开启mysql，并进入连接的数据库执行如下语句，表示采用原来的身份验证机制。mysql&gt; ALTER USER &apos;root&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;123456&apos;;mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select user, host, authentication_string , plugin from user;+------------------+-----------+------------------------------------------------------------------------+-----------------------+| user | host | authentication_string | plugin |+------------------+-----------+------------------------------------------------------------------------+-----------------------+| root | % | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 | mysql_native_password || mysql.infoschema | localhost | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED | caching_sha2_password || mysql.session | localhost | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED | caching_sha2_password || mysql.sys | localhost | $A$005$THISISACOMBINATIONOFINVALIDSALTANDPASSWORDTHATMUSTNEVERBRBEUSED | caching_sha2_password |+------------------+-----------+------------------------------------------------------------------------+-----------------------+4 rows in set (0.00 sec) Hive安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475vim /etc/profileexport HIVE_HOME=/usr/software/hive/apache-hive-2.3.4-binexport PATH=$PATH:$HIVE_HOME/binsource /etc/profile# 此时执行hive的show databases会报错，是从Hive 2.1版本开始,我们需要先运行schematool 命令来执行初始化操作schematool -dbType derby -initSchema# 启动hive之前请确保hadoop启动起来# 使用默认数据库derby，执行hive的show databases仍然会报错，未解决。# 试着用mysql数据库cp hive-env.sh.template hive-env.shcp hive-default.xml.template hive-site.xmlvim hive-site.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hive.default.fileformat&lt;/name&gt; &lt;value&gt;TextFile&lt;/value&gt; &lt;description&gt;Default file format for CREATE TABLE statement. Options are TextFile and SequenceFile. Users can explicitly say CREATE TABLE ... STORED AS &amp;lt;TEXTFILE|SEQUENCEFILE&amp;gt; to override&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt; &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;description&gt;username to use against metastore database&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;123456&lt;/value&gt; &lt;description&gt;password to use against metastore database&lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt;vim hive-env.shHADOOP_HOME=/usr/software/hadoop2.8.5/hadoop-2.8.5export HIVE_CONF_DIR=/usr/software/hive/apache-hive-2.3.4-bin/confexport HIVE_AUX_JARS_PATH=/usr/software/hive/apache-hive-2.3.4-bin/lib# 将mysql连接jar放到/hive/lib下# 初始化mysql数据库schematool -dbType mysql -initSchemaschematool -dbType postgres -initSchemahive&gt; show databases;Loading class `com.mysql.jdbc.Driver&apos;. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver&apos;. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.OKdefaultTime taken: 9.951 seconds, Fetched: 1 row(s)# 存在一个默认数据库default,但是在hdfs中并没有/user/hive/warehouse，这个目录属于顶层目录，即数据仓库；# 此时，在hive shell中create database test;# 此时，/user/hive/warehouse会被创建，并有test.db文件 hive in spark123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081配置步骤：1.复制postgresql-42.2.5.jar文件到spark home路径下jars文件夹中2. 使用hadoop fs命令创建hive数仓目录/usr/lib/LOCALCLUSTER/SERVICE-HADOOP-ec48e21ba173412995c6eff698cca573/bin/hadoop fs -mkdir -p /hive/warehouse3. spark 配置路径下配置hive-site.xml文件配置内容参考当前目录下hive-site.xml3.在postgresql中新建名为hivedb的数据库；（hivedb是在hive-site.xml文件中配置的）验证配置是否正确1. 以yran-client模式启动hive thriftserver：$Spark-Home/sbin/start-thriftserver.sh \--master yarn-client \--driver-cores 1 \--conf spark.driver.memory=2G \--queue root.jobs \--num-executors 2 \--executor-memory 2g \--conf spark.yarn.executor.memoryOverhead=1024./start-thriftserver.sh \--master yarn-client \--driver-cores 2 \--conf spark.driver.memory=1G \--queue root.jobs \--num-executors 2 \--executor-memory 1g \--conf spark.yarn.executor.memoryOverhead=10242. 使用beeline工具操作数据库：$Spark-Home/bin/beeline3. 之后执行：!connect jdbc:hive2://10.194.224.112:10000连续回车即可----------------------------------------------SQL 建表操作1. 使用CSV等文本格式存储create table test (id int , name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;|&apos; STORED AS TEXTFILE ;INSERT INTO test VALUES(1,&apos;a&apos;);2. 使用ORC格式存储数据create table if not exists test_orc( id string, name string, comment string) STORED AS ORC;INSERT INTO test_orc VALUES(1,&apos;a&apos;,&apos;abc&apos;);3. 使用parquet格式存储数据create table if not exists test_parquet( id string, name string, comment string) STORED AS PARQUET;INSERT INTO test_parquet VALUES(1,&apos;a&apos;,&apos;abc&apos;);--------------------------------------------使用insert语句添加数据，一句insert语句就会生成一个文件，大量的小文件会严重拖慢sparkSQL的查询性能，因此需要定期对文件进行合并。创建表后hdfs会生成相应目录，外部程序通过将规定格式的文件写入hdfs对应目录下，hive就可以查询到对应数据。注意：上面的方式创建的是hive内部表，当执行drop table table_name;语句时，hdfs上关联的数据目录将会被删除。如果创建外部表则在drop table后hdfs数据目录不会被删除。创建外部表方式如下：create external table if not exists external_test_parquet( id string, name string, comment string) stored as parquet location &apos;/hive/warehouse/external_test_parquet&apos;;其中指定的目录为hdfs路径。 数据处理表类型 Hive 是一个建立在hadoop文件系统上的数据仓库架构，可以用其对hdfs上数据进行分析与管理； 实际上是将hdfs上的文件映射成table（按文件格式创建table,然后hive的数据仓库会生成对应的目录，默认的仓库路径：user/hive/warehouse/tablename，目录名与这个表名相同，这时只要将符合table定义的文件加载到该目录便可通过Hql对整个目录的文件进行查询； 将数据加载到该目录可以用hdfs dfs -put 命令直接添加到该目录； 也可以通过load data local inpath ‘user/test.txt’ into table tableName,通过load命令加载数据与通过put命令加载文件的结果是一样的，即在user/hive/warehouse/tablename 目录下都会有加载进来的文件，如果用load命令加载的是hdfs上的文件则会将原hdfs目录下对应的文件移动至hive的仓库目录下）,并将这些元数据保存到关系型数据库中，元数据存储着表所对应的文件路径，表的列与分区，表创建时间，文件大小等属性； 同时支持用户运用类sql对文件进行操作，这个操作主要是查询。 hive的数据模型中有4种表： 1234Table内部表 External Table 外部表Partition分区表 Bucket Table 桶表]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Zeppline进行hive表的查询]]></title>
    <url>%2F2019%2F10%2F22%2F%E5%9F%BA%E4%BA%8EZeppline%E8%BF%9B%E8%A1%8Chive%E8%A1%A8%E7%9A%84%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[zeppelin是一个让交互式数据分析变得可行的基于网页的notebook;前端提供了精美的数据可视化功能;后台提供各种大数据组件的解析器，可以操作hive、sparkSQL、rdbms、es等大数据组件。 hive数据仓库数据无法使用传统数据库连接工具查看，因此可以借助zeppelin查看hive数仓数据。 配置步骤 下载zeppelin： https://mirrors.tuna.tsinghua.edu.cn/apache/zeppelin/zeppelin-0.8.0/zeppelin-0.8.0-bin-all.tgz 修改配置文件 解压后修改配置文件: conf目录中: cp zeppelin-site.xml.template zeppelin-site.xml cp zeppelin-env.sh.template zeppelin-env.sh cp shiro.ini.template shiro.ini 将hive的依赖包拷贝到 interpreter/jdbc 目录下: 1cp $Spark-Home/jars /tools/zeppeline/zeppelin-0.8.0-bin-all/interpreter/jdbc 启动bin/zeppelin-daemon.sh start 浏览器访问 8080 使用shiro.ini中配置的用户名密码登录 创建hive interpreter 1234# create--填写Interpreter Name--Interpreter group选择jdbc# 在配置里增加两项内容default.driver：org.apache.hive.jdbc.HiveDriverdefault.url：jdbc:hive2://&#123;ip&#125;:10000 创建notebook并使用hive interpreter]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yarn的基本架构]]></title>
    <url>%2F2019%2F10%2F21%2FYarn%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[基本流程1.应用程序通client类向ResourceManager提交程序，Application运行所需要的入口类，出口类，运行的命令，运行所需要的cpu资源和内存资源，jar包资源。 2.ResourceManager通过内部的调度器，去集群中寻找资源，找到资源后与NodeManager进行通信，去启动相应的ApplicationMaster,AM会按照事先的规划将任务切分为许多的task任务。 3.ApplicationMaster之后向ResourceManager进行申请资源，RM会将资源进行动态的分配。 4.ApplicationMaster获得资源后会再将资源进一步分配给内部的task. 5.之后，ApplicationMaster会向NodeManager进行请求，让NM给启动起来Task,NM会把Task封装到Container中允许。 ResourceManager整个集群只有一个，负责集群资源的统一管理和调度。 处理客户端请求 启动监控ApplicationMaster 监控NodeManager 资源分配与调度 用户交互YARN分别针对普通用户，管理员和Web提供了三种对外服务，分别对应ClientRMService、AdminService和WebApp： ClientRMService ClientRMService是为普通用户提供的服务，它会处理来自客户端各种RPC请求，比如提交应用程序、终止应用程序，获取应用程序运行状态等。 AdminService YARN为管理员提供了一套独立的服务接口，以防止大量的普通用户请求使管理员发送的管理命令饿死，管理员可通过这些接口管理集群，比如动态更新节点列表，更新ACL列表，更新队列信息等。 WebApp 为了更加友好地展示集群资源使用情况和应用程序运行状态等信息，YARN对外提供了一个Web 界面，这一部分是YARN仿照haml（http://haml.info/）开发的一个轻量级嵌入式Web框架。具体讨论见：https://issues.apache.org/jira/browse/MAPREDUCE-2399 NM管理 NMLivelinessMonitor 监控NM是否活着，如果一个NodeManager在一定时间（默认为10min）内未汇报心跳信息，则认为它死掉了，会将其从集群中移除。 NodesListManager 维护正常节点和异常节点列表，管理exlude（类似于黑名单）和inlude（类似于白名单）节点列表，这两个列表均是在配置文件中设置的，可以动态加载。 ResourceTrackerService 处理来自NodeManager的请求，主要包括两种请求：注册和心跳，其中，注册是NodeManager启动时发生的行为，请求包中包含节点ID，可用的资源上限等信息，而心跳是周期性 行为，包含各个Container运行状态，运行的Application列表、节点健康状况（可通过一个脚本设置），而ResourceTrackerService则为NM返回待释放的Container列表、Application列表等。 AM管理 AMLivelinessMonitor 监控AM是否活着，如果一个ApplicationMaster在一定时间（默认为10min）内未汇报心跳信息，则认为它死掉了，它上面所有正在运行的Container将被认为死亡，AM本身会被重新分配到另外一个节点上（用户可指定每个ApplicationMaster的尝试次数，默认是1次）执行。 ApplicationMasterLauncher 与NodeManager通信，要求它为某个应用程序启动ApplicationMaster。 ApplicationMasterService 处理来自ApplicationMaster的请求，主要包括两种请求：注册和心跳，其中，注册是ApplicationMaster启动时发生的行为，包括请求包中包含所在节点，RPC端口号和tracking URL等信息，而心跳是周期性 行为，包含请求资源的类型描述、待释放的Container列表等，而AMS则为之返回新分配的Container、失败的Container等信息。 Application管理 ApplicationACLsManager 管理应用程序访问权限，包含两部分权限：查看和修改，查看主要指查看应用程序基本信息，而修改则主要是修改应用程序优先级、杀死应用程序等。 RMAppManager 管理应用程序的启动和关闭。 ContainerAllocationExpirer YARN不允许AM获得Container后长时间不对其使用，因为这会降低整个集群的利用率。当AM收到RM新分配的一个Container后，必须在一定的时间（默认为10min）内在对应的NM上启动该Container， 否则，RM会回收该Container。 安全管理ResourceManage自带了非常全面的权限管理机制，主要由ClientToAMSecretManager、ContainerTokenSecretManager、ApplicationTokenSecretManager等模块完成。 资源分配ResourceScheduler是资源调度器，它按照一定的约束条件（比如队列容量限制等）将集群中的资源分配给各个应用程序，当前主要考虑内存资源，在3.0版本中将会考虑CPU（https://issues.apache.org/jira/browse/YARN-2）。ResourceScheduler是一个插拔式模块，默认是FIFO实现，YARN还提供了Fair Scheduler和Capacity Scheduler两个多租户调度器。 参考资料：http://hortonworks.com/blog/apache-hadoop-yarn-resourcemanager/ NodeManager整个集群存在多个，负责单节点资源管理与使用。 处理来自ResourceManager的命令 处理来自ApplicationMaster的命令 ApplicationMaster每一个应用有一个，负责应用程序的管理。 数据切分，申请资源，任务监控，任务容错。 Container对任务环境的抽象。 封装了CPU、Memory等资源的一个容器，相当于是一个任务运行环境的抽象。 Yarn的容错性ResourceManager存在单点故障，基于Zookeeper实现HA,通常任务失败后，RM将失败的任务告诉AM,RM负责任务的重启,AM来决定如何处理失败的任务。RMAppMaster会保存已经运行完成的Task,重启后无需重新运行。 Yarn资源调度框架与调度器Yarn采用的双层调度框架，RM将资源分配给AM,AM再将资源进一步分配给Task,资源不够时会为TASK预留，直到资源充足。在Hadoop1.0中我们分配资源通过slot实现，但是在Yarn中，直接分配资源。 资源调度器有：FIFO,Fair scheduler,Capacity scheduler Yarn支持CPU和内存两种资源隔离，内存是决定生死的资源，CPU是影响快慢的资源，内存隔离采用的是基于线程监控和基于Cgroup的方案。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yarn的调度器--Scheduler探究]]></title>
    <url>%2F2019%2F10%2F21%2FYarn%E7%9A%84%E8%B0%83%E5%BA%A6%E5%99%A8--Scheduler%E6%8E%A2%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[引言在Yarn体系中，Scheduler负责为Application分配资源，按照调度策略可分为以下3种： FIFO Scheduler Capacity Scheduler Fair Scheduler 下面具体介绍上述3种调度器： FIFO Scheduler顾名思义，该调度器是按照应用的提交顺序分配资源的，先进先出，优先满足先到达的应用，待前面的应用所需资源满足后再分配后面的应用。 在共享集群模式下，该模式会存在应用饥饿问题，即小应用会被前面的大应用阻塞，当前面存在某个大应用耗尽所有资源，会导致后续的应用永远得不到执行。 Capacity Scheduler概述由引言中的图易知，Capacity调度器将整个集群的资源分为多个Queue，每个Queue可占用一定的集群资源，应用可提交到指定的Queue上，在每个Queue内部，执行的仍然是FIFO策略。 当某个Queue因为被提交了多个Application而导致资源告急时，Capacity调度器扔可能分配部分资源给当前队列，但前提是其他队列有剩余，或其他队列释放了某些Container资源。 为避免某队列占用过多的空闲资源，导致其他队列无法使用这些空闲资源，建议设置队列的最大资源使用量。 配置Capacity Schduler是YARN中默认的资源调度器。 在Capacity Scheduler的配置文件中，队列queueX的参数Y的配置名称为yarn.scheduler.capacity.queueX.Y，为了简单起见，我们记为Y，则每个队列可以配置的参数如下： 资源分配相关参数 capacity 队列的资源容量（百分比）。 当系统非常繁忙时，应保证每个队列的容量得到满足，而如果每个队列应用程序较少，可将剩余资源共享给其他队列。注意，所有队列的容量之和应小于100。 maximum-capacity 队列的资源使用上限（百分比）。由于存在资源共享，因此一个队列使用的资源量可能超过其容量，而最多使用资源量可通过该参数限制。 minimum-user-limit-percent 每个用户最低资源保障（百分比）。任何时刻，一个队列中每个用户可使用的资源量均有一定的限制。当一个队列中同时运行多个用户的应用程序时中，每个用户的使用资源量在一个最小值和最大值之间浮动，其中，最小值取决于正在运行的应用程序数目，而最大值则由minimum-user-limit-percent决定。比如，假设minimum-user-limit-percent为25。当两个用户向该队列提交应用程序时，每个用户可使用资源量不能超过50%，如果三个用户提交应用程序，则每个用户可使用资源量不能超多33%，如果四个或者更多用户提交应用程序，则每个用户可用资源量不能超过25%。 user-limit-factor 每个用户最多可使用的资源量（百分比）。比如，假设该值为30，则任何时刻，每个用户使用的资源量不能超过该队列容量的30%。 限制应用程序数目相关参数 maximum-applications 集群或者队列中同时处于等待和运行状态的应用程序数目上限，这是一个强限制，一旦集群中应用程序数目超过该上限，后续提交的应用程序将被拒绝，默认值为10000。所有队列的数目上限可通过参数yarn.scheduler.capacity.maximum-applications设置（可看做默认值），而单个队列可通过参数yarn.scheduler.capacity..maximum-applications设置适合自己的值。 maximum-am-resource-percent 集群中用于运行应用程序ApplicationMaster的资源比例上限，该参数通常用于限制处于活动状态的应用程序数目。该参数类型为浮点型，默认是0.1，表示10%。所有队列的ApplicationMaster资源比例上限可通过参数yarn.scheduler.capacity. maximum-am-resource-percent设置（可看做默认值），而单个队列可通过参数yarn.scheduler.capacity.. maximum-am-resource-percent设置适合自己的值。 队列访问和权限控制参数 state 队列状态可以为STOPPED或者RUNNING，如果一个队列处于STOPPED状态，用户不可以将应用程序提交到该队列或者它的子队列中，类似的，如果ROOT队列处于STOPPED状态，用户不可以向集群中提交应用程序，但正在运行的应用程序仍可以正常运行结束，以便队列可以优雅地退出。 acl_submit_applications 限定哪些用户/用户组可向给定队列中提交应用程序。需要注意的是，该属性具有继承性，即如果一个用户可以向某个队列中提交应用程序，则它可以向它的所有子队列中提交应用程序。 acl_administer_queue 为队列指定一个管理员，该管理员可控制该队列的所有应用程序，比如杀死任意一个应用程序等。同样，该属性具有继承性，如果一个用户可以向某个队列中提交应用程序，则它可以向它的所有子队列中提交应用程序。 实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.maximum-applications&lt;/name&gt; &lt;value&gt;10000&lt;/value&gt; &lt;description&gt;最多可同时处于等待和运行状态的应用程序数目&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.maximum-am-resource-percent&lt;/name&gt; &lt;value&gt;0.1&lt;/value&gt; &lt;description&gt;集群中可用于运行application master的资源比例上限，这通常用于限制并发运行的应用程序数目。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt; &lt;value&gt;default&lt;/value&gt; &lt;description&gt;root队列的所有子队列，该实例中只有一个&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.default.capacity&lt;/name&gt; &lt;value&gt;100&lt;/value&gt; &lt;description&gt;default队列的资源容量&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.default.user-limit-factor&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;description&gt; 每个用户可使用的资源限制 &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.default.maximum-capacity&lt;/name&gt; &lt;value&gt;100&lt;/value&gt; &lt;description&gt; Default队列可使用的资源上限. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.default.state&lt;/name&gt; &lt;value&gt;RUNNING&lt;/value&gt; &lt;description&gt; Default队列的状态，可以是RUNNING或者STOPPED. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.default.acl_submit_applications&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;description&gt; 限制哪些用户可向default队列中提交应用程序. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.default.acl_administer_queue&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;description&gt; 限制哪些用户可管理default队列中的应用程序，“*”表示任意用户 &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.node-locality-delay&lt;/name&gt; &lt;value&gt;-1&lt;/value&gt; &lt;description&gt;调度器尝试调度一个rack-local container之前，最多跳过的调度机会，通常而言，该值被设置成集群中机架数目，默认情况下为-1，表示不启用该功能。 &lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; Fair Scheduler概述Fair调度器的设计目标是为所有的应用分配公平的资源（对公平的定义可以通过参数来设置），用户在各自队列运行中逐渐资源变得平分。 假如现在存在大、小2个任务，当提交大任务时，其会获取所有的系统资源，大任务执行期间，当小任务提交时，大任务会释放出一半数量的Container供小任务使用，待小任务执行完毕后，小任务会释放其所占有的资源，此时大任务重新获取到系统的所有资源。 因为小任务需要等待大任务释放出Container，所以从小任务提交到获取到资源会有一定的延迟，但确实值得的。 该种模式下，即保证了资源的高利用率又使得晚提交的小任务获得执行的机会，不至于饿死。 配置首先在yarn-site.xml中，将配置参数yarn.resourcemanager.scheduler.class设置为org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler。 Fair Scheduler的配置选项包括两部分，其中一部分在yarn-site.xml中，主要用于配置调度器级别的参数，另外一部分在一个自定义配置文件（默认是fair-scheduler.xml）中，主要用于配置各个队列的资源量、权重等信息。 yarn-site.xml yarn.scheduler.fair.allocation.file 自定义XML配置文件所在位置，该文件主要用于描述各个队列的属性，比如资源量、权重等，具体配置格式将在后面介绍。 yarn.scheduler.fair.user-as-default-queue 当应用程序未指定队列名时，是否指定用户名作为应用程序所在的队列名。如果设置为false或者未设置，所有未知队列的应用程序将被提交到default队列中，默认值为true。 yarn.scheduler.fair.preemption 是否启用抢占机制，默认值是false。 yarn.scheduler.fair.sizebasedweight 在一个队列内部分配资源时，默认情况下，采用公平轮询的方法将资源分配各各个应用程序，而该参数则提供了另外一种资源分配方式：按照应用程序资源需求数目分配资源，即需求资源数量越多，分配的资源越多。默认情况下，该参数值为false。 yarn.scheduler.assignmultiple 是否启动批量分配功能。当一个节点出现大量资源时，可以一次分配完成，也可以多次分配完成。默认情况下，该参数值为false。 yarn.scheduler.fair.max.assign 如果开启批量分配功能，可指定一次分配的container数目。默认情况下，该参数值为-1，表示不限制。 yarn.scheduler.fair.locality.threshold.node 当应用程序请求某个节点上资源时，它可以接受的可跳过的最大资源调度机会。当按照分配策略，可将一个节点上的资源分配给某个应用程序时，如果该节点不是应用程序期望的节点，可选择跳过该分配机会暂时将资源分配给其他应用程序，直到出现满足该应用程序需的节点资源出现。通常而言，一次心跳代表一次调度机会，而该参数则表示跳过调度机会占节点总数的比例，默认情况下，该值为-1.0，表示不跳过任何调度机会。 yarn.scheduler.fair.locality.threshold.rack 当应用程序请求某个机架上资源时，它可以接受的可跳过的最大资源调度机会。 yarn.scheduler.increment-allocation-mb 内存规整化单位，默认是1024，这意味着，如果一个Container请求资源是1.5GB，则将被调度器规整化为ceiling(1.5 GB / 1GB) * 1G=2GB。 yarn.scheduler.increment-allocation-vcores 虚拟CPU规整化单位，默认是1，含义与内存规整化单位类似。 自定义配置文件Fair Scheduler允许用户将队列信息专门放到一个配置文件（默认是fair-scheduler.xml），对于每个队列，管理员可配置以下选项： minResources 最少资源保证量，设置格式为“X mb, Y vcores”，当一个队列的最少资源保证量未满足时，它将优先于其他同级队列获得资源，对于不同的调度策略（后面会详细介绍），最少资源保证量的含义不同，对于fair策略，则只考虑内存资源，即如果一个队列使用的内存资源超过了它的最少资源量，则认为它已得到了满足；对于drf策略，则考虑主资源使用的资源量，即如果一个队列的主资源量超过它的最少资源量，则认为它已得到了满足。 maxResources 最多可以使用的资源量，fair scheduler会保证每个队列使用的资源量不会超过该队列的最多可使用资源量。 maxRunningApps 最多同时运行的应用程序数目。通过限制该数目，可防止超量Map Task同时运行时产生的中间输出结果撑爆磁盘。 minSharePreemptionTimeout 最小共享量抢占时间。如果一个资源池在该时间内使用的资源量一直低于最小资源量，则开始抢占资源。 schedulingMode/schedulingPolicy 队列采用的调度模式，可以是fifo、fair或者drf。 aclSubmitApps 可向队列中提交应用程序的用户列表，默认情况下为”*”，表示任何用户均可以向该队列提交应用程序。需要注意的是，该属性具有继承性，即子队列的列表会继承父队列的列表。 aclAdministerApps 该队列的管理员列表。一个队列的管理员可管理该队列中的资源和应用程序，比如可杀死任意应用程序。 管理员也可为单个用户添加maxRunningJobs属性限制其最多同时运行的应用程序数目。此外，管理员也可通过以下参数设置以上属性的默认值： userMaxJobsDefault 用户的maxRunningJobs属性的默认值。 defaultMinSharePreemptionTimeout 队列的minSharePreemptionTimeout属性的默认值。 defaultPoolSchedulingMode 队列的schedulingMode属性的默认值。 fairSharePreemptionTimeout 公平共享量抢占时间。如果一个资源池在该时间内使用资源量一直低于公平共享量的一半，则开始抢占资源。 实例假设要为一个Hadoop集群设置三个队列queueA、queueB和queueC，其中，queueB和queueC为queueA的子队列，且规定普通用户最多可同时运行40个应用程序，但用户userA最多可同时运行400个应用程序，那么可在自定义配置文件中进行如下设置： 1234567891011121314151617181920212223&lt;allocations&gt; &lt;queue name=”queueA”&gt; &lt;minResources&gt;100 mb, 100 vcores&lt;/minResources&gt; &lt;maxResources&gt;150 mb, 150 vcores&lt;/maxResources&gt; &lt;maxRunningApps&gt;200&lt;/maxRunningApps&gt; &lt;minSharePreemptionTimeout&gt;300&lt;/minSharePreemptionTimeout&gt; &lt;weight&gt;1.0&lt;/weight&gt; &lt;queue name=”queueB”&gt; &lt;minResources&gt;30 mb, 30 vcores&lt;/minResources&gt; &lt;maxResources&gt;50 mb, 50 vcores&lt;/maxResources&gt; &lt;/queue&gt; &lt;queue name=”queueC”&gt; &lt;minResources&gt;50 mb, 50 vcores&lt;/minResources&gt; &lt;maxResources&gt;50 mb, 50 vcores&lt;/maxResources&gt; &lt;/queue&gt; &lt;/queue&gt; &lt;user name=”userA”&gt; &lt;maxRunningApps&gt;400&lt;/maxRunningApps&gt; &lt;/user&gt; &lt;userMaxAppsDefault&gt;40&lt;/userMaxAppsDefault&gt; &lt;fairSharePreemptionTimeout&gt;6000&lt;/fairSharePreemptionTimeout&gt;&lt;/allocations&gt; 配置Example123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=&quot;1.0&quot;?&gt;&lt;allocations&gt; &lt;queue name=&quot;sample_queue&quot;&gt; &lt;minResources&gt;10000 mb,0vcores&lt;/minResources&gt; &lt;maxResources&gt;90000 mb,0vcores&lt;/maxResources&gt; &lt;maxRunningApps&gt;50&lt;/maxRunningApps&gt; &lt;maxAMShare&gt;0.1&lt;/maxAMShare&gt; &lt;!--设置权重 40%--&gt; &lt;weight&gt;2.0&lt;/weight&gt; &lt;!--调度策略--&gt; &lt;schedulingPolicy&gt;fair&lt;/schedulingPolicy&gt; &lt;queue name=&quot;sample_sub_queue&quot;&gt; &lt;aclSubmitApps&gt;charlie&lt;/aclSubmitApps&gt; &lt;minResources&gt;5000 mb,0vcores&lt;/minResources&gt; &lt;/queue&gt; &lt;queue name=&quot;sample_reservable_queue&quot;&gt; &lt;reservation&gt;&lt;/reservation&gt; &lt;/queue&gt; &lt;/queue&gt; &lt;queueMaxAMShareDefault&gt;0.5&lt;/queueMaxAMShareDefault&gt; &lt;queueMaxResourcesDefault&gt;40000 mb,0vcores&lt;/queueMaxResourcesDefault&gt; &lt;!-- Queue &apos;secondary_group_queue&apos; is a parent queue and may have user queues under it --&gt; &lt;queue name=&quot;secondary_group_queue&quot; type=&quot;parent&quot;&gt; &lt;!--设置权重 60%--&gt; &lt;weight&gt;3.0&lt;/weight&gt; &lt;maxChildResources&gt;4096 mb,4vcores&lt;/maxChildResources&gt; &lt;/queue&gt; &lt;user name=&quot;sample_user&quot;&gt; &lt;maxRunningApps&gt;30&lt;/maxRunningApps&gt; &lt;/user&gt; &lt;userMaxAppsDefault&gt;5&lt;/userMaxAppsDefault&gt; &lt;queuePlacementPolicy&gt; &lt;!--若提交的任务指定了队列名，则放入指定队列--&gt; &lt;rule name=&quot;specified&quot; /&gt; &lt;!--尝试将任务提交到名称为用户名的队列，若不存在与当前用户名相同的队列，则转入下一个规则--&gt; &lt;rule name=&quot;primaryGroup&quot; create=&quot;false&quot; /&gt; &lt;rule name=&quot;nestedUserQueue&quot;&gt; &lt;rule name=&quot;secondaryGroupExistingQueue&quot; create=&quot;false&quot; /&gt; &lt;/rule&gt; &lt;!--前面均不匹配，则放入默认队列sample_queue--&gt; &lt;rule name=&quot;default&quot; queue=&quot;sample_queue&quot;/&gt; &lt;/queuePlacementPolicy&gt;&lt;/allocations&gt; 抢占Fair调度器支持抢占，抢占就是允许调度器杀掉占用超过其应占份额资源队列的containers，这些containers资源便可被分配到应该享有这些份额资源的队列中。需要注意抢占会降低集群的执行效率，因为被终止的containers需要被重新执行。 可以通过设置一个全局的参数yarn.scheduler.fair.preemption=true来启用抢占功能。 参考文献: https://www.jianshu.com/p/8738acc89bd4 http://www.imooc.com/article/253999]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yarn的资源配置参数]]></title>
    <url>%2F2019%2F10%2F21%2FYarn%E7%9A%84%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[YARN的资源调度主要针对的是内存(Memory)和CPU，并将其组合抽象成Container来管理分配。 在YARN中，资源管理由ResourceManager和NodeManager共同完成，其中，ResourceManager中的调度器负责资源的分配，而NodeManager则负责资源的供给和隔离。ResourceManager将某个NodeManager上资源分配给任务（这就是所谓的“资源调度”）后，NodeManager需按照要求为任务提供相应的资源，甚至保证这些资源应具有独占性，为任务运行提供基础的保证，这就是所谓的资源隔离。 在正式介绍具体的资源调度和隔离之前，先品味一下内存和CPU这两种资源的特点，这是两种性质不同的资源。内存资源的多少会会决定任务的生死，如果内存不够，任务可能会运行失败；相比之下，CPU资源则不同，它只会决定任务运行的快慢，不会对生死产生影响。 Memory配置计算单台机器的Container上限值1containers = min (2*CORES, 1.8*DISKS, (Total available RAM) / MIN_CONTAINER_SIZE) 其中： CORES: 机器CPU核数 DISKS: 机器上挂载的磁盘个数 Total available RAM: 机器总内存 MIN_CONTAINER_SIZE: Container最小的容量大小 MIN_CONTAINER_SIZE主要与机器可用的RAM有关： 单台机器可用RAM Container最小值 &lt;4GB 256MB 4GB-8GB 512MB 8GB-24GB 1024MB &gt;24GB 2048MB YARN配置(内存相关) yarn.nodemanager.resource.memory-mb 表示该节点上YARN可使用的物理内存总量，默认是8192（MB）。 注意，如果你的节点内存资源不够8GB，则需要调减小这个值，而YARN不会智能的探测节点的物理内存总量。 yarn.nodemanager.vmem-pmem-ratio 任务每使用1MB物理内存，最多可使用虚拟内存量，默认是2.1。 yarn.nodemanager.pmem-check-enabled 是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true。 yarn.nodemanager.vmem-check-enabled 是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true。 yarn.scheduler.minimum-allocation-mb 单个container可申请的最少物理内存量，默认是1024（MB），如果一个任务申请的物理内存量少于该值，则该对应的值改为这个数。 yarn.scheduler.maximum-allocation-mb 单个container可申请的最少物理内存量，默认是1024（MB），如果一个任务申请的物理内存量少于该值，则该对应的值改为这个数。 默认情况下，YARN采用了线程监控的方法判断任务是否超量使用内存，一旦发现超量，则直接将其杀死。由于Cgroups对内存的控制缺乏灵活性（即任务任何时刻不能超过内存上限，如果超过，则直接将其杀死或者报OOM），而Java进程在创建瞬间内存将翻倍，之后骤降到正常值，这种情况下，采用线程监控的方式更加灵活（当发现进程树内存瞬间翻倍超过设定值时，可认为是正常现象，不会将任务杀死），因此YARN未提供Cgroups内存隔离机制。 CPU配置在YARN中使用的是虚拟CPU，虚拟CPU是YARN自己引入的概念，初衷是，考虑到不同节点的CPU性能可能不同，每个CPU具有的计算能力也是不一样的，比如某个物理CPU的计算能力可能是另外一个物理CPU的2倍，这时候，你可以通过为第一个物理CPU多配置几个虚拟CPU弥补这种差异。用户提交作业时，可以指定每个任务需要的虚拟CPU个数。在YARN中，CPU相关配置参数如下： YARN配置(CPU相关) yarn.nodemanager.resource.cpu-vcores 表示该节点上YARN可使用的虚拟CPU个数，默认是8，注意，目前推荐将该值设值为与物理CPU核数数目相同。 如果你的节点CPU核数不够8个，则需要调减小这个值，而YARN不会智能的探测节点的物理CPU总数。 yarn.scheduler.minimum-allocation-vcores 单个任务可申请的最小虚拟CPU个数，默认是1，如果一个任务申请的CPU个数少于该数，则该对应的值改为这个数。 yarn.scheduler.maximum-allocation-vcores 单个任务可申请的最多虚拟CPU个数，默认是32。 默认情况下，YARN是不会对CPU资源进行调度的，你需要配置相应的资源调度器来支持。 资源划分方式默认情况下，NodeManager不会对CPU资源进行任何隔离，你可以通过启用Cgroups让你支持CPU隔离。 由于CPU资源的独特性，目前这种CPU分配方式仍然是粗粒度的。举个例子，很多任务可能是IO密集型的，消耗的CPU资源非常少，如果此时你为它分配一个CPU，则是一种严重浪费，你完全可以让他与其他几个任务公用一个CPU，也就是说，我们需要支持更粒度的CPU表达方式。 借鉴亚马逊EC2中CPU资源的划分方式，即提出了CPU最小单位为EC2 Compute Unit（ECU），一个ECU代表相当于1.0-1.2 GHz 2007 Opteron or 2007 Xeon处理器的处理能力。YARN提出了CPU最小单位YARN Compute Unit（YCU），目前这个数是一个整数，默认是720，由参数yarn.nodemanager.resource.cpu-ycus-per-core设置，表示一个CPU core具备的计算能力（该feature在2.2.0版本中并不存在，可能增加到2.3.0版本中），这样，用户提交作业时，直接指定需要的YCU即可，比如指定值为360，表示用1/2个CPU core，实际表现为，只使用一个CPU core的1/2计算时间。注意，在操作系统层，CPU资源是按照时间片分配的，你可以说，一个进程使用1/3的CPU时间片，或者1/5的时间片。 参考文献： http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-memory-cpu-scheduling/]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lambda架构]]></title>
    <url>%2F2019%2F10%2F20%2FLambda%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[引言Lambda架构是由Storm的作者Nathan Marz提出的一个实时大数据处理框架。Marz在Twitter工作期间开发了著名的实时大数据处理框架Storm，Lambda架构是其根据多年进行分布式大数据系统的经验总结提炼而成。 Lambda架构的目标是设计出一个能满足实时大数据系统关键特性的架构，包括有：高容错、低延时和可扩展等。Lambda架构整合离线计算和实时计算，融合不可变性（Immunability），读写分离和复杂性隔离等一系列架构原则，可集成Hadoop，Kafka，Storm，Spark，Hbase等各类大数据组件。 Lambda架构如何实时地在任意大数据集上进行查询？大数据再加上实时计算，问题的难度比较大。 最简单的方法是，根据前述的查询等式Query = Function(All Data)，在全体数据集上在线运行查询函数得到结果。但如果数据量比较大，该方法的计算代价太大了，所以不现实。 Lambda架构通过分解的三层架构来解决该问题：Batch Layer，Speed Layer和Serving Layer。 Batch LayerBatch Layer的功能主要有两点： 存储数据集 在数据集上预先计算查询函数，构建查询所对应的View 储存数据集根据前述对数据When&amp;What特性的讨论，Batch Layer采用不可变模型存储所有的数据。因为数据量比较大，可以采用HDFS之类的大数据储存方案。如果需要按照数据产生的时间先后顺序存放数据，可以考虑如InfluxDB之类的时间序列数据库（TSDB）存储方案。 构建查询View上面说到根据等式Query = Function(All Data)，在全体数据集上在线运行查询函数得到结果的代价太大。但如果我们预先在数据集上计算并保存查询函数的结果，查询的时候就可以直接返回结果（或通过简单的加工运算就可得到结果）而无需重新进行完整费时的计算了。这儿可以把Batch Layer看成是一个数据预处理的过程。我们把针对查询预先计算并保存的结果称为View，View是Lamba架构的一个核心概念，它是针对查询的优化，通过View即可以快速得到查询结果。 如果采用HDFS来储存数据，我们就可以使用MapReduce来在数据集上构建查询的View。Batch Layer的工作可以简单的用如下伪码表示： 该工作看似简单，实质非常强大。任何人为或机器发生的错误，都可以通过修正错误后重新计算来恢复得到正确结果。 View是一个和业务关联性比较大的概念，View的创建需要从业务自身的需求出发。一个通用的数据库查询系统，查询对应的函数千变万化，不可能穷举。但是如果从业务自身的需求出发，可以发现业务所需要的查询常常是有限的。Batch Layer需要做的一件重要的工作就是根据业务的需求，考察可能需要的各种查询，根据查询定义其在数据集上对应的Views。 Speed LayerBatch Layer可以很好的处理离线数据，但有很多场景数据不断实时生成，并且需要实时查询处理。Speed Layer正是用来处理增量的实时数据。 Speed Layer和Batch Layer比较类似，对数据进行计算并生成Realtime View，其主要区别在于： Speed Layer处理的数据是最近的增量数据流，Batch Layer处理的全体数据集 Speed Layer为了效率，接收到新数据时不断更新Realtime View，而Batch Layer根据全体离线数据集直接得到Batch View。 Lambda架构将数据处理分解为Batch Layer和Speed Layer有如下优点： 容错性 Speed Layer中处理的数据也不断写入Batch Layer，当Batch Layer中重新计算的数据集包含Speed Layer处理的数据集后，当前的Realtime View就可以丢弃，这也就意味着Speed Layer处理中引入的错误，在Batch Layer重新计算时都可以得到修正。这点也可以看成是CAP理论中的最终一致性（Eventual Consistency）的体现。 复杂性隔离 Batch Layer处理的是离线数据，可以很好的掌控。Speed Layer采用增量算法处理实时数据，复杂性比Batch Layer要高很多。通过分开Batch Layer和Speed Layer，把复杂性隔离到Speed Layer，可以很好的提高整个系统的鲁棒性和可靠性。 Serving LayerLambda架构的Serving Layer用于响应用户的查询请求，合并Batch View和Realtime View中的结果数据集到最终的数据集。 这儿涉及到数据如何合并的问题。前面我们讨论了查询函数的Monoid性质，如果查询函数满足Monoid性质，即满足结合率，只需要简单的合并Batch View和Realtime View中的结果数据集即可。否则的话，可以把查询函数转换成多个满足Monoid性质的查询函数的运算，单独对每个满足Monoid性质的查询函数进行Batch View和Realtime View中的结果数据集合并，然后再计算得到最终的结果数据集。另外也可以根据业务自身的特性，运用业务自身的规则来对Batch View和Realtime View中的结果数据集合并。 总结上面分别讨论了Lambda架构的三层：Batch Layer，Speed Layer和Serving Layer。下图给出了Lambda架构的一个完整视图和流程。 数据流进入系统后，同时发往Batch Layer和Speed Layer处理。Batch Layer以不可变模型离线存储所有数据集，通过在全体数据集上不断重新计算构建查询所对应的Batch Views。Speed Layer处理增量的实时数据流，不断更新查询所对应的Realtime Views。Serving Layer响应用户的查询请求，合并Batch View和Realtime View中的结果数据集到最终的数据集。 下图给出了Lambda架构中各个层常用的组件。数据流存储可选用基于不可变日志的分布式消息系统Kafka；Batch Layer数据集的存储可选用Hadoop的HDFS，或者是阿里云的ODPS；Batch View的预计算可以选用MapReduce或Spark；Batch View自身结果数据的存储可使用MySQL（查询少量的最近结果数据），或HBase（查询大量的历史结果数据）。Speed Layer增量数据的处理可选用Storm或Spark Streaming；Realtime View增量结果数据集为了满足实时更新的效率，可选用Redis等内存NoSQL。 Lambda架构是个通用框架，各个层选型时不要局限时上面给出的组件，特别是对于View的选型。从我对Lambda架构的实践来看，因为View是个和业务关联性非常大的概念，View选择组件时关键是要根据业务的需求，来选择最适合查询的组件。不同的View组件的选择要深入挖掘数据和计算自身的特点，从而选择出最适合数据和计算自身特点的组件，同时不同的View可以选择不同的组件。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yen算法详解]]></title>
    <url>%2F2019%2F10%2F19%2FYen%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[算法介绍转载自https://www.cnblogs.com/qq952693358/p/7354070.html，具体算法实现由ruanshubin完成。 算法背景K 最短路径问题是最短路径问题的扩展和变形。1959 年，霍夫曼(Hoffman) 和帕夫雷(Pavley)在论文中第一次提出k 最短路径问题。 k 最短路径问题通常包括两类：有限制的k 最短路问题和无限制的K 最短路问题。 前者要求最短路径集合不含有回路，而后者对所求得的最短路径集合无限制。 算法简介Yen’s算法是Yen 在1971 年提出的以其名字命名 的Yen 算法。Yen’s算法采用了递推法中的偏离路径算法思想，适用于非负权边的有向无环图结构。 算法思想算法可分为两部分，算出第1条最短路径P(1)，然后在此基础上依次依次算出其他的K-1条最短路径。在求P(i+1) 时，将P(i)上除了终止节点外的所有节点都视为偏离节点，并计算每个偏离节点到终止节点的最短路径，再与之前的P(i)上起始节点到偏离节点的路径拼接，构成候选路径，进而求得最短偏离路径。 算法实例 根据个人的理解，我归纳出了以下步骤： 调用K条最短路径算法，源C，目的H，K为3。B为偏离路径集合。 1.通过Dijkstra算法计算得到最短路径A^1：C-E-F-H，其中，花费为5，A[1] = C-E-F-H； 2.将A[1]作为迭代路径，进行第一次迭代： (1)以部分迭代路径(即A[1])C路径中，C点为起点，将C-E路径之间的权值设为无穷大，进行一次Dijkstra，得到路径A^2-1：C-D-F-H，花费为8，将A^2-1路径加入B； (2)以部分迭代路径(即A[1])C-E路径中，E为起点，将E-F路径之间的权值设为无穷大，进行一次Dijkstra，得到路径A^2-2：C-E-G-H，花费为7，将A^2-2路径加入B； (3)以部分迭代路径(即A[1])C-E-F路径中，F为起点，将F-H路径之间的权值设为无穷大，进行一次Dijkstra，得到路径A^2-3：C-E-F-G-H，花费为8，将A^2-3路径加入B； 迭代完成，B集合中有三条路径：C-D-F-H，C-E-G-H，C-E-F-G-H；选出花费最小的偏离路径C-E-G-H，A[2] = C-E-G-H，移出B集合。 3.将A[2]作为迭代路径，进行第二次迭代： (1)以部分迭代路径(即A[2])C路径中，C点为起点，将C-E路径之间的权值设为无穷大，进行一次Dijkstra，得到路径A^3-1：C-D-F-H，但B集合已存在该路径，故不存在偏移路径； (2)以部分迭代路径(即A[2])C-E路径中，E点为起点，将E-G、E-F路径之间的权值设为无穷大 (注意，这里设置两条路径的权值原因是这两条路径分别存在于A[1]和A[2]中)，进行一次Dijkstra，得到路径A^3-2：C-E-D-F-H，花费为8，将A^3-2加入B； (3)以部分迭代路径(即A[2])C-E-G路径中，G点为起点，将C-H路径之间的权值设为无穷大，不存在偏移路径。 迭代完成，B集合中有三条路径：C-D-F-H，C-E-F-G-H，C-E-D-F-H；由于三条路径花费均为8，则根据最小节点数进行判断，选出偏离路径C-D-F-H，A[3] = C-D-F-H。 此时，选出了三条最短路径，分别是： 12345A[1] = C-E-F-HA[2] = C-E-G-HA[3] = C-D-F-H 算法结束。以上过程均为个人理解，如果出现了偏差，请大家指出，谢谢！ 算法实现可以参考Github中的一个使用python实现KSP算法的repo：Yen’s K-Shortest Path Algorithm 然而经过测试，上述代码存在bug，在实际路网测试中经常出现”走回头路”的情况。 故ruanshubin基于NetworkX框架实现了Yen算法，并在荆州市实际路网上测试通过。 参考 K最短路径算法之Yen’s Algorithm Yen’s Algorithm 基于网络流量的SDN最短路径转发应用]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[何为Parquet格式]]></title>
    <url>%2F2019%2F10%2F15%2F%E4%BD%95%E4%B8%BAParquet%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[背景列式存储由于OLAP查询的特点，列式存储可以提升其查询性能，但是它是如何做到的呢？这就要从列式存储的原理说起，从图1中可以看到，相对于关系数据库中通常使用的行式存储，在使用列式存储时每一列的所有元素都是顺序存储的。由此特点可以给查询带来如下的优化： 查询的时候不需要扫描全部的数据，而只需要读取每次查询涉及的列，这样可以将I/O消耗降低N倍，另外可以保存每一列的统计信息(min、max、sum等)，实现部分的谓词下推。 由于每一列的成员都是同构的，可以针对不同的数据类型使用更高效的数据压缩算法，进一步减小I/O。 由于每一列的成员的同构性，可以使用更加适合CPU pipeline的编码方式，减小CPU的缓存失效。 嵌套数据格式通常我们使用关系数据库存储结构化数据，而关系数据库支持的数据模型都是扁平式的，而遇到诸如List、Map和自定义Struct的时候就需要用户自己解析，但是在大数据环境下，数据的来源多种多样，例如埋点数据，很可能需要把程序中的某些对象内容作为输出的一部分，而每一个对象都可能是嵌套的，所以如果能够原生的支持这种数据，查询的时候就不需要额外的解析便能获得想要的结果。例如在Twitter，他们一个典型的日志对象（一条记录）有87个字段，其中嵌套了7层，如下图。 随着嵌套格式的数据的需求日益增加，目前Hadoop生态圈中主流的查询引擎都支持更丰富的数据类型，例如Hive、SparkSQL、Impala等都原生的支持诸如struct、map、array这样的复杂数据类型，这样促使各种存储格式都需要支持嵌套数据格式。 Parquet存储格式Apache Parquet是Hadoop生态圈中一种新型列式存储格式，它可以兼容Hadoop生态圈中大多数计算框架(Mapreduce、Spark等)，被多种查询引擎支持（Hive、Impala、Drill等），并且它是语言和平台无关的。Parquet最初是由Twitter和Cloudera合作开发完成并开源，2015年5月从Apache的孵化器里毕业成为Apache顶级项目。 Parquet最初的灵感来自Google于2010年发表的Dremel论文，文中介绍了一种支持嵌套结构的存储格式，并且使用了列式存储的方式提升查询性能，在Dremel论文中还介绍了Google如何使用这种存储格式实现并行查询的，如果对此感兴趣可以参考论文和开源实现Drill。 数据模型Parquet支持嵌套的数据模型，类似于Protocol Buffers，每一个数据模型的schema包含多个字段，每一个字段有三个属性：重复次数、数据类型和字段名，重复次数可以是以下三种：required(只出现1次)，repeated(出现0次或多次)，optional(出现0次或1次)。每一个字段的数据类型可以分成两种：group(复杂类型)和primitive(基本类型)。例如Dremel中提供的Document的schema示例，它的定义如下： 1234567891011121314message Document &#123; required int64 DocId; optional group Links &#123; repeated int64 Backward; repeated int64 Forward; &#125; repeated group Name &#123; repeated group Language &#123; required string Code; optional string Country; &#125; optional string Url; &#125;&#125; 可以把这个Schema转换成树状结构，根节点可以理解为repeated类型，如图3。 可以看出在Schema中所有的基本类型字段都是叶子节点，在这个Schema中一共存在6个叶子节点，如果把这样的Schema转换成扁平式的关系模型，就可以理解为该表包含六个列。Parquet中没有Map、Array这样的复杂数据结构，但是可以通过repeated和group组合来实现的。由于一条记录中某一列可能出现零次或者多次，需要标示出哪些列的值构成一条完整的记录。这是由Striping/Assembly算法实现的。 由于Parquet支持的数据模型比较松散，可能一条记录中存在比较深的嵌套关系，如果为每一条记录都维护一个类似的树状结可能会占用较大的存储空间，因此Dremel论文中提出了一种高效的对于嵌套数据格式的压缩算法：Striping/Assembly算法。它的原理是每一个记录中的每一个成员值有三部分组成：Value、Repetition level和Definition level。value记录了该成员的原始值，可以根据特定类型的压缩算法进行压缩，两个level值用于记录该值在整个记录中的位置。对于repeated类型的列，Repetition level值记录了当前值属于哪一条记录以及它处于该记录的什么位置；对于repeated和optional类型的列，可能一条记录中某一列是没有值的，假设我们不记录这样的值就会导致本该属于下一条记录的值被当做当前记录的一部分，从而造成数据的错误，因此对于这种情况需要一个占位符标示这种情况。 通过Striping/Assembly算法，parquet可以使用较少的存储空间表示复杂的嵌套格式，并且通常Repetition level和Definition level都是较小的整数值，可以通过RLE算法对其进行压缩，进一步降低存储空间。 文件结构Parquet文件是以二进制方式存储的，是不可以直接读取和修改的，Parquet文件是自解析的，文件中包括该文件的数据和元数据。在HDFS文件系统和Parquet文件中存在如下几个概念： HDFS块(Block)：它是HDFS上的最小的副本单位，HDFS会把一个Block存储在本地的一个文件并且维护分散在不同的机器上的多个副本，通常情况下一个Block的大小为256M、512M等。 HDFS文件(File)：一个HDFS的文件，包括数据和元数据，数据分散存储在多个Block中。 行组(Row Group)：按照行将数据物理上划分为多个单元，每一个行组包含一定的行数，在一个HDFS文件中至少存储一个行组，Parquet读写的时候会将整个行组缓存在内存中，所以如果每一个行组的大小是由内存大的小决定的。 列块(Column Chunk)：在一个行组中每一列保存在一个列块中，行组中的所有列连续的存储在这个行组文件中。不同的列块可能使用不同的算法进行压缩。 页(Page)：每一个列块划分为多个页，一个页是最小的编码的单位，在同一个列块的不同页可能使用不同的编码方式。 通常情况下，在存储Parquet数据的时候会按照HDFS的Block大小设置行组的大小，由于一般情况下每一个Mapper任务处理数据的最小单位是一个Block，这样可以把每一个行组由一个Mapper任务处理，增大任务执行并行度。Parquet文件的格式如下图所示。 上图展示了一个Parquet文件的结构，一个文件中可以存储多个行组，文件的首位都是该文件的Magic Code，用于校验它是否是一个Parquet文件，Footer length存储了文件元数据的大小，通过该值和文件长度可以计算出元数据的偏移量，文件的元数据中包括每一个行组的元数据信息和当前文件的Schema信息。除了文件中每一个行组的元数据，每一页的开始都会存储该页的元数据，在Parquet中，有三种类型的页：数据页、字典页和索引页。数据页用于存储当前行组中该列的值，字典页存储该列值的编码字典，每一个列块中最多包含一个字典页，索引页用来存储当前行组下该列的索引，目前Parquet中还不支持索引页，但是在后面的版本中增加。 映射下推(Project PushDown)说到列式存储的优势，Project下推是无疑最突出的，它意味着在获取表中原始数据时只需要扫描查询中需要的列，由于每一列的所有值都是连续存储的，避免扫描整个表文件内容。 在Parquet中原生就支持Project下推，执行查询的时候可以通过Configuration传递需要读取的列的信息，这些列必须是Schema的子集，Parquet每次会扫描一个Row Group的数据，然后一次性得将该Row Group里所有需要的列的Cloumn Chunk都读取到内存中，每次读取一个Row Group的数据能够大大降低随机读的次数，除此之外，Parquet在读取的时候会考虑列是否连续，如果某些需要的列是存储位置是连续的，那么一次读操作就可以把多个列的数据读取到内存。 谓词下推(Predicate PushDown)在数据库之类的查询系统中最常用的优化手段就是谓词下推了，通过将一些过滤条件尽可能的在最底层执行可以减少每一层交互的数据量，从而提升性能，例如”select count(1) from A Join B on A.id = B.id where A.a &gt; 10 and B.b &lt; 100”SQL查询中，在处理Join操作之前需要首先对A和B执行TableScan操作，然后再进行Join，再执行过滤，最后计算聚合函数返回，但是如果把过滤条件A.a &gt; 10和B.b &lt; 100分别移到A表的TableScan和B表的TableScan的时候执行，可以大大降低Join操作的输入数据。 无论是行式存储还是列式存储，都可以在将过滤条件在读取一条记录之后执行以判断该记录是否需要返回给调用者，在Parquet做了更进一步的优化，优化的方法时对每一个Row Group的每一个Column Chunk在存储的时候都计算对应的统计信息，包括该Column Chunk的最大值、最小值和空值个数。通过这些统计值和该列的过滤条件可以判断该Row Group是否需要扫描。另外Parquet未来还会增加诸如Bloom Filter和Index等优化数据，更加有效的完成谓词下推。 在使用Parquet的时候可以通过如下两种策略提升查询性能：1、类似于关系数据库的主键，对需要频繁过滤的列设置为有序的，这样在导入数据的时候会根据该列的顺序存储数据，这样可以最大化的利用最大值、最小值实现谓词下推。2、减小行组大小和页大小，这样增加跳过整个行组的可能性，但是此时需要权衡由于压缩和编码效率下降带来的I/O负载。 项目组成Parquet仅仅是一种存储格式，它是语言、平台无关的，并且不需要和任何一种数据处理框架绑定，目前能够和Parquet适配的组件包括下面这些，可以看出基本上通常使用的查询引擎和计算框架都已适配，并且可以很方便的将其它序列化工具生成的数据转换成Parquet格式。 查询引擎: Hive, Impala, Pig, Presto, Drill, Tajo, HAWQ, IBM Big SQL 计算框架: MapReduce, Spark, Cascading, Crunch, Scalding, Kite 数据模型: Avro, Thrift, Protocol Buffers, POJOs Parquet项目由以下几个子项目组成: parquet-format项目由java实现，它定义了所有Parquet元数据对象，Parquet的元数据是使用Apache Thrift进行序列化并存储在Parquet文件的尾部。 parquet-format项目由java实现，它包括多个模块，包括实现了读写Parquet文件的功能，并且提供一些和其它组件适配的工具，例如Hadoop Input/Output Formats、Hive Serde(目前Hive已经自带Parquet了)、Pig loaders等。 parquet-compatibility项目，包含不同编程语言之间(JAVA和C/C++)读写文件的测试代码。 parquet-cpp项目，它是用于用于读写Parquet文件的C++库。 下图展示了Parquet各个组件的层次以及从上到下交互的方式。 Striping/Assembly算法上文介绍了Parquet的数据模型，在Document中存在多个非required列，由于Parquet一条记录的数据分散的存储在不同的列中，如何组合不同的列值组成一条记录是由Striping/Assembly算法决定的，在该算法中列的每一个值都包含三部分：value、repetition level和definition level。 Repetition Levels为了支持repeated类型的节点，在写入的时候该值等于它和前面的值在哪一层节点是不共享的。在读取的时候根据该值可以推导出哪一层上需要创建一个新的节点，例如对于这样的一个schema和两条记录。 1234567message nested &#123; repeated group leve1 &#123; repeated string leve2; &#125;&#125;r1:[[a,b,c,] , [d,e,f,g]]r2:[[h] , [i,j]] 计算repetition level值的过程如下： value=a是一条记录的开始，和前面的值(已经没有值了)在根节点(第0层)上是不共享的，所以repeated level=0. value=b它和前面的值共享了level1这个节点，但是level2这个节点上是不共享的，所以repeated level=2. 同理value=c, repeated level=2. value=d和前面的值共享了根节点(属于相同记录)，但是在level1这个节点上是不共享的，所以repeated level=1. value=h和前面的值不属于同一条记录，也就是不共享任何节点，所以repeated level=0. 根据以上的分析每一个value需要记录的repeated level值如下： 在读取的时候，顺序的读取每一个值，然后根据它的repeated level创建对象，当读取value=a时repeated level=0，表示需要创建一个新的根节点(新记录)，value=b时repeated level=2，表示需要创建一个新的level2节点，value=d时repeated level=1，表示需要创建一个新的level1节点，当所有列读取完成之后可以创建一条新的记录。本例中当读取文件构建每条记录的结果如下： 可以看出repeated level=0表示一条记录的开始，并且repeated level的值只是针对路径上的repeated类型的节点，因此在计算该值的时候可以忽略非repeated类型的节点，在写入的时候将其理解为该节点和路径上的哪一个repeated节点是不共享的，读取的时候将其理解为需要在哪一层创建一个新的repeated节点，这样的话每一列最大的repeated level值就等于路径上的repeated节点的个数（不包括根节点）。减小repeated level的好处能够使得在存储使用更加紧凑的编码方式，节省存储空间。 Definition Levels有了repeated level我们就可以构造出一个记录了，为什么还需要definition levels呢？由于repeated和optional类型的存在，可能一条记录中某一列是没有值的，假设我们不记录这样的值就会导致本该属于下一条记录的值被当做当前记录的一部分，从而造成数据的错误，因此对于这种情况需要一个占位符标示这种情况。 definition level的值仅仅对于空值是有效的，表示在该值的路径上第几层开始是未定义的，对于非空的值它是没有意义的，因为非空值在叶子节点是定义的，所有的父节点也肯定是定义的，因此它总是等于该列最大的definition levels。例如下面的schema。 1234567message ExampleDefinitionLevel &#123; optional group a &#123; optional group b &#123; optional string c; &#125; &#125;&#125; 它包含一个列a.b.c，这个列的的每一个节点都是optional类型的，当c被定义时a和b肯定都是已定义的，当c未定义时我们就需要标示出在从哪一层开始时未定义的，如下面的值： 由于definition level只需要考虑未定义的值，而对于repeated类型的节点，只要父节点是已定义的，该节点就必须定义（例如Document中的DocId，每一条记录都该列都必须有值，同样对于Language节点，只要它定义了Code必须有值），所以计算definition level的值时可以忽略路径上的required节点，这样可以减小definition level的最大值，优化存储。 完整实例本节我们使用Dremel论文中给的Document示例和给定的两个值r1和r2展示计算repeated level和definition level的过程，这里把未定义的值记录为NULL，使用R表示repeated level，D表示definition level。 参考https://www.cnblogs.com/ITtangtang/p/7681019.html]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字的计算机表达]]></title>
    <url>%2F2019%2F10%2F13%2F%E6%95%B0%E5%AD%97%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A1%A8%E8%BE%BE%2F</url>
    <content type="text"><![CDATA[大端和小端起源关于大端小端名词的由来，有一个有趣的故事，来自于Jonathan Swift的《格利佛游记》：Lilliput和Blefuscu这两个强国在过去的36个月中一直在苦战。战争的原因：大家都知道，吃鸡蛋的时候，原始的方法是打破鸡蛋较大的一端，可以那时的皇帝的祖父由于小时侯吃鸡蛋，按这种方法把手指弄破了，因此他的父亲，就下令，命令所有的子民吃鸡蛋的时候，必须先打破鸡蛋较小的一端，违令者重罚。然后老百姓对此法令极为反感，期间发生了多次叛乱，其中一个皇帝因此送命，另一个丢了王位，产生叛乱的原因就是另一个国家Blefuscu的国王大臣煽动起来的，叛乱平息后，就逃到这个帝国避难。据估计，先后几次有11000余人情愿死也不肯去打破鸡蛋较小的端吃鸡蛋。这个其实讽刺当时英国和法国之间持续的冲突。Danny Cohen一位网络协议的开创者，第一次使用这两个术语指代字节顺序，后来就被大家广泛接受。 什么是大端和小端举一个例子，比如数字0x12 34 56 78在内存中的表示形式。 1)大端模式：Big-Endian就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。 低地址 ——————————&gt; 高地址0x12 | 0x34 | 0x56 | 0x78 2)小端模式：Little-Endian就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。 低地址 ——————————&gt; 高地址0x78 | 0x56 | 0x34 | 0x12 3)下面是两个具体例子： 16bit宽的数0x1234在Little-endian模式（以及Big-endian模式）CPU内存中的存放方式（假设从地址0x4000开始存放）为： 内存地址 小端模式存放内容 大端模式存放内容 0x4000 0x34 0x12 0x4001 0x12 0x34 32bit宽的数0x12345678在Little-endian模式以及Big-endian模式）CPU内存中的存放方式（假设从地址0x4000开始存放）为： 内存地址 小端模式存放内容 大端模式存放内容 0x4000 0x78 0x12 0x4001 0x56 0x34 0x4002 0x34 0x56 0x4003 0x12 0x78 4)大端小端没有谁优谁劣，各自优势便是对方劣势： 小端模式 ：强制转换数据不需要调整字节内容，1、2、4字节的存储方式一样。大端模式 ：符号位的判定固定为第一个字节，容易判断正负。 为什么会有大小端模式之分呢？ 这是因为在计算机系统中，我们是以字节为单位的，每个地址单元都对应着一个字节，一个字节为8bit。但是在C语言中除了8bit的char之外，还有16bit的short型，32bit的long型（要看具体的编译器），另外，对于位数大于8位的处理器，例如16位或者32位的处理器，由于寄存器宽度大于一个字节，那么必然存在着一个如果将多个字节安排的问题。因此就导致了大端存储模式和小端存储模式。例如一个16bit的short型x，在内存中的地址为0x0010，x的值为0x1122，那么0x11为高字节，0x22为低字节。对于大端模式，就将0x11放在低地址中，即0x0010中，0x22放在高地址中，即0x0011中。小端模式，刚好相反。我们常用的X86结构是小端模式，而KEIL C51则为大端模式。很多的ARM，DSP都为小端模式。有些ARM处理器还可以由硬件来选择是大端模式还是小端模式。 如何判断机器的字节序通过JDK的NIO包中的Bits来说明： 123456789101112131415161718192021222324private static final ByteOrder byteOrder;static ByteOrder byteOrder() &#123; if (byteOrder == null) throw new Error(&quot;Unknown byte order&quot;); return byteOrder;&#125;static &#123; long a = unsafe.allocateMemory(8); try &#123; unsafe.putLong(a, 0x0102030405060708L); byte b = unsafe.getByte(a); switch (b) &#123; case 0x01: byteOrder = ByteOrder.BIG_ENDIAN; break; case 0x08: byteOrder = ByteOrder.LITTLE_ENDIAN; break; default: assert false; byteOrder = null; &#125; &#125; finally &#123; unsafe.freeMemory(a); &#125;&#125; 常见的字节序一般操作系统都是小端，而通讯协议是大端的。 常见CPU的字节序 Big Endian : PowerPC、IBM、SunLittle Endian : x86、DECARM既可以工作在大端模式，也可以工作在小端模式。 常见文件的字节序 Adobe PS – Big EndianBMP – Little EndianDXF(AutoCAD) – VariableGIF – Little EndianJPEG – Big EndianMacPaint – Big EndianRTF – Little Endian Java和所有的网络通讯协议都是使用Big-Endian的编码。 浮点数十进制转二进制如何将十进制转换成二进制浮点数呢, 先介绍一下十进制的浮点数 转换二进制的浮点数，分为两部分： 先将整数部分转换为二进制，将小数部分转换为二进制， 然后将整数部分与小数部分相加。以 20.3 转换为例， 20转换后变为 10100 0.3 要转换二进制，需要乘2, 乘完之后 取整数部分，然后用乘的结果减去整数部分， 然后 接着乘2, 直至最后没有小数或者小数出现循环, 即乘完. 20 = 10100 (二进制) 0.3 * 2= 0.6 (0) 0.6 * 2 = 1.2 (1) 0.2 * 2= 0.4 (0) 0.4 * 2 = 0.8 (0) 0.8 *2 = 1.6 (1) 计算到这里， 将再出现0.6,进入循环了，所以，结果 0.3 = 0.010011001…1001 所以20.3 = 10100.010011001…1001 (二进制). 2.二进制数转化为科学计数法 20.3 = 10100.010011001…1001 (二进制)=1.01000100110011E10…..（十进制科学计数）=1.01000100110011E100…..(二进制科学计数) 这里使用移位存储，对于float来说，指数位加上127，double位加上1023(这里指的是存储，在比较的时候要分别减去127和1023) 移位存储移位存储本质上是为了保证+0和-0的一致性。 以float指数部分的这8位来分析， 那么这8位组成的新的字节，我们来用下面的一串数字表示：0000 0000 首先，我们假设不使用移位存储技术，而是单单看看这个 8位组成的新字节，到底能表示多少个数： 0000 0000 -1111 1111 即0-255，一共256个数。 但是我们知道这8位数既要表示正数也要表示负数。 所以将左边第一位拿出来表示正负的符号： 第一个区间： 120 000 0000-0 111 1111 即+0 到127 这就是问题的所在:怎么会有两个0，一个正零，一个负零。 这时候使用移位存储：float使用127(0011 1111) 表示0 0+127=127 即 0000 0000 +0111 1111=0111 1111 表示1 1+127=128 即 0000 0001 +0111 1111=0111 1111 表示128 128+127=255 即 1000 0000+0111 1111=1111 1111 最大的正数，再大就要溢出了。 表示-1 -1+127=126=127-1 即 0111 1111-0000 0001=0111 1110 表示-1 -2+127=125=127-2 即 0111 1111-0000 0010=0111 1101 表示-127 -127+127=0 即0111 1111-0111 1111=0000 0000 最小的负数，再小就溢出了。]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存更新模式]]></title>
    <url>%2F2019%2F10%2F12%2F%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[缓存能解决的问题 提升性能 绝大多数情况下，select 是出现性能问题最大的地方。一方面，select 会有很多像 join、group、order、like 等这样丰富的语义，而这些语义是非常耗性能的；另一方面，大多 数应用都是读多写少，所以加剧了慢查询的问题。 分布式系统中远程调用也会耗很多性能，因为有网络开销，会导致整体的响应时间下降。为了挽救这样的性能开销，在业务允许的情况（不需要太实时的数据）下，使用缓存是非常必要的事情。 缓解数据库压力 当用户请求增多时，数据库的压力将大大增加，通过缓存能够大大降低数据库的压力。 缓存的适用场景 对于数据实时性要求不高 对于一些经常访问但是很少改变的数据，读明显多于写，适用缓存就很有必要。比如一些网站配置项。 对于性能要求高 比如一些秒杀活动场景。 缓存三种模式一般来说，缓存有以下三种模式： Cache Aside 更新模式 Read/Write Through 更新模式 Write Behind Caching 更新模式 通俗一点来讲就是，同时更新缓存和数据库（Cache Aside 更新模式）；先更新缓存，缓存负责同步更新数据库（Read/Write Through 更新模式）；先更新缓存，缓存定时异步更新数据库（Write Behind Caching 更新模式）。这三种模式各有优劣，可以根据业务场景选择使用。 Cache Aside 更新模式这是最常用的缓存模式了，具体的流程是： 失效：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从 cache 中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 注意我们上面所提到的，缓存更新时先更新数据库，然后在让缓存失效。那么为什么不是直接更新缓存呢？这里有一些缓存更新的坑，我们需要避免入坑。 避坑指南一先更新数据库，再更新缓存。这种做法最大的问题就是两个并发的写操作导致脏数据。如下图（以Redis和Mysql为例），两个并发更新操作，数据库先更新的反而后更新缓存，数据库后更新的反而先更新缓存。这样就会造成数据库和缓存中的数据不一致，应用程序中读取的都是脏数据。 避坑指南二先删除缓存，再更新数据库。这个逻辑是错误的，因为两个并发的读和写操作导致脏数据。如下图（以Redis和Mysql为例）。假设更新操作先删除了缓存，此时正好有一个并发的读操作，没有命中缓存后从数据库中取出老数据并且更新回缓存，这个时候更新操作也完成了数据库更新。此时，数据库和缓存中的数据不一致，应用程序中读取的都是原来的数据（脏数据）。 避坑指南三先更新数据库，再删除缓存。这种做法其实不能算是坑，在实际的系统中也推荐使用这种方式。但是这种方式理论上还是可能存在问题。如下图（以Redis和Mysql为例），查询操作没有命中缓存，然后查询出数据库的老数据。此时有一个并发的更新操作，更新操作在读操作之后更新了数据库中的数据并且删除了缓存中的数据。然而读操作将从数据库中读取出的老数据更新回了缓存。这样就会造成数据库和缓存中的数据不一致，应用程序中读取的都是原来的数据（脏数据）。 但是，仔细想一想，这种并发的概率极低。因为这个条件需要发生在读缓存时缓存失效，而且有一个并发的写操作。实际上数据库的写操作会比读操作慢得多，而且还要加锁，而读操作必需在写操作前进入数据库操作，又要晚于写操作更新缓存，所有这些条件都具备的概率并不大。但是为了避免这种极端情况造成脏数据所产生的影响，我们还是要为缓存设置过期时间。 Read/Write Through 更新模式在上面的 Cache Aside 更新模式中，应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。而在Read/Write Through 更新模式中，应用程序只需要维护缓存，数据库的维护工作由缓存代理了。 Read ThroughRead Through 模式就是在查询操作中更新缓存，也就是说，当缓存失效的时候，Cache Aside 模式是由调用方负责把数据加载入缓存，而 Read Through 则用缓存服务自己来加载。 Write ThroughWrite Through 模式和 Read Through 相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后由缓存自己更新数据库（这是一个同步操作）。 Write Behind Caching 更新模式Write Behind Caching 更新模式就是在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是直接操作内存速度快。因为异步，Write Behind Caching 更新模式还可以合并对同一个数据的多次操作到数据库，所以性能的提高是相当可观的。 但其带来的问题是，数据不是强一致性的，而且可能会丢失。另外，Write Behind Caching 更新模式实现逻辑比较复杂，因为它需要确认有哪些数据是被更新了的，哪些数据需要刷到持久层上。只有在缓存需要失效的时候，才会把它真正持久起来。 总结三种缓存模式的优缺点： Cache Aside 更新模式实现起来比较简单，但是需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。 Read/Write Through 更新模式只需要维护一个数据存储（缓存），但是实现起来要复杂一些。 Write Behind Caching 更新模式和Read/Write Through 更新模式类似，区别是Write Behind Caching 更新模式的数据持久化操作是异步的，但是Read/Write Through 更新模式的数据持久化操作是同步的。优点是直接操作内存速度快，多次操作可以合并持久化到数据库。缺点是数据可能会丢失，例如系统断电等。 缓存是通过牺牲强一致性来提高性能的。所以使用缓存提升性能，就是会有数据更新的延迟。这需要我们在设计时结合业务仔细思考是否适合用缓存。然后缓存一定要设置过期时间，这个时间太短太长都不好，太短的话请求可能会比较多的落到数据库上，这也意味着失去了缓存的优势。太长的话缓存中的脏数据会使系统长时间处于一个延迟的状态，而且系统中长时间没有人访问的数据一直存在内存中不过期，浪费内存。]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unsafe类详解]]></title>
    <url>%2F2019%2F09%2F25%2FUnsafe%E7%B1%BB%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Java 不能直接访问操作系统底层，而是通过本地方法来访问。Unsafe 类提供了硬件级别的原子操作。 Unsafe 类在 sun.misc 包下，不属于 Java 标准。很多 Java 的基础类库，包括一些被广泛使用的高性能开发库都是基于 Unsafe 类开发，比如 Netty、Hadoop、Kafka 等。 Unsafe 是用于在实质上扩展 Java 语言表达能力、便于在更高层（Java 层）代码里实现原本要在更低层（C 层）实现的核心库功能用的。 这些功能包括裸内存的申请/释放/访问，低层硬件的 atomic/volatile 支持，创建未初始化对象等。 它原本的设计就只应该被标准库使用，因此不建议在生产环境中使用。 获取实例Unsafe 对象不能直接通过 new Unsafe() 或调用 Unsafe.getUnsafe() 获取。 Unsafe 被设计成单例模式，构造方法私有。 getUnsafe 被设计成只能从引导类加载器（bootstrap class loader）加载。 1234567891011private Unsafe() &#123;&#125;public static Unsafe getUnsafe() &#123; Class var0 = Reflection.getCallerClass(2); if (var0.getClassLoader() != null) &#123; throw new SecurityException(&quot;Unsafe&quot;); &#125; else &#123; return theUnsafe; &#125;&#125; 非启动类加载器直接调用 Unsafe.getUnsafe() 方法会抛出 SecurityException 异常。 解决办法有两个: 令代码 “ 受信任 “ 运行程序时，通过 JVM 参数设置 bootclasspath 选项，指定系统类路径加上使用的一个 Unsafe 路径。 1java -Xbootclasspath:/usr/jdk1.7.0/jre/lib/rt.jar:. com.mishadoff.magic.UnsafeClient Java 反射机制 通过将 private 单例实例暴力设置 accessible 为 true，然后通过 Field 的 get 方法，直接获取一个 Object 强制转换为 Unsafe。 123Field f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);f.setAccessible(true);Unsafe unsafe = (Unsafe) f.get(null); 在 IDE 中，这些方法会被标志为 Error，可以通过以下设置解决： Preferences -&gt; Java -&gt; Compiler -&gt; Errors/Warnings -&gt; Deprecated and restricted API -&gt; Forbidden reference -&gt; Warning 常用方法Unsafe 的大部分 API 都是 native 的方法。 Classes/Objects创建类对象，不进行初始化： 12//实例化对象，但是不进行初始化，类初始化和实例初始化都不调用Object allocateInstance(Class&lt;?&gt; cls) 对象和字段的地址获取： 1234567//字段在内存中的地址相对于实例对象内存地址的偏移量public long objectFieldOffset(Field f)public long objectFieldOffset(Class&lt;?&gt; c, String name)//静态字段在类对象中的偏移public long staticFieldOffset(Field f)//获得静态字段所对应类对象，等同于f.getDeclaringClass()public Object staticFieldBase(Field f) 读取/修改对象上指定偏移位置的值，其他基本数据类型(boolean,char,byte,short,float,double,long)类似： 12public native int getInt(Object o, long offset);public native void putInt(Object o, long offset, int x); 此外还可以读取/设定引用值reference value,指针native pointer 1234567//获得给定对象偏移量上的引用类型的值public native Object getObject(Object o, long offset);//设置给定对象偏移量上的引用类型的值public native void putObject(Object o, long offset, Object x);//获取、设定本地指针的值，等同于获取、设定int或者是long类型的数据public long getAddress(Object o, long offset)public void putAddress(Object o, long offset, long x) 以上方法都是通过两个参数引用到一个变量，叫做double-register地址模式，当Object引用为null时，把offset作为绝对地址，使用绝对地址的API，叫做single-register地址模式，例如： 123public void putInt(long address, int x) &#123; putInt(null, address, x);&#125; 此时address可以指向通过Unsafe.allocateMemory获取的内存块中的地址，类似于C语言中的指针，直接指明实际要读写的地址 数组相关数组头部还存储有数组的长度信息，索引访问数组元素时需要知道第一个元素与起始位置的偏移地址，Unsafe类包含所有的基本数据类型和Object类型的偏移的常量值，名称为ARRAY_*_BASE_OFFSET 同时访问数组第i个元素，对应偏移的确定需要乘以一个比例值，即数组中单个元素的长度，Unsafe中对应的常量为ARRAY_*_INDEX_SCALE 12345678910111213141516// 初始偏移public int arrayBaseOffset(Class&lt;?&gt; arrayClass)public static final int ARRAY_BOOLEAN_BASE_OFFSET = theUnsafe.arrayBaseOffset(boolean[].class);public static final int ARRAY_OBJECT_BASE_OFFSET = theUnsafe.arrayBaseOffset(Object[].class);// 比例值public int arrayIndexScale(Class&lt;?&gt; arrayClass)public static final int ARRAY_BOOLEAN_INDEX_SCALE = theUnsafe.arrayIndexScale(boolean[].class);public static final int ARRAY_OBJECT_INDEX_SCALE = theUnsafe.arrayIndexScale(Object[].class); 两个信息配合使用，就可以得到数组中每个元素相对内存起点的偏移，然后进行读写 1234567891011// java8中的ConcurrentHashMapClass&lt;?&gt; ak = Node[].class;ABASE = U.arrayBaseOffset(ak);int scale = U.arrayIndexScale(ak);ASHIFT = 31 - Integer.numberOfLeadingZeros(scale);//具体使用，i代表索引static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125; CAS 相关compareAndSwap，内存偏移地址 offset，预期值 expected，新值 x。如果变量在当前时刻的值和预期值 expected 相等，尝试将变量的值更新为 x。如果更新成功，返回 true；否则，返回 false。 1234567//更新变量值为x，如果当前值为expected//o：对象 offset：偏移量 expected：期望值 x：新值public final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object x); public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); public final native boolean compareAndSwapLong(Object o, long offset, long expected, long x); compareAndSwapObject方法中的第一个参数和第二个参数，用于确定待操作对象在内存中的具体位置的，然后取出值和第三个参数进行比较，如果相等，则将内存中的值更新为第四个参数的值，同时返回true，表明原子更新操作完毕。反之则不更新内存中的值，同时返回false，表明原子操作失败。 同样的，compareAndSwapInt方法也是相似的道理，第一个，第二个参数用来确定当前操作对象在内存中的存储值，然后和第三个expect value比较，如果相等，则将内存值更新为第四个update value值。 JDK 1.8 中基于 CAS 扩展。作用都是，通过 CAS 设置新的值，返回旧的值。 123456789101112131415161718192021222324252627282930313233343536373839//增加public final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v;&#125; public final long getAndAddLong(Object o, long offset, long delta) &#123; long v; do &#123; v = getLongVolatile(o, offset); &#125; while (!compareAndSwapLong(o, offset, v, v + delta)); return v;&#125;//设置public final int getAndSetInt(Object o, long offset, int newValue) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, newValue)); return v;&#125; public final long getAndSetLong(Object o, long offset, long newValue) &#123; long v; do &#123; v = getLongVolatile(o, offset); &#125; while (!compareAndSwapLong(o, offset, v, newValue)); return v;&#125;public final Object getAndSetObject(Object o, long offset, Object newValue) &#123; Object v; do &#123; v = getObjectVolatile(o, offset); &#125; while (!compareAndSwapObject(o, offset, v, newValue)); return v; ABA 问题 在多线程环境中，使用 CAS，如果一个线程对变量修改 2 次，第 2 次修改后的值和第 1 次修改前的值相同，其他线程对此一无所知，这类现象称为 ABA 问题。 ABA 问题可以使用 JDK 并发包中的 AtomicStampedReference 和 AtomicMarkableReference 处理。 AtomicStampedReference 是通过版本号（时间戳）来解决 ABA 问题的，也可以使用版本号（verison）来解决 ABA，即乐观锁每次在执行数据的修改操作时，都带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本号执行 +1 操作，否则执行失败。 AtomicMarkableReference 则是将一个 boolean 值作是否有更改的标记，本质就是它的版本号只有两个，true 和 false，修改的时候在两个版本号之间来回切换，虽然这样做并不能解决 ABA 的问题，但是会降低 ABA 问题发生的几率。 线程调度相关主要包括监视器锁定、解锁等。 12345678910//取消阻塞线程public native void unpark(Object thread);//阻塞线程public native void park(boolean isAbsolute, long time);//获得对象锁public native void monitorEnter(Object o);//释放对象锁public native void monitorExit(Object o);//尝试获取对象锁，返回 true 或 false 表示是否获取成功public native boolean tryMonitorEnter(Object o); volatile 相关读写使用volatile机制加载读取数据，保证可见性，API包含所有的基本数据类型和Object类型 1234//设置给定对象的int值，使用volatile语义，即设置后立马更新到内存对其他线程可见public native void putIntVolatile(Object o, long offset, int x);//获得给定对象的指定偏移量offset的int值，使用volatile语义，总能获取到最新的int值。public native int getIntVolatile(Object o, long offset); 此外还有一种惰性设定值的方式，通常出现在AtomicXXX.lazySet，它允许volatile变量和后续的内存操作重排序，就像普通非volatile变量的写操作，所以其他线程可能不能立即获取到新的值 123putOrderedObject(Object o, long offset, Object x)putOrderedInt(Object o, long offset, int x)putOrderedLong(Object o, long offset, long x) 内存屏障相关JDK 1.8 引入 ，用于定义内存屏障，避免代码重排序。 123456//内存屏障，禁止 load 操作重排序，即屏障前的load操作不能被重排序到屏障后，屏障后的 load 操作不能被重排序到屏障前public native void loadFence();//内存屏障，禁止 store 操作重排序，即屏障前的 store 操作不能被重排序到屏障后，屏障后的 store 操作不能被重排序到屏障前public native void storeFence();//内存屏障，禁止 load、store 操作重排序public native void fullFence(); 内存管理（非堆内存）allocateMemory 所分配的内存需要手动 free（不被 GC 回收）。 123456789101112131415161718192021222324252627//（boolean、byte、char、short、int、long、float、double) 都有以下 get、put 两个方法。 //获得给定地址上的 int 值public native int getInt(long address);//设置给定地址上的 int 值public native void putInt(long address, int x);//获得本地指针public native long getAddress(long address);//存储本地指针到给定的内存地址public native void putAddress(long address, long x); //分配指定大小的内存,内存没有被初始化public long allocateMemory(long bytes)//根据给定的内存地址address调整内存大小public long reallocateMemory(long address, long bytes)//将内存块中的所有字节设置为固定值，类似于C中的memoryset函数public void setMemory(Object o, long offset, long bytes, byte value)public void setMemory(long address, long bytes, byte value)//内存复制，支持两种地址模式public void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes)public void copyMemory(long srcAddress, long destAddress, long bytes)//释放allocateMemory和reallocateMemory申请的内存public native void freeMemory(long l); 系统相关12345678//返回指针的大小。返回值为 4 或 8。public native int addressSize();/** The value of &#123;@code addressSize()&#125; */public static final int ADDRESS_SIZE = theUnsafe.addressSize(); //内存页的大小。public native int pageSize(); 其他12345//获取系统的平均负载值，loadavg 这个 double 数组将会存放负载值的结果，nelems 决定样本数量，nelems 只能取值为 1 到 3，分别代表最近 1、5、15 分钟内系统的平均负载。//如果无法获取系统的负载，此方法返回 -1，否则返回获取到的样本数量（loadavg 中有效的元素个数）。public native int getLoadAverage(double[] loadavg, int nelems);//绕过检测机制直接抛出异常。public native void throwException(Throwable ee); Unsafe 类的使用场景避免初始化当想要绕过对象构造方法、安全检查器或者没有 public 的构造方法时，allocateInstance() 方法变得非常有用。 编写一个简单的 Java 类。 1234567891011public class TestA &#123; private int a = 0; public TestA() &#123; a = 1; &#125; public int getA() &#123; return a; &#125;&#125; 构造方法、反射方法和 allocateInstance 方法的不同实现。 将 public 构造方法修改为 private，allocateInstance 方法可以得到同样的结果。 1234567891011121314151617181920212223242526272829// constructorTestA constructorA = new TestA();System.out.println(constructorA.getA()); //print 1// reflectiontry &#123; TestA reflectionA = TestA.class.newInstance(); System.out.println(reflectionA.getA()); //print 1&#125; catch (InstantiationException e) &#123; e.printStackTrace();&#125; catch (IllegalAccessException e) &#123; e.printStackTrace();&#125;// unsafeField f = null;try &#123; f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); f.setAccessible(true); Unsafe unsafe = (Unsafe) f.get(null); TestA unsafeA = (TestA) unsafe.allocateInstance(TestA.class); System.out.println(unsafeA.getA()); //print 0&#125; catch (NoSuchFieldException e) &#123; e.printStackTrace();&#125; catch (IllegalAccessException e) &#123; e.printStackTrace();&#125; catch (InstantiationException e) &#123; e.printStackTrace();&#125; 内存修改Unsafe 可用于绕过安全的常用技术，直接修改内存变量。 反射也可以实现相同的功能。但是 Unsafe 可以修改任何对象，甚至没有这些对象的引用。 编写一个简单的 Java 类。 12345678public class TestA &#123; private int ACCESS_ALLOWED = 1; public boolean giveAccess() &#123; return 40 == ACCESS_ALLOWED; &#125;&#125; 在正常情况下，giveAccess 总会返回 false。 通过计算内存偏移，并使用 putInt() 方法，类的 ACCESS_ALLOWED 被修改。 在已知类结构的时候，数据的偏移总是可以计算出来（与 c++ 中的类中数据的偏移计算是一致的）。 123456789101112131415161718192021// constructorTestA constructorA = new TestA();System.out.println(constructorA.giveAccess()); //print false// unsafeField f = null;try &#123; f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); f.setAccessible(true); Unsafe unsafe = (Unsafe) f.get(null); TestA unsafeA = (TestA) unsafe.allocateInstance(TestA.class); Field unsafeAField = unsafeA.getClass().getDeclaredField(&quot;ACCESS_ALLOWED&quot;); unsafe.putInt(unsafeA, unsafe.objectFieldOffset(unsafeAField), 40); // memory corruption System.out.println(unsafeA.giveAccess()); //print true&#125; catch (NoSuchFieldException e) &#123; e.printStackTrace();&#125; catch (IllegalAccessException e) &#123; e.printStackTrace();&#125; catch (InstantiationException e) &#123; e.printStackTrace();&#125; 动态类可以在运行时创建一个类，比如从已编译的 .class 文件中将类内容读取为字节数组，并正确地传递给 defineClass 方法。 当必须动态创建类，而现有代码中有一些代理，这非常有用。 编写一个简单的 Java 类。 123456789101112public class TestA &#123; private int a = 1; public int getA() &#123; return a; &#125; public void setA(int a) &#123; this.a = a; &#125;&#125; 动态创建类。 1234567891011121314151617181920212223242526272829303132byte[] classContents = new byte[0];try &#123; classContents = getClassContent(); Class c = getUnsafe().defineClass(null, classContents, 0, classContents.length); System.out.println(c.getMethod(&quot;getA&quot;).invoke(c.newInstance(), null)); //print 1&#125; catch (Exception e) &#123; e.printStackTrace();&#125;private static Unsafe getUnsafe() &#123; Field f = null; Unsafe unsafe = null; try &#123; f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); f.setAccessible(true); unsafe = (Unsafe) f.get(null); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; return unsafe;&#125;private static byte[] getClassContent() throws Exception &#123; File f = new File(&quot;/home/test/TestA.class&quot;); FileInputStream input = new FileInputStream(f); byte[] content = new byte[(int) f.length()]; input.read(content); input.close(); return content;&#125; 大数组Java 数组大小的最大值为 Integer.MAX_VALUE。使用直接内存分配，创建的数组大小受限于堆大小。 Unsafe 分配的内存，分配在非堆内存，因为不执行任何边界检查，所以任何非法访问都可能会导致 JVM 崩溃。 在需要分配大的连续区域、实时编程（不能容忍 JVM 延迟）时，可以使用它。java.nio 使用这一技术。 创建一个 Java 类。 123456789101112131415161718192021222324252627282930313233343536373839public class SuperArray &#123; private final static int BYTE = 1; private long size; private long address; public SuperArray(long size) &#123; this.size = size; address = getUnsafe().allocateMemory(size * BYTE); &#125; public void set(long i, byte value) &#123; getUnsafe().putByte(address + i * BYTE, value); &#125; public int get(long idx) &#123; return getUnsafe().getByte(address + idx * BYTE); &#125; public long size() &#123; return size; &#125; private static Unsafe getUnsafe() &#123; Field f = null; Unsafe unsafe = null; try &#123; f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); f.setAccessible(true); unsafe = (Unsafe) f.get(null); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; return unsafe; &#125;&#125; 使用大数组。 123456789long SUPER_SIZE = (long) Integer.MAX_VALUE * 2;SuperArray array = new SuperArray(SUPER_SIZE);System.out.println(&quot;Array size:&quot; + array.size()); //print 4294967294int sum = 0;for (int i = 0; i &lt; 100; i++) &#123; array.set((long) Integer.MAX_VALUE + i, (byte) 3); sum += array.get((long) Integer.MAX_VALUE + i);&#125;System.out.println(&quot;Sum of 100 elements:&quot; + sum); //print 300 并发应用compareAndSwap 方法是原子的，并且可用来实现高性能的、无锁的数据结构。 创建一个 Java 类。 12345678910111213141516171819202122232425262728293031323334353637public class CASCounter &#123; private volatile long counter = 0; private Unsafe unsafe; private long offset; public CASCounter() throws Exception &#123; unsafe = getUnsafe(); offset = unsafe.objectFieldOffset(CASCounter.class.getDeclaredField(&quot;counter&quot;)); &#125; public void increment() &#123; long before = counter; while (!unsafe.compareAndSwapLong(this, offset, before, before + 1)) &#123; before = counter; &#125; &#125; public long getCounter() &#123; return counter; &#125; private static Unsafe getUnsafe() &#123; Field f = null; Unsafe unsafe = null; try &#123; f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); f.setAccessible(true); unsafe = (Unsafe) f.get(null); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; return unsafe; &#125;&#125; 使用无锁的数据结构。 123456789101112131415161718192021222324252627282930313233343536373839public static void main(String[] args) &#123; final TestB b = new TestB(); Thread threadA = new Thread(new Runnable() &#123; @Override public void run() &#123; b.counter.increment(); &#125; &#125;); Thread threadB = new Thread(new Runnable() &#123; @Override public void run() &#123; b.counter.increment(); &#125; &#125;); Thread threadC = new Thread(new Runnable() &#123; @Override public void run() &#123; b.counter.increment(); &#125; &#125;); threadA.start(); threadB.start(); threadC.start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(b.counter.getCounter()); //print 3&#125;private static class TestB &#123; private CASCounter counter; public TestB() &#123; try &#123; counter = new CASCounter(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 挂起与恢复12public native void unpark(Thread jthread); public native void park(boolean isAbsolute, long time); // isAbsolute 参数是指明时间是绝对的，还是相对的。 将一个线程进行挂起是通过 park 方法实现，调用 park 后，线程将一直阻塞直到超时或者中断等条件出现。 unpark 可以终止一个挂起的线程，使其恢复正常。 整个并发框架中对线程的挂起操作被封装在 LockSupport 类中，LockSupport 类中有各种版本 pack 方法，但最终都调用的 Unsafe.park() 方法。 unpark 函数为线程提供 “ 许可（permit）”，线程调用 park 函数则等待 “ 许可 “。 这个有点像信号量，但是这个 “ 许可 “ 不能叠加，是一次性的。 比如线程 B 连续调用了三次 unpark 函数，当线程 A 调用 park 函数就使用掉这个 “ 许可 “，如果线程 A 再次调用 park，则进入等待状态。 12345678Thread currThread = Thread.currentThread();getUnsafe().unpark(currThread);getUnsafe().unpark(currThread);getUnsafe().unpark(currThread);getUnsafe().park(false, 0);getUnsafe().park(false, 0);System.out.println(&quot;execute success&quot;); // 线程挂起，不会打印。 unpark 函数可以先于 park 调用（但最好别这样做），比如线程 B 调用 unpark 函数，给线程 A 发了一个 “ 许可 “，那么当线程 A 调用 park 时，发现已经有 “ 许可 “，会马上再继续运行。 park 遇到线程终止时，会直接返回（不同于 Thread.sleep，Thread.sleep 遇到 thread.interrupt() 会抛异常）。 unpark 无法恢复处于 sleep 中的线程，只能与 park 配对使用，因为 unpark 发放的许可只有 park 能监听到。 因为 park 的特性，可以不用担心 park 的时序问题。 park / unpark 模型真正解耦了线程之间的同步，线程之间不再需要一个 Object 或者其它变量来存储状态，不再需要关心对方的状态。 参考资料https://www.jianshu.com/p/2e5b92d0962ehttps://www.jianshu.com/p/96ccc5dbd8c5]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink的分布式缓存]]></title>
    <url>%2F2019%2F09%2F16%2FFlink%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[分布式缓存Flink提供了一个分布式缓存，类似于hadoop，可以使用户在并行函数中很方便的读取本地文件，并把它放在taskmanager节点中，防止task重复拉取。 此缓存的工作机制如下：程序注册一个文件或者目录(本地或者远程文件系统，例如hdfs或者s3)，通过ExecutionEnvironment注册缓存文件并为它起一个名称。 当程序执行，Flink自动将文件或者目录复制到所有taskmanager节点的本地文件系统，仅会执行一次。用户可以通过这个指定的名称查找文件或者目录，然后从taskmanager节点的本地文件系统访问它。 示例在ExecutionEnvironment中注册一个文件： 1234// 获取运行环境ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();// 注册一个文件 本地文件或者分布式文件env.registerCachedFile(&quot;flink-common\\src\\main\\resources\\cache.txt&quot;, &quot;cache&quot;); 在用户函数中访问缓存文件或者目录(这里是一个map函数)。这个函数必须继承RichFunction,因为它需要使用RuntimeContext读取数据: 1234567891011121314151617DataSet&lt;String&gt; result = data.map(new RichMapFunction&lt;String, String&gt;() &#123; String cacheString; @Override public void open(Configuration parameters) throws Exception &#123; super.open(parameters); File cache = getRuntimeContext().getDistributedCache().getFile(&quot;cache&quot;); cacheString = FileUtils.readFileUtf8(cache); &#125; @Override public String map(String value) throws Exception &#123; return cacheString + &quot;: &quot; + value; &#125; &#125;); 完整代码见：https://github.com/Ruanshubin/awesome-flink/tree/master/flink-common/src/main/java/com/ruanshubin/bigdata/flink/common/cache 开源推荐在学习Flink的过程中，本人将涉及到的测试案例、源码解读、开发技巧等系统整理了一下，并开源到Github上，地址为： https://github.com/Ruanshubin/awesome-flink 欢迎大家Star支持！]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java停止线程的3种方式]]></title>
    <url>%2F2019%2F09%2F16%2FJava%E5%81%9C%E6%AD%A2%E7%BA%BF%E7%A8%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在Java中有以下3种方式终止正在运行的线程： 使用退出标志，使线程正常退出； 使用stop()方法强行终止线程，不推荐使用该方法，JDK已声明弃用； 使用interrupt方法中断线程。 使用标志位在 run() 方法执行完毕后，该线程就终止了。但是在某些特殊的情况下，run() 方法会被一直执行；比如在服务端程序中可能会使用 while(true) { … } 这样的循环结构来不断的接收来自客户端的请求。此时就可以用修改标志位的方式来结束 run() 方法。 1234567891011121314151617181920public class ServerThread extends Thread &#123; //volatile修饰符用来保证其它线程读取的总是该变量的最新的值 public volatile boolean exit = false; @Override public void run() &#123; ServerSocket serverSocket = new ServerSocket(8080); while(!exit)&#123; serverSocket.accept(); //阻塞等待客户端消息 ... &#125; &#125; public static void main(String[] args) &#123; ServerThread t = new ServerThread(); t.start(); ... t.exit = true; //修改标志位，退出线程 &#125;&#125; 使用stop()通过查看 JDK 的 API，我们会看到 java.lang.Thread 类型提供了一系列的方法如 start()、stop()、resume()、suspend()、destory()等方法来管理线程。但是除了 start() 之外，其它几个方法都被声名为已过时（deprecated）。 虽然 stop() 方法确实可以停止一个正在运行的线程，但是这个方法是不安全的，而且该方法已被弃用，最好不要使用它。 为什么弃用stop： 调用 stop() 方法会立刻停止 run() 方法中剩余的全部工作，包括在 catch 或 finally 语句中的，并抛出ThreadDeath异常(通常情况下此异常不需要显示的捕获)，因此可能会导致一些清理性的工作的得不到完成，如文件，数据库等的关闭。 调用 stop() 方法会立即释放该线程所持有的所有的锁，导致数据得不到同步，出现数据不一致的问题。 例如，存在一个对象 u 持有 ID 和 NAME 两个字段，假如写入线程在写对象的过程中，只完成了对 ID 的赋值，但没来得及为 NAME 赋值，就被 stop() 导致锁被释放，那么当读取线程得到锁之后再去读取对象 u 的 ID 和 Name 时，就会出现数据不一致的问题，如下图： 使用 interrupt()现在我们知道了使用 stop() 方式停止线程是非常不安全的方式，那么我们应该使用什么方法来停止线程呢？答案就是使用 interrupt() 方法来中断线程。 需要明确的一点的是：interrupt() 方法并不像在 for 循环语句中使用 break 语句那样干脆，马上就停止循环。调用 interrupt() 方法仅仅是在当前线程中打一个停止的标记，并不是真的停止线程。 也就是说，线程中断并不会立即终止线程，而是通知目标线程，有人希望你终止。至于目标线程收到通知后会如何处理，则完全由目标线程自行决定。这一点很重要，如果中断后，线程立即无条件退出，那么我们又会遇到 stop() 方法的老问题。 事实上，如果一个线程不能被 interrupt，那么 stop 方法也不会起作用。 我们来看一个使用 interrupt() 的例子： 123456789101112131415161718192021public class InterruptThread1 extends Thread&#123; public static void main(String[] args) &#123; try &#123; InterruptThread1 t = new InterruptThread1(); t.start(); Thread.sleep(200); t.interrupt(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; super.run(); for(int i = 0; i &lt;= 200000; i++) &#123; System.out.println(&quot;i=&quot; + i); &#125; &#125; &#125; 输出： 从输出的结果我们会发现 interrupt 方法并没有停止线程 t 中的处理逻辑，也就是说即使 t 线程被设置为了中断状态，但是这个中断并不会起作用，那么该如何停止线程呢？ 这就需要使用到另外两个与线程中断有关的方法了： 12public boolean Thread.isInterrupted() //判断是否被中断public static boolean Thread.interrupted() //判断是否被中断，并清除当前中断状态 这两个方法使得当前线程能够感知到是否被中断了（通过检查标志位）。 所以如果希望线程 t 在中断后停止，就必须先判断是否被中断，并为它增加相应的中断处理代码： 123456789101112@Overridepublic void run() &#123; super.run(); for(int i = 0; i &lt;= 200000; i++) &#123; //判断是否被中断 if(Thread.currentThread().isInterrupted())&#123; //处理中断逻辑 break; &#125; System.out.println(&quot;i=&quot; + i); &#125;&#125; 输出结果，for 循环在执行完成前就提前结束了： 在上面这段代码中，我们增加了 Thread.isInterrupted() 来判断当前线程是否被中断了，如果是，则退出 for 循环，结束线程。 这种方式看起来与之前介绍的“使用标志位终止线程”非常类似，但是在遇到 sleep() 或者 wait() 这样的操作，我们只能通过中断来处理了。 1public static native void sleep(long millis) throws InterruptedException Thread.sleep() 方法会抛出一个 InterruptedException 异常，当线程被 sleep() 休眠时，如果被中断，这会就抛出这个异常。（注意：Thread.sleep() 方法由于中断而抛出的异常，是会清除中断标记的。）]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink的Window源码剖析]]></title>
    <url>%2F2019%2F08%2F19%2FFlink%E7%9A%84Window%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Window 可以看到，GlobalWindow和TimeWindow均继承自抽象类Window，其源码如下： 123public abstract class Window &#123; public abstract long maxTimestamp();&#125; 可以看出，Window抽象类仅有一个maxTimestamp()方法用于获取仍属于该窗口的最大时间戳。 TimeWindow首先看TimeWindow的数据结构： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public class TimeWindow extends Window &#123; private final long start; private final long end; public TimeWindow(long start, long end) &#123; this.start = start; this.end = end; &#125; public long getStart() &#123; return start; &#125; public long getEnd() &#123; return end; &#125; @Override public long maxTimestamp() &#123; return end - 1; &#125; @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (o == null || getClass() != o.getClass()) &#123; return false; &#125; TimeWindow window = (TimeWindow) o; return end == window.end &amp;&amp; start == window.start; &#125; @Override public int hashCode() &#123; return MathUtils.longToIntWithBitMixing(start + end); &#125; @Override public String toString() &#123; return &quot;TimeWindow&#123;&quot; + &quot;start=&quot; + start + &quot;, end=&quot; + end + &apos;&#125;&apos;; &#125; public boolean intersects(TimeWindow other) &#123; return this.start &lt;= other.end &amp;&amp; this.end &gt;= other.start; &#125; public TimeWindow cover(TimeWindow other) &#123; return new TimeWindow(Math.min(start, other.start), Math.max(end, other.end)); &#125; ...... public static void mergeWindows(Collection&lt;TimeWindow&gt; windows, MergingWindowAssigner.MergeCallback&lt;TimeWindow&gt; c) &#123; List&lt;TimeWindow&gt; sortedWindows = new ArrayList&lt;&gt;(windows); Collections.sort(sortedWindows, new Comparator&lt;TimeWindow&gt;() &#123; @Override public int compare(TimeWindow o1, TimeWindow o2) &#123; return Long.compare(o1.getStart(), o2.getStart()); &#125; &#125;); List&lt;Tuple2&lt;TimeWindow, Set&lt;TimeWindow&gt;&gt;&gt; merged = new ArrayList&lt;&gt;(); Tuple2&lt;TimeWindow, Set&lt;TimeWindow&gt;&gt; currentMerge = null; for (TimeWindow candidate: sortedWindows) &#123; if (currentMerge == null) &#123; currentMerge = new Tuple2&lt;&gt;(); currentMerge.f0 = candidate; currentMerge.f1 = new HashSet&lt;&gt;(); currentMerge.f1.add(candidate); &#125; else if (currentMerge.f0.intersects(candidate)) &#123; currentMerge.f0 = currentMerge.f0.cover(candidate); currentMerge.f1.add(candidate); &#125; else &#123; merged.add(currentMerge); currentMerge = new Tuple2&lt;&gt;(); currentMerge.f0 = candidate; currentMerge.f1 = new HashSet&lt;&gt;(); currentMerge.f1.add(candidate); &#125; &#125; if (currentMerge != null) &#123; merged.add(currentMerge); &#125; for (Tuple2&lt;TimeWindow, Set&lt;TimeWindow&gt;&gt; m: merged) &#123; if (m.f1.size() &gt; 1) &#123; c.merge(m.f1, m.f0); &#125; &#125; &#125; public static long getWindowStartWithOffset(long timestamp, long offset, long windowSize) &#123; return timestamp - (timestamp - offset + windowSize) % windowSize; &#125;&#125; 该窗口主要用于实现时间驱动的相关操作。 可以看到。TimeWindow由start和end2个时间戳组成，最大时间戳为end-1，同时，TimeWindow提供了getWindowStartWithOffset静态方法，用于获取时间戳所属时间窗的起点，其中的offset为偏移量。例如，没有偏移量的话，小时滚动窗口将按时间纪元来对齐，也就是1:00:00—1:59:59,2:00:00—2:59:59等，如果你指定了15分钟的偏移，你将得到1:15:00—2:14:59,2:15:00—3:14:59等。时间偏移主要用于调准非0时区的窗口，例如:在中国你需要指定8小时的时间偏移。 intersects方法用于判断2个时间窗是否有交集，cover方法用于求2个时间窗的合集，mergeWindows用于将时间窗集合进行合并，该方法是实现Session Window的关键。 对于session window来说，我们需要窗口变得更灵活。基本的思想是这样的：SessionWindows assigner 会为每个进入的元素分配一个窗口，该窗口以元素的时间戳作为起始点，时间戳加会话超时时间为结束点，也就是该窗口为[timestamp, timestamp+sessionGap)。比如我们现在到了两个元素，它们被分配到两个独立的窗口中，两个窗口目前不相交，如图： 当第三个元素进入时，分配到的窗口与现有的两个窗口发生了叠加，情况变成了这样： 由于我们支持了窗口的合并，WindowAssigner可以合并这些窗口。它会遍历现有的窗口，并告诉系统哪些窗口需要合并成新的窗口。Flink 会将这些窗口进行合并，合并的主要内容有两部分： 需要合并的窗口的底层状态的合并（也就是窗口中缓存的数据，或者对于聚合窗口来说是一个聚合值）； 需要合并的窗口的Trigger的合并（比如对于EventTime来说，会删除旧窗口注册的定时器，并注册新窗口的定时器）。 总之，结果是三个元素现在在同一个窗口中： 需要注意的是，对于每一个新进入的元素，都会分配一个属于该元素的窗口，都会检查并合并现有的窗口。在触发窗口计算之前，每一次都会检查该窗口是否可以和其他窗口合并，直到trigger触发后，会将该窗口从窗口列表中移除。对于 event time 来说，窗口的触发是要等到大于窗口结束时间的 watermark 到达，当watermark没有到，窗口会一直缓存着。所以基于这种机制，可以做到对乱序消息的支持。 这里有一个优化点可以做，因为每一个新进入的元素都会创建属于该元素的窗口，然后合并。如果新元素连续不断地进来，并且新元素的窗口一直都是可以和之前的窗口重叠合并的，那么其实这里多了很多不必要的创建窗口、合并窗口的操作，我们可以直接将新元素放到那个已存在的窗口，然后扩展该窗口的大小，看起来就像和新元素的窗口合并了一样。 GlobalWindow接着看GlobalWindow： 12345678910111213141516171819202122232425262728293031323334public class GlobalWindow extends Window &#123; private static final GlobalWindow INSTANCE = new GlobalWindow(); private GlobalWindow() &#123; &#125; public static GlobalWindow get() &#123; return INSTANCE; &#125; @Override public long maxTimestamp() &#123; return Long.MAX_VALUE; &#125; @Override public boolean equals(Object o) &#123; return this == o || !(o == null || getClass() != o.getClass()); &#125; @Override public int hashCode() &#123; return 0; &#125; @Override public String toString() &#123; return &quot;GlobalWindow&quot;; &#125; /** * 序列化相关操作 */&#125; GlobalWindow提供了get()静态方法用于获取GlobalWindow实例，maxTimestamp()统一返回Long的最大值，而hashCode统一返回0。 该窗口主要用于实现数据驱动的相关操作。 WindowAssigner顾名思义，WindowAssigner用来决定某个元素被分配到哪个/哪些窗口中去。 1234567891011121314151617public abstract class WindowAssigner&lt;T, W extends Window&gt; implements Serializable &#123; private static final long serialVersionUID = 1L; public abstract Collection&lt;W&gt; assignWindows(T element, long timestamp, WindowAssignerContext context); public abstract Trigger&lt;T, W&gt; getDefaultTrigger(StreamExecutionEnvironment env); public abstract TypeSerializer&lt;W&gt; getWindowSerializer(ExecutionConfig executionConfig); public abstract boolean isEventTime(); public abstract static class WindowAssignerContext &#123; public abstract long getCurrentProcessingTime(); &#125;&#125; 首先看assignWindows方法，其输入element为待分配的元素，timestamp为element持有的时间戳，context为该分配器的上下文容器，返回值为element所属的窗口集合，也就说，同一条数据元素，可能会被分配到多个窗口中去。但并不是将该数据复制到多个窗口中去，Window本身只是一个ID标识符，其内部可能存储了一些元数据，如TimeWindow中有开始和结束时间，但是并不会存储窗口中的元素。窗口中的元素实际存储在 Key/Value State 中，key为Window，value为元素集合（或聚合值）。为了保证窗口的容错性，该实现依赖了 Flink 的 State 机制（参见 state 文档）。 接着看其他方法，getDefaultTrigger用于返回该窗口默认的触发器，getWindowSerializer用于返回窗口的序列化器，isEventTime用于判断是否基于event time来进行元素的分配。 最后看一下WindowAssignerContext这个上下文容器，其是一个内部静态抽象类，提供了getCurrentProcessingTime方法用于获取当前的processing time。 看一下WindowAssigner的实现类，GlobalWindows主要用于实现CountWindow，MergingWindowAssigner主要用于实现SessionWindow，剩下的分别基于processing time和event time实现了翻滚窗口和滑动窗口。 先捡软柿子捏，首先看较为简单的GlobalWindows： GlobalWindows12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class GlobalWindows extends WindowAssigner&lt;Object, GlobalWindow&gt; &#123; private static final long serialVersionUID = 1L; private GlobalWindows() &#123;&#125; @Override public Collection&lt;GlobalWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; return Collections.singletonList(GlobalWindow.get()); &#125; @Override public Trigger&lt;Object, GlobalWindow&gt; getDefaultTrigger(StreamExecutionEnvironment env) &#123; return new NeverTrigger(); &#125; @Override public String toString() &#123; return &quot;GlobalWindows()&quot;; &#125; public static GlobalWindows create() &#123; return new GlobalWindows(); &#125; @Internal public static class NeverTrigger extends Trigger&lt;Object, GlobalWindow&gt; &#123; private static final long serialVersionUID = 1L; @Override public TriggerResult onElement(Object element, long timestamp, GlobalWindow window, TriggerContext ctx) &#123; return TriggerResult.CONTINUE; &#125; @Override public TriggerResult onEventTime(long time, GlobalWindow window, TriggerContext ctx) &#123; return TriggerResult.CONTINUE; &#125; @Override public TriggerResult onProcessingTime(long time, GlobalWindow window, TriggerContext ctx) &#123; return TriggerResult.CONTINUE; &#125; @Override public void clear(GlobalWindow window, TriggerContext ctx) throws Exception &#123;&#125; @Override public void onMerge(GlobalWindow window, OnMergeContext ctx) &#123; &#125; &#125; @Override public TypeSerializer&lt;GlobalWindow&gt; getWindowSerializer(ExecutionConfig executionConfig) &#123; return new GlobalWindow.Serializer(); &#125; @Override public boolean isEventTime() &#123; return false; &#125;&#125; GlobalWindows提供了create静态方法用于返回GlobalWindows实例，assignWindows方法会将上游的元素全都分配到一个单例GlobalWindow中，其默认的Trigger为NeverTrigger，即永不触发fire计算。 TumblingProcessingTimeWindows和TumblingEventTimeWindowsTumblingProcessingTimeWindows和TumblingEventTimeWindows的assignWindows方法： 123456789101112131415161718192021222324// TumblingProcessingTimeWindows@Overridepublic Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; // 获取当前的processing time final long now = context.getCurrentProcessingTime(); // 计算当前processing time所属窗口的start long start = TimeWindow.getWindowStartWithOffset(now, offset, size); return Collections.singletonList(new TimeWindow(start, start + size));&#125;// TumblingEventTimeWindows@Overridepublic Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; if (timestamp &gt; Long.MIN_VALUE) &#123; // Long.MIN_VALUE is currently assigned when no timestamp is present // 以元素自带的时间戳(event time)计算窗口的start long start = TimeWindow.getWindowStartWithOffset(timestamp, offset, size); return Collections.singletonList(new TimeWindow(start, start + size)); &#125; else &#123; throw new RuntimeException(&quot;Record has Long.MIN_VALUE timestamp (= no timestamp marker). &quot; + &quot;Is the time characteristic set to &apos;ProcessingTime&apos;, or did you forget to call &quot; + &quot;&apos;DataStream.assignTimestampsAndWatermarks(...)&apos;?&quot;); &#125;&#125; 可以看到，其逻辑是相似的，区别就在于窗口的start时间，一个使用的是WindowAssignerContext获取的当前时间戳，另外一个则是利用元素的EventTime，通过TimeWindow的getWindowStartWithOffset方法计算得到的。 SlidingProcessingTimeWindows和SlidingEventTimeWindows接着看滑动窗口，以SlidingProcessingTimeWindows为例： 123456789101112131415@Overridepublic Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; // 获取当前系统的Processing Time timestamp = context.getCurrentProcessingTime(); // 初始化窗口集合，窗口个数为size/slide List&lt;TimeWindow&gt; windows = new ArrayList&lt;&gt;((int) (size / slide)); long lastStart = TimeWindow.getWindowStartWithOffset(timestamp, offset, slide); // 计算窗口集合 for (long start = lastStart; start &gt; timestamp - size; start -= slide) &#123; windows.add(new TimeWindow(start, start + size)); &#125; return windows;&#125; 上述代码可能不够直观，我们以一个简单例子来解释上述方法。 假设基础数据如下： 1234timestamp=73;offset=6;size=60;slide=10; 计算过程： 1234567891011121314集合的大小为：60/10=6上一次起始起始时间:lastStart=timestamp-(timestamp-offset+slide)%slide=73-(73-6+10)%10=73-7=66则for(start=66; start&gt;73-60; start=start-10)&#123; windows.add(new TimeWindow(start, start + size));&#125;windows集合为：[66, 126][56, 116][46, 106][36, 96][26, 86][16, 76] SlidingEventTimeWindows与SlidingProcessingTimeWindows的assignWindows基本一致，只是额外添加了一层对timestamp的判断，只有当timestamp &gt; Long.MIN_VALUE才会进入到窗口分配，否则抛异常。 1234567891011121314151617@Overridepublic Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; if (timestamp &gt; Long.MIN_VALUE) &#123; List&lt;TimeWindow&gt; windows = new ArrayList&lt;&gt;((int) (size / slide)); long lastStart = TimeWindow.getWindowStartWithOffset(timestamp, offset, slide); for (long start = lastStart; start &gt; timestamp - size; start -= slide) &#123; windows.add(new TimeWindow(start, start + size)); &#125; return windows; &#125; else &#123; throw new RuntimeException(&quot;Record has Long.MIN_VALUE timestamp (= no timestamp marker). &quot; + &quot;Is the time characteristic set to &apos;ProcessingTime&apos;, or did you forget to call &quot; + &quot;&apos;DataStream.assignTimestampsAndWatermarks(...)&apos;?&quot;); &#125;&#125; MergingWindowAssigner12345678910public abstract class MergingWindowAssigner&lt;T, W extends Window&gt; extends WindowAssigner&lt;T, W&gt; &#123; private static final long serialVersionUID = 1L; public abstract void mergeWindows(Collection&lt;W&gt; windows, MergeCallback&lt;W&gt; callback); public interface MergeCallback&lt;W&gt; &#123; void merge(Collection&lt;W&gt; toBeMerged, W mergeResult); &#125;&#125; MergingWindowAssigner主要提供了MergeCallback抽象接口，然后将该接口传递给TimeWindow的mergeWindows方法来进行窗口的合并(具体可看TimeWindow)。 123public static void mergeWindows(Collection&lt;TimeWindow&gt; windows, MergingWindowAssigner.MergeCallback&lt;TimeWindow&gt; c) &#123; ......&#125; Trigger触发器。决定了一个窗口何时能够被计算或清除，每个窗口都会拥有一个自己的Trigger。 123456789101112131415161718192021222324252627282930313233343536373839public abstract class Trigger&lt;T, W extends Window&gt; implements Serializable &#123; private static final long serialVersionUID = -4104633972991191369L; public abstract TriggerResult onElement(T element, long timestamp, W window, TriggerContext ctx) throws Exception; public abstract TriggerResult onProcessingTime(long time, W window, TriggerContext ctx) throws Exception; public abstract TriggerResult onEventTime(long time, W window, TriggerContext ctx) throws Exception; public boolean canMerge() &#123; return false; &#125; public void onMerge(W window, OnMergeContext ctx) throws Exception &#123; throw new UnsupportedOperationException(&quot;This trigger does not support merging.&quot;); &#125; public abstract void clear(W window, TriggerContext ctx) throws Exception; public interface TriggerContext &#123; long getCurrentProcessingTime(); MetricGroup getMetricGroup(); long getCurrentWatermark(); void registerProcessingTimeTimer(long time); void registerEventTimeTimer(long time); void deleteProcessingTimeTimer(long time); void deleteEventTimeTimer(long time); &lt;S extends State&gt; S getPartitionedState(StateDescriptor&lt;S, ?&gt; stateDescriptor); @Deprecated &lt;S extends Serializable&gt; ValueState&lt;S&gt; getKeyValueState(String name, Class&lt;S&gt; stateType, S defaultState); @Deprecated &lt;S extends Serializable&gt; ValueState&lt;S&gt; getKeyValueState(String name, TypeInformation&lt;S&gt; stateType, S defaultState); &#125; public interface OnMergeContext extends TriggerContext &#123; &lt;S extends MergingState&lt;?, ?&gt;&gt; void mergePartitionedState(StateDescriptor&lt;S, ?&gt; stateDescriptor); &#125;&#125; 当元素加入窗口时，onElement方法被调用，主要完成定时器的注册，当基于processing time的timer被触发后，onProcessingTime方法被调用，同样的，当基于event time的timer被触发后，onEventTime方法被调用。 其实现类有以下几种： 常用的主要有CountTrigger、EventTimeTrigger、ProcessingTimeTrigger，下面分别看看这几个触发器。 CountTrigger1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class CountTrigger&lt;W extends Window&gt; extends Trigger&lt;Object, W&gt; &#123; private static final long serialVersionUID = 1L; // 当窗口中的元素&gt;=maxCount时，窗口操作将被触发 private final long maxCount; // 声明count的ReducingStateDescriptor，相当于一个分布式环境下的共享变量，主要记录当前窗口中元素的数量 private final ReducingStateDescriptor&lt;Long&gt; stateDesc = new ReducingStateDescriptor&lt;&gt;(&quot;count&quot;, new Sum(), LongSerializer.INSTANCE); private CountTrigger(long maxCount) &#123; this.maxCount = maxCount; &#125; @Override public TriggerResult onElement(Object element, long timestamp, W window, TriggerContext ctx) throws Exception &#123; // 获取窗口中的元素的数量 ReducingState&lt;Long&gt; count = ctx.getPartitionedState(stateDesc); // 执行+1操作 count.add(1L); // 若count值&gt;=maxCount，则窗口执行fire操作，否则continue if (count.get() &gt;= maxCount) &#123; count.clear(); return TriggerResult.FIRE; &#125; return TriggerResult.CONTINUE; &#125; @Override public TriggerResult onEventTime(long time, W window, TriggerContext ctx) &#123; return TriggerResult.CONTINUE; &#125; @Override public TriggerResult onProcessingTime(long time, W window, TriggerContext ctx) throws Exception &#123; return TriggerResult.CONTINUE; &#125; @Override public void clear(W window, TriggerContext ctx) throws Exception &#123; // 清空共享变量 ctx.getPartitionedState(stateDesc).clear(); &#125; @Override public boolean canMerge() &#123; return true; &#125; @Override public void onMerge(W window, OnMergeContext ctx) throws Exception &#123; // 当发生窗口merge时，合并共享变量 ctx.mergePartitionedState(stateDesc); &#125; @Override public String toString() &#123; return &quot;CountTrigger(&quot; + maxCount + &quot;)&quot;; &#125; // 提供of(long maxCount)方法返回CountTrigger的实例 public static &lt;W extends Window&gt; CountTrigger&lt;W&gt; of(long maxCount) &#123; return new CountTrigger&lt;&gt;(maxCount); &#125; private static class Sum implements ReduceFunction&lt;Long&gt; &#123; private static final long serialVersionUID = 1L; @Override public Long reduce(Long value1, Long value2) throws Exception &#123; return value1 + value2; &#125; &#125;&#125; ProcessingTimeTrigger当processing time超过窗口的end值时，窗口将执行fire操作： 123456789101112131415161718192021222324@Overridepublic TriggerResult onElement(Object element, long timestamp, TimeWindow window, TriggerContext ctx) &#123; // 注册processing time的时钟，相当于定了个闹钟，闹钟时间为window.maxTimestamp() ctx.registerProcessingTimeTimer(window.maxTimestamp()); return TriggerResult.CONTINUE;&#125;@Overridepublic TriggerResult onEventTime(long time, TimeWindow window, TriggerContext ctx) throws Exception &#123; // 不做处理 return TriggerResult.CONTINUE;&#125;@Overridepublic TriggerResult onProcessingTime(long time, TimeWindow window, TriggerContext ctx) &#123; // 当闹钟定的时间到了，执行fire操作 return TriggerResult.FIRE;&#125;@Overridepublic void clear(TimeWindow window, TriggerContext ctx) throws Exception &#123; // 清除时钟 ctx.deleteProcessingTimeTimer(window.maxTimestamp());&#125; 可以看到，onElement方法主要用于注册时钟，时钟时间到达后(onProcessingTime)，会触发窗口的fire操作。 EventTimeTriggerEventTimeTrigger与ProcessingTimeTrigger类似： 123456789101112131415161718192021222324252627@Overridepublic TriggerResult onElement(Object element, long timestamp, TimeWindow window, TriggerContext ctx) throws Exception &#123; if (window.maxTimestamp() &lt;= ctx.getCurrentWatermark()) &#123; // if the watermark is already past the window fire immediately return TriggerResult.FIRE; &#125; else &#123; ctx.registerEventTimeTimer(window.maxTimestamp()); return TriggerResult.CONTINUE; &#125;&#125;@Overridepublic TriggerResult onEventTime(long time, TimeWindow window, TriggerContext ctx) &#123; return time == window.maxTimestamp() ? TriggerResult.FIRE : TriggerResult.CONTINUE;&#125;@Overridepublic TriggerResult onProcessingTime(long time, TimeWindow window, TriggerContext ctx) throws Exception &#123; return TriggerResult.CONTINUE;&#125;@Overridepublic void clear(TimeWindow window, TriggerContext ctx) throws Exception &#123; ctx.deleteEventTimeTimer(window.maxTimestamp());&#125; onElement方法会检查当前窗口的最大时间戳是否大于水印，若大于水印，则直接触发窗口的fire操作，若小于水印，则注册EventTime的时钟，当水印时间到达时钟设定值时，会触发窗口的fire操作。 最后，我们看一个很有用的Trigger工具类—PurgingTrigger。 PurgingTrigger首先看PurgingTrigger的构造器： 123private PurgingTrigger(Trigger&lt;T, W&gt; nestedTrigger) &#123; this.nestedTrigger = nestedTrigger;&#125; PurgingTrigger会将传入的nestedTrigger进行”二次处理”，当nestedTrigger执行fire操作时，PurgingTrigger会将其转换为fire+purge操作。 1234567891011121314151617@Overridepublic TriggerResult onElement(T element, long timestamp, W window, TriggerContext ctx) throws Exception &#123; TriggerResult triggerResult = nestedTrigger.onElement(element, timestamp, window, ctx); return triggerResult.isFire() ? TriggerResult.FIRE_AND_PURGE : triggerResult;&#125;@Overridepublic TriggerResult onEventTime(long time, W window, TriggerContext ctx) throws Exception &#123; TriggerResult triggerResult = nestedTrigger.onEventTime(time, window, ctx); return triggerResult.isFire() ? TriggerResult.FIRE_AND_PURGE : triggerResult;&#125;@Overridepublic TriggerResult onProcessingTime(long time, W window, TriggerContext ctx) throws Exception &#123; TriggerResult triggerResult = nestedTrigger.onProcessingTime(time, window, ctx); return triggerResult.isFire() ? TriggerResult.FIRE_AND_PURGE : triggerResult;&#125; 典型的修饰器模式。 KeyedStream的countWindow(long size)直接应用了PurgingTrigger工具类。 123public WindowedStream&lt;T, KEY, GlobalWindow&gt; countWindow(long size) &#123; return window(GlobalWindows.create()).trigger(PurgingTrigger.of(CountTrigger.of(size)));&#125; Evictor可以译为“驱逐者”。在Trigger触发之后，在窗口被处理前/后，Evictor（如果有Evictor的话）会用来剔除窗口中不需要的元素，相当于一个filter。 123456789101112131415public interface Evictor&lt;T, W extends Window&gt; extends Serializable &#123; void evictBefore(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, W window, EvictorContext evictorContext); void evictAfter(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, W window, EvictorContext evictorContext); interface EvictorContext &#123; long getCurrentProcessingTime(); MetricGroup getMetricGroup(); long getCurrentWatermark(); &#125;&#125; 其主要有如下实现类： CountEvictor1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class CountEvictor&lt;W extends Window&gt; implements Evictor&lt;Object, W&gt; &#123; private static final long serialVersionUID = 1L; // 窗口的最大元素数量 private final long maxCount; // 是否在计算后驱逐元素 private final boolean doEvictAfter; private CountEvictor(long count, boolean doEvictAfter) &#123; this.maxCount = count; this.doEvictAfter = doEvictAfter; &#125; private CountEvictor(long count) &#123; this.maxCount = count; // 默认在计算前执行Evictor操作 this.doEvictAfter = false; &#125; @Override public void evictBefore(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, W window, EvictorContext ctx) &#123; // 若doEvictAfter为false if (!doEvictAfter) &#123; evict(elements, size, ctx); &#125; &#125; @Override public void evictAfter(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, W window, EvictorContext ctx) &#123; // 若doEvictAfter为true if (doEvictAfter) &#123; evict(elements, size, ctx); &#125; &#125; private void evict(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, EvictorContext ctx) &#123; if (size &lt;= maxCount) &#123; return; &#125; else &#123; int evictedCount = 0; // Iterator&lt;TimestampedValue&lt;Object&gt;&gt; iterator是按照元素到达时间排序的有序迭代器，第1个元素为时间最old的 for (Iterator&lt;TimestampedValue&lt;Object&gt;&gt; iterator = elements.iterator(); iterator.hasNext();)&#123; iterator.next(); evictedCount++; if (evictedCount &gt; size - maxCount) &#123; break; &#125; else &#123; // 将多余的元素剔除 iterator.remove(); &#125; &#125; &#125; &#125; /** * Creates a &#123;@code CountEvictor&#125; that keeps the given number of elements. * Eviction is done before the window function. * * @param maxCount The number of elements to keep in the pane. */ public static &lt;W extends Window&gt; CountEvictor&lt;W&gt; of(long maxCount) &#123; return new CountEvictor&lt;&gt;(maxCount); &#125; public static &lt;W extends Window&gt; CountEvictor&lt;W&gt; of(long maxCount, boolean doEvictAfter) &#123; return new CountEvictor&lt;&gt;(maxCount, doEvictAfter); &#125;&#125; KeyedStream的countWindow(long size, long slide)方法应用CountEvictor实现了滑动窗口。 12345public WindowedStream&lt;T, KEY, GlobalWindow&gt; countWindow(long size, long slide) &#123; return window(GlobalWindows.create()) .evictor(CountEvictor.of(size)) .trigger(CountTrigger.of(slide));&#125; TimeEvictorTimeEvictor与CountEvictor类似，TimeEvictor基于时间驱动，故其windowSize参数对应CountEvictor的maxCount，均表征窗口的大小，重点看一下evict方法： 1234567891011121314151617private void evict(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, EvictorContext ctx) &#123; if (!hasTimestamp(elements)) &#123; return; &#125; // 获取所有元素时间戳的最大值 long currentTime = getMaxTimestamp(elements); // 获取evict分割线 long evictCutoff = currentTime - windowSize; for (Iterator&lt;TimestampedValue&lt;Object&gt;&gt; iterator = elements.iterator(); iterator.hasNext(); ) &#123; TimestampedValue&lt;Object&gt; record = iterator.next(); // 若元素的时间戳不大于evict分割线，执行删除操作 if (record.getTimestamp() &lt;= evictCutoff) &#123; iterator.remove(); &#125; &#125;&#125; DeltaEvictor12345678910111213141516171819202122232425public class DeltaEvictor&lt;T, W extends Window&gt; implements Evictor&lt;T, W&gt; &#123; private static final long serialVersionUID = 1L; // 求两元素间距离的函数 DeltaFunction&lt;T&gt; deltaFunction; // 阈值 private double threshold; private final boolean doEvictAfter; ...... private void evict(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, EvictorContext ctx) &#123; // 获取最新的元素 TimestampedValue&lt;T&gt; lastElement = Iterables.getLast(elements); for (Iterator&lt;TimestampedValue&lt;T&gt;&gt; iterator = elements.iterator(); iterator.hasNext();)&#123; TimestampedValue&lt;T&gt; element = iterator.next(); // 若当前元素与最新元素之间的距离超过阈值，则删除该元素 if (deltaFunction.getDelta(element.getValue(), lastElement.getValue()) &gt;= this.threshold) &#123; iterator.remove(); &#125; &#125; &#125; ...... &#125; 由上述代码易知，基于DeltaEvictor可以实现CountEvictor和TimeEvictor，只要实现各自的DeltaFunction即可，所以DeltaEvictor更具有一般性。 开源推荐在学习Flink的过程中，本人将涉及到的测试案例、源码解读、开发技巧等系统整理了一下，并开源到Github上，地址为： https://github.com/Ruanshubin/awesome-flink 欢迎大家Star支持！]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink的Window初探]]></title>
    <url>%2F2019%2F08%2F15%2FFlink%E7%9A%84Window%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[Flink 认为 Batch 是 Streaming 的一个特例，所以 Flink 底层引擎是一个流式引擎，在上面实现了流处理和批处理。而窗口（window）就是从 Streaming 到 Batch 的一个桥梁。 引言在流处理应用中，数据是连续不断的，因此我们不可能等到所有数据都到了才开始处理。当然我们可以每来一个消息就处理一次，但是有时我们需要做一些聚合类的处理。 基于窗口驱动方式可分为: 时间驱动的（Time Window，例如：每30秒钟） 数据驱动的（Count Window，例如：每一百个元素） 基于窗口处理方式可分为： 翻滚窗口（Tumbling Window，无重叠） 滚动窗口（Sliding Window，有重叠） 会话窗口（Session Window，活动间隙） 需要说明的是，Flink将Time分为3种: event time（事件时间：事件发生时的时间） ingestion time（摄取时间：事件进入流处理系统的时间） processing time（处理时间：消息被计算处理的时间） Count WindowCount Window 是根据元素个数对数据流进行分组的。 Tumbling Count Window当我们想要每100个用户购买行为事件统计购买总数，那么每当窗口中填满100个元素了，就会对窗口进行计算，这种窗口我们称之为翻滚计数窗口（Tumbling Count Window），通过使用 DataStream API，我们可以这样实现： 12345678910// Stream of (userId, buyCnts)val buyCnts: DataStream[(Int, Int)] = ...val tumblingCnts: DataStream[(Int, Int)] = buyCnts // key stream by sensorId .keyBy(0) // tumbling count window of 100 elements size .countWindow(100) // compute the buyCnt sum .sum(1) Sliding Count WindowCount Window 也支持 Sliding Window，虽在上图中未描述出来，但和Sliding Time Window含义是类似的，例如计算每10个元素计算一次最近100个元素的总和，代码示例如下: 12345val slidingCnts: DataStream[(Int, Int)] = vehicleCnts .keyBy(0) // sliding count window of 100 elements size and 10 elements trigger interval .countWindow(100, 10) .sum(1) Time WindowTumbling Time Window统计每一分钟中用户购买的商品的总数，需要将用户的行为事件按每一分钟进行切分，这种切分被成为翻滚时间窗口（Tumbling Time Window）。 翻滚窗口能将数据流切分成不重叠的窗口，每一个事件只能属于一个窗口。通过使用DataStream API，可以这样实现： 12345678910// Stream of (userId, buyCnt)val buyCnts: DataStream[(Int, Int)] = ...val tumblingCnts: DataStream[(Int, Int)] = buyCnts // key stream by userId .keyBy(0) // tumbling time window of 1 minute length .timeWindow(Time.minutes(1)) // compute sum over buyCnt .sum(1) Sliding Time Window对于某些应用，它们需要的窗口是不间断的，需要平滑地进行窗口聚合。比如，我们可以每30秒计算一次最近一分钟用户购买的商品总数。这种窗口我们称为滑动时间窗口（Sliding Time Window）。在滑窗中，一个元素可以对应多个窗口。通过使用 DataStream API，我们可以这样实现： 12345val slidingCnts: DataStream[(Int, Int)] = buyCnts .keyBy(0) // sliding time window of 1 minute length and 30 secs trigger interval .timeWindow(Time.minutes(1), Time.seconds(30)) .sum(1) Session Window在这种用户交互事件流中，我们首先想到的是将事件聚合到会话窗口中（一段用户持续活跃的周期），由非活跃的间隙分隔开。如上图所示，就是需要计算每个用户在活跃期间总共购买的商品数量，如果用户30秒没有活动则视为会话断开（假设raw data stream是单个用户的购买行为流）。Session Window 的示例代码如下： 12345678// Stream of (userId, buyCnts)val buyCnts: DataStream[(Int, Int)] = ... val sessionCnts: DataStream[(Int, Int)] = vehicleCnts .keyBy(0) // session window based on a 30 seconds session gap interval .window(ProcessingTimeSessionWindows.withGap(Time.seconds(30))) .sum(1) session 是指一段持续活跃的期间，由活跃间隙分隔开。通俗一点说，消息之间的间隔小于超时阈值（sessionGap）的，则被分配到同一个窗口，间隔大于阈值的，则被分配到不同的窗口。 目前开源领域大部分的流计算引擎都有窗口的概念，但是没有对 session window 的支持，要实现 session window，需要用户自己去做完大部分事情。而当 Flink 1.1.0 版本正式发布时，Flink 将会是开源流计算领域第一个内建支持 session window 的引擎。 在 Flink 1.1.0 之前，Flink 也可以通过自定义的window assigner和trigger来实现一个基本能用的session window。 基于GlobleWindow这个window assigner，将所有元素都分配到同一个窗口中，然后指定一个自定义的trigger来触发执行窗口。这个trigger的触发机制是，对于每个到达的元素都会根据其时间戳（timestamp）注册一个会话超时的定时器（timestamp+sessionTimeout），并移除上一次注册的定时器。最新一个元素到达后，如果超过 sessionTimeout 的时间还没有新元素到达，那么trigger就会触发，当前窗口就会是一个session window。处理完窗口后，窗口中的数据会清空，用来缓存下一个session window的数据。 但是这种session window的实现是非常弱的，无法应用到实际生产环境中的。因为它无法处理乱序 event time 的消息。 Flink 1.1.0 版本中，Flink提供了对session window的直接支持，用户可以通过SessionWindows.withGap()来轻松地定义session widnow，而且能够处理乱序消息。Flink对session window的支持主要借鉴自Google的DataFlow。 Window APIWindow Assigner用来决定某个元素被分配到哪个/哪些窗口中去。 Window本身只是一个ID标识符，其内部可能存储了一些元数据，如TimeWindow中有开始和结束时间，但是并不会存储窗口中的元素。窗口中的元素实际存储在 Key/Value State 中，key为Window，value为元素集合（或聚合值）。为了保证窗口的容错性，该实现依赖了 Flink 的 State 机制（参见 state 文档）。 Trigger触发器。决定了一个窗口何时能够被计算或清除，每个窗口都会拥有一个自己的Trigger。 Trigger的返回结果可以是 continue（不做任何操作），fire（处理窗口数据），purge（移除窗口和窗口中的数据），或者 fire + purge。一个Trigger的调用结果只是fire的话，那么会计算窗口并保留窗口原样，也就是说窗口中的数据仍然保留不变，等待下次Trigger fire的时候再次执行计算。一个窗口可以被重复计算多次知道它被 purge 了。在purge之前，窗口会一直占用着内存。 Evictor可以译为“驱逐者”。在Trigger触发之后，在窗口被处理之前，Evictor（如果有Evictor的话）会用来剔除窗口中不需要的元素，相当于一个filter。 当Trigger fire了，窗口中的元素集合就会交给Evictor（如果指定了的话）。Evictor 主要用来遍历窗口中的元素列表，并决定最先进入窗口的多少个元素需要被移除。剩余的元素会交给用户指定的函数进行窗口的计算。如果没有 Evictor 的话，窗口中的所有元素会一起交给函数进行计算。 上述三个组件的不同实现的不同组合，可以定义出非常复杂的窗口。Flink 中内置的窗口也都是基于这三个组件构成的，当然内置窗口有时候无法解决用户特殊的需求，所以 Flink 也暴露了这些窗口机制的内部接口供用户实现自定义的窗口。 在后面的章节里，我们会从源码剖析Flink的Window机制。 开源推荐在学习Flink的过程中，本人将涉及到的测试案例、源码解读、开发技巧等系统整理了一下，并开源到Github上，地址为： https://github.com/Ruanshubin/awesome-flink 欢迎大家Star支持！]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark从入门到放弃--3RDD和共享变量]]></title>
    <url>%2F2019%2F06%2F14%2FSpark%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83--3RDD%E5%92%8C%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[为进行分布式环境下数据资源的描述，Spark引入了2类抽象概念： 第1个抽象概念是RDD。 RDD基本介绍RDD全称为Resilient Distributed Dataset，即弹性分布式数据集，设计理念源自AMP实验室发表的论文《Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing》。 RDDs是跨集群节点分区的元素集合，可以执行并行操作。 RDDs可以读取HDFS中的文件进行创建，或者由Driver程序的已有Scala集合进行转化后创建。用户可以将RDDs持久存储在内存中，以便在并行操作中复用。 RDD操作一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可以分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算。RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，不能直接修改，只能基于稳定的物理存储中的数据集来创建RDD，或者通过在其他RDD上执行确定的转换操作（如map、join和groupBy）而创建得到新的RDD。 RDD提供了一组丰富的操作以支持常见的数据运算，分为Action和Transformation两种类型。 Action操作 用于执行计算并指定输出的形式，行动操作（比如count、collect等）接受RDD但是返回非RDD（即输出一个值或结果）。 Transformation操作 指定RDD之间的相互依赖关系，转换操作（比如map、filter、groupBy、join等）接受RDD并返回RDD。 RDD提供的转换接口都非常简单，都是类似map、filter、groupBy、join等粗粒度的数据转换操作，而不是针对某个数据项的细粒度修改。因此，RDD比较适合对于数据集中元素执行相同操作的批处理式应用，而不适合用于需要异步、细粒度状态的应用，比如Web应用系统、增量式的网页爬虫等。正因为这样，这种粗粒度转换接口设计，会使人直觉上认为RDD的功能很受限、不够强大。但是，实际上RDD已经被实践证明可以很好地应用于许多并行计算应用中，可以具备很多现有计算框架（比如MapReduce、SQL、Pregel等）的表达能力，并且可以应用于这些框架处理不了的交互式数据挖掘应用。 懒执行及DAGRDD采用了懒执行策略，即在RDD的执行过程中，真正的计算发生在RDD的Action操作，对于Action之前的所有Transformation操作，Spark只是记录下Transformation操作应用的一些基础数据集以及RDD生成的轨迹，即相互之间的依赖关系，而不会触发真正的计算。 如上图，从输入中逻辑上生成A和C两个RDD，经过一系列Transformation操作，逻辑上生成了F（也是一个RDD），之所以说是逻辑上，是因为这时候计算并没有发生，Spark只是记录了RDD之间的生成和依赖关系。当F要进行输出时，也就是当F进行Action操作的时候，Spark才会根据RDD的依赖关系生成DAG，并从起点开始真正的计算。 上述这一系列处理称为一个“血缘关系（Lineage）”，即DAG拓扑排序的结果。采用惰性调用，通过血缘关系连接起来的一系列RDD操作就可以实现管道化（pipeline），避免了多次转换操作之间数据同步的等待，而且不用担心有过多的中间数据，因为这些具有血缘关系的操作都管道化了，一个操作得到的结果不需要保存为中间数据，而是直接管道式地流入到下一个操作进行处理。同时，这种通过血缘关系把一系列操作进行管道化连接的设计方式，也使得管道中每次操作的计算变得相对简单，保证了每个操作在处理逻辑上的单一性；相反，在MapReduce的设计中，为了尽可能地减少MapReduce过程，在单个MapReduce中会写入过多复杂的逻辑。 RDD依赖RDD中不同的操作会使得不同RDD中的分区会产生不同的依赖。RDD中的依赖关系分为窄依赖（Narrow Dependency）与宽依赖（Wide Dependency）。 其实宽、窄依赖的区分非常简单： 若每个父RDD分区仅流向1个子RDD分区，则为窄依赖； 若每个父RDD分区流向多个子RDD分区，则为宽依赖。 对于窄依赖的RDD，可以以流水线的方式计算所有父分区，不会造成网络之间的数据混合。对于宽依赖的RDD，则通常伴随着Shuffle操作，即首先需要计算好所有父分区数据，然后在节点之间进行Shuffle。 Stage划分Spark通过分析各个RDD的依赖关系生成了DAG，再通过分析各个RDD中的分区之间的依赖关系来决定如何划分Stage(阶段)。 具体划分方法是： 在DAG中进行反向解析，遇到宽依赖就断开，遇到窄依赖就把当前的RDD加入到当前的Stage中； 将窄依赖尽量划分在同一个Stage中，可以实现流水线计算。 假设从HDFS中读入数据生成3个不同的RDD（即A、C和E），通过一系列转换操作后再将计算结果保存回HDFS。对DAG进行解析时，在依赖图中进行反向解析，由于从RDD A到RDD B的转换以及从RDD B和F到RDD G的转换，都属于宽依赖，因此，在宽依赖处断开后可以得到三个阶段，即阶段1、阶段2和阶段3。可以看出，在阶段2中，从map到union都是窄依赖，这两步操作可以形成一个流水线操作，比如，分区7通过map操作生成的分区9，可以不用等待分区8到分区9这个转换操作的计算结束，而是继续进行union操作，转换得到分区13，这样流水线执行大大提高了计算的效率。 任务调度器Spark的任务调度器包括DAGScheduler和TaskScheduler。 DAGScheduler把一个Spark作业转换成Stage的DAG（Directed Acyclic Graph有向无环图），根据RDD和Stage之间的关系找出开销最小的调度方法，然后把Stage以TaskSet的形式提交给TaskScheduler。 DAGScheduler决定了运行Task的理想位置，并把这些信息传递给下层的TaskScheduler。此外，DAGScheduler还处理由于Shuffle数据丢失 导致的失败，这有可能需要重新提交运行之前的Stage（非Shuffle数据丢失导致的Task失败由TaskScheduler处理）。 TaskScheduler维护所有TaskSet，当Executor向Driver发送心跳时，TaskScheduler会根据其资源剩余情况分配 相应的Task。另外TaskScheduler还维护着所有Task的运行状态，重试失败的Task。 RDD运行 创建RDD对象； SparkContext负责计算RDD之间的依赖关系，构建DAG； DAGScheduler负责把DAG图分解成多个阶段，每个阶段中包含了多个任务，每个任务会被任务调度器分发给各个工作节点（Worker Node）上的Executor去执行。 Spark的第2抽象概念是共享变量。 共享变量默认情况下，Spark在不同节点的task上并行运行函数时，它会将函数使用的每个变量的副本发送给每个任务。 当需要在tasks之间，或者task与driver之间共享某个变量时，共享变量便登场了。 Spark支持2种类型的共享变量: 广播变量(broadcast variables) 其可以在所有节点的内存中缓存某个Value。 广播变量允许开发人员在每个节点（Worker or Executor）缓存只读变量，而不是在Task之间传递这些变量。使用广播变量能够高效地在集群每个节点创建大数据集的副本。同时Spark还使用高效的广播算法分发这些变量，从而减少通信的开销。 Spark应用程序Job的执行由一系列调度Stage(阶段)构成，而这些调度Stage通过Shuffle进行分隔。Spark能够在每个调度Stage自动广播任务所需通用的数据，这些数据在广播时需进行序列化缓存，并在任务运行前进行反序列化。这就意味着当多个调度Stage的任务需要相同的数据，显示地创建广播变量才有用。 计数器(accumulators) 仅用于执行变量的累加操作，如计数或求和。 Accumulator只提供了累加的功能，但是却给我们提供了多个task对一个变量并行操作的功能。task只能对Accumulator进行累加操作，不能读取它的值。只有Driver程序可以读取Accumulator的值。 累加器只能由Spark内部进行更新，并保证每个任务在累加器的更新操作仅执行一次，也就是说重启任务也不应该更新。在转换操作中，用户必须意识到任务和作业的调度过程重新执行会造成累加器的多次更新。 累加器同样具有Spark懒加载的求值模型。如果它们在RDD的操作中进行更新，它们的值只在RDD进行行动操作时才进行更新。 参考文献: http://spark.apache.org/docs/latest/rdd-programming-guide.html http://dblab.xmu.edu.cn/blog/985-2/ https://www.cnblogs.com/1130136248wlxk/articles/6289717.html https://blog.csdn.net/anbang713/article/details/81588829 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark从入门到放弃--2运行架构]]></title>
    <url>%2F2019%2F06%2F14%2FSpark%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83--2%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[术语表讲解Spark运行架构之前，我们先科普一下Spark集群的相关术语: 基本流程Spark应用运行在集群中的独立进程集中，并通过主进程(Driver)中的SparkContext对象进行进程间的控制协调，其运行架构如下图所示: Cluster Manager(CM)主要负责应用的资源管理，在集群上运行Spark应用时，先由Driver的SparkContext连接CM申请计算资源，然后在集群的Worker节点上启动相应的Exector进程，Executor运行情况将随着心跳发送到资源管理器上。 具体执行任务时，先由SparkContext构建成DAG图，将DAG图分解成Stage，并把Taskset发送给Task Scheduler。Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行同时SparkContext将应用程序代码发放给Executor。 Task在Executor上运行，运行完毕释放所有资源。 SparkContext可以连接不同种类的CM，比如Spark的Standalone、Yarn及Mesos等。 整个架构需要注意以下几点: 不同应用间的Exector是互相独立的，其task也是运行在不同的线程中，该种模式的优点是应用在调度端(每个Driver调度自己的tasks)和执行端(不同应用的tasks运行在不同JVMs中)均是相互独立的。 Spark与底层Cluster Manager类型无关，只要它能获取相应资源，启动Executor进程，并且Executor进程间可以相互通信即可。 Executor上有一个BlockManager存储模块，类似于键值存储系统（把内存和磁盘共同作为存储设备），在处理迭代计算任务时，不需要把中间结果写入到HDFS等文件系统，而是直接放在这个存储系统上，后续有需要时就可以直接读取；在交互式查询场景下，也可以把表提前缓存到这个存储系统上，提高读写IO性能。 任务采用了数据本地性和推测执行等优化机制。数据本地性是尽量将计算移到数据所在的节点上进行，即“计算向数据靠拢”，因为移动计算比移动数据所占的网络资源要少得多。而且，Spark采用了延时调度机制，可以在更大的程度上实现执行过程优化。比如，拥有数据的节点当前正被其他的任务占用，那么，在这种情况下是否需要将数据移动到其他的空闲节点呢？答案是不一定。因为，如果经过预测发现当前节点结束当前任务的时间要比移动数据的时间还要少，那么，调度就会等待，直到当前节点可用。 参考文献: http://spark.apache.org/docs/latest/cluster-overview.html http://dblab.xmu.edu.cn/blog/972-2/ 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark从入门到放弃--1概述]]></title>
    <url>%2F2019%2F06%2F13%2FSpark%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83--1%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[什么是Spark先甩出官网链接: http://spark.apache.org/ 通俗来讲，Spark是一个大数据计算框架。 其具有以下特性: 快速性 Spark在批数据和流数据处理上均具有高效地性能，其快速性主要依赖于DAG任务执行器、计算优化和内存执行引擎。 易用性 支持Java, Scala, Python, R, and SQL等语言，并提供了80多种常用算子，可以使你快速构建并行应用。 普适性 Spark提供了丰富的组件，主要包括SQL、DataFrames、MLlib、GraphX及Spark Streaming，适用于多种场景下的计算任务。 兼容性 Spark可运行在Hadoop(Yarn)、Apache Mesos、Kubernetes(K8s)、独立集群或者云服务器(集群)上，并且支持接入不同种类的数据源。 发展历程 Spark在2009年由Matei Zaharia在加州大学伯克利分校AMPLab开创。 2010年通过BSD许可协议开源发布。 2013年6月，该项目被捐赠给Apache软件基金会并切换许可协议至Apache2.0。 2014年2月，Spark成为Apache的顶级项目。 2014年11月，Databricks团队使用Spark刷新数据排序世界记录。 2014年5月底Spark1.0.0发布。 2014年9月Spark1.1.0发布。 2014年12月Spark1.2.0发布。 … 2016年1月4号Spark1.6.0发布。 … 2016年6月26号Spark2.0发布。 … 时至今日的2.4.3版本。 Spark作为Hadoop生态中重要的一员，其发展速度堪称恐怖，不过其作为一个完整的技术栈，在技术和环境的双重刺激下，得到如此多的关注也是有依据的。核心在于内存计算模型代替Hadoop生态的MapReduce离线计算模型，用更加丰富Transformation和Action算子来替代map,reduce两种算子。 使用Spark的另外一个好处是，Spark的社区比较活跃，且框架一直处于不断优化中，开发过程中若出现问题，方便寻找解决方案。 从Github上也可以看出，直至今日，Spark仍处于Commit高度活跃的状态。 主要组件 Spark Core 包含Spark的基本功能；尤其是定义RDD的API、操作以及这两者上的动作。其他Spark的库都是构建在RDD和Spark Core之上的。 Spark SQL 提供通过Apache Hive的SQL变体Hive查询语言（HiveQL）与Spark进行交互的API。每个数据库表被当做一个RDD，Spark SQL查询被转换为Spark操作。 Spark Streaming 对实时数据流进行处理和控制。Spark Streaming允许程序能够像普通RDD一样处理实时数据。 MLlib 一个常用机器学习算法库，算法被实现为对RDD的Spark操作。这个库包含可扩展的学习算法，比如分类、回归等需要对大量数据集进行迭代的操作。 GraphX 控制图、并行图操作和计算的一组算法和工具的集合。GraphX扩展了RDD API，包含控制图、创建子图、访问路径上所有顶点的操作。 参考文献: http://spark.apache.org/ https://www.cnblogs.com/qingyunzong/p/8886338.html https://hacpai.com/article/1499870999066 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-IOC的XML配置]]></title>
    <url>%2F2019%2F06%2F05%2FSpring-IOC%E7%9A%84XML%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[引言在Springboot编程实践中，我们偏向使用注解的方式进行Bean的注册和依赖注入等，但XML格式的容器信息管理方式仍是Spring提供的最为强大、支持最为全面的方式，本文对Spring-IOC的XML配置进行详细的讲解。 和BeanFactory和ApplicationContext的XML配置均采用统一的格式，在Spring2.0之前，这种格式由Spring提供的DTD规定，即在配置文件的头部，需要以下形式的DOCTYPE声明: 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-//SPRING//DTD BEAN//EN&quot;&quot;http://www.springframework.org/dtd/spring-beans.dtd&quot;&gt;&lt;beans&gt; ...&lt;/beans&gt; 从Spring 2.0版本之后，Spring在继续保持向前兼容的前提下，既可以继续使用DTD方式的 DOCTYPE进行配置文件格式的限定，又引入了基于XML Schema的文档声明： 123456789101112131415161718192021&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:util=&quot;http://www.springframework.org/schema/util&quot; xmlns:jee=&quot;http://www.springframework.org/schema/jee&quot; xmlns:lang=&quot;http://www.springframework.org/schema/lang&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-2.0.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-2.0.xsd http://www.springframework.org/schema/lang http://www.springframework.org/schema/lang/spring-lang-2.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.0.xsd&quot;&gt; ...&lt;/beans&gt; 是配置文件的顶层元素，其可以包含0或1个和多个以及或者 可以配置所有的全局行为，主要包括: default-lazy-init 取值true或false，默认值false，用来标志是否对所有的进行延迟初始化。 default-autowire 可以取值为no、byName、byType、constructor以及autodetect。默认值为 no ，如果使用自动绑定的话，用来标志全体bean使用哪一种默认绑定方式。 default-dependency-check 可以取值none、objects、simple以及all，默认值为none，即不做依赖检查。 default-init-method 如果所管辖的按照某种规则，都有同样名称的初始化方法的话，可以在这里统一指定这个初始化方法名，而不用在每一个上都重复单独指定。 default-destroy-method 与default-init-method相对应，如果所管辖的bean有按照某种规则使用了相同名称的对象销毁方法，可以通过这个属性统一指定。 、和 配置文件的描述信息。 通常情况下，可以根据模块功能或者层次关系，将配置信息分门别类地放到多个配置文件中。在想加载主要配置文件，并将主要配置文件所依赖的配置文件同时加载时，可以在这个主要的配置文件中通过元素对其所依赖的配置文件进行引用。比如，如果A.xml中的定义可能依赖B.xml中的某些定义，那么就可以在A.xml中使用将B.xml引入到A.xml，以类似于 的形式。 可以通过为某些起一些“外号”（别名），通常情况下是为了减少输入。比如，假设有个 ，它的名称为dataSourceForMasterDatabase ，你可以为其添加一个 ，像这样 。以后通过dataSourceForMasterDatabase或者 masterDataSource来引用这个都可以。 id属性 对象在容器里的标识，若未配置，则的id取类名的小驼峰。 除了使用id，也可以使用name来进行标识，它与id的区别是， name可以使用id不能使用的一些字符，比如/。而且还可以通过逗号、空格或者冒号分割指定多个name。name的作用跟使用为id指定多个别名基本相同： 1234&lt;bean id=&quot;person&quot; name=&quot;/china/person,/england/person&quot;/ class=&quot;com.ruanshubin.springboot.entity.Person&quot;&gt;等同于:&lt;alias name=&quot;person&quot; alias=&quot;/china/person&quot;/&gt;&lt;alias name=&quot;person&quot; alias=&quot;/england/person&quot;/&gt; class属性 每个注册到容器的对象都需要通过元素的class属性指定其类型。 依赖注入为了演示依赖注入，我们新建3个实体类，分别为主机、显示器和电脑。 1234567891011121314151617181920212223242526272829303132333435363738public class MainEngine &#123; // 名称 private String name; // 型号 private String type; // 花费 private Integer cost; ... 构造器及get/set方法 toString方法 &#125; public class Display &#123; // 名称 private String name; // 型号 private String type; // 花费 private Integer cost; ... 构造器及get/set方法 toString方法 &#125; public class Computer &#123; // 名称 private String name; // 主机 private MainEngine mainEngine; // 显示器 private Display display; ... 构造器及get/set方法 toString方法 &#125; 构造方法注入在resources目录下新建spring-beans.xml文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:util=&quot;http://www.springframework.org/schema/util&quot; xmlns:jee=&quot;http://www.springframework.org/schema/jee&quot; xmlns:lang=&quot;http://www.springframework.org/schema/lang&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-2.0.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-2.0.xsd http://www.springframework.org/schema/lang http://www.springframework.org/schema/lang/spring-lang-2.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.0.xsd&quot;&gt; &lt;bean id=&quot;display&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Display&quot;&gt; &lt;constructor-arg&gt; &lt;value&gt;惠普&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;V300&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;1000&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;constructor-arg&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot;&gt; &lt;constructor-arg&gt; &lt;value&gt;组装机1&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;ref bean=&quot;mainEngine&quot;&gt;&lt;/ref&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;ref bean=&quot;display&quot;&gt;&lt;/ref&gt; &lt;/constructor-arg&gt; &lt;/bean&gt;&lt;/beans&gt; 编写主函数: 1234567public class IocXmlTest &#123; public static void main(String[] args) &#123; XmlBeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;spring-beans.xml&quot;)); Computer computer = (Computer) beanFactory.getBean(&quot;computer&quot;); System.out.println(computer); &#125;&#125; 运行结果为: 1Computer&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; 可以发现，如果注入的属性为基本数据类型(及其包装类)、String等，则使用进行注入，若为Java对象，则使用的方式进行注入。 同时，上述的顺序要与Java类中属性的顺序要严格一致，否则会出现问题，如将mainEngine的配置修改为: 1234567891011&lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;constructor-arg&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 重新运行主类，结果为: 1Computer&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;T600&apos;, type=&apos;戴尔&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; 可以发现，主机的名称和型号互换，造成异常。 此时，可以添加index标签，其表征了属性的顺序编号，从0开始。 1234567891011&lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;constructor-arg index=&quot;1&quot;&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg index=&quot;0&quot;&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 还有type标签，用于各属性类型不同时配置： 123456789101112&lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;!--不添加type标签会报错--&gt; &lt;constructor-arg type=&quot;Integer&quot;&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 最强大的是name标签，不管的顺序是否与实体类各属性的顺序是否一致，只要保证name一致即可安全注入，如将mainEngine的配置修改为: 1234567891011&lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;constructor-arg name=&quot;cost&quot;&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;type&quot;&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;name&quot;&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 虽然的顺序与实体类的属性顺序完全相反，但是通过name一对一绑定，运行结果仍旧为: 1Computer&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; setter方法注入setter方法使用完成依赖注入，如: 12345&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;组装机1&quot;/&gt; &lt;property name=&quot;mainEngine&quot; ref=&quot;mainEngine&quot;/&gt; &lt;property name=&quot;display&quot; ref=&quot;display&quot;/&gt;&lt;/bean&gt; 需要指出的是，除了value和ref标签，Spring还提供了bean、idref、value、null、list、set、map、props。 具体使用场景，本文不做过多介绍，大家可自行Google。 自动注入autowire除了可以通过配置明确指定bean之间的依赖关系，Spirng还提供了根据bean定义的某些特点将相互依赖的某些bean直接自动绑定的功能。通过 的autowire属性，可以指定当前bean定义采用某种类型的自动绑定模式。这样，你就无需手工明确指定该bean定义相关的依赖关系，从而也可以免去一些手工输入的工作量。 Spring提供了5种自动绑定模式，即 no、byName、byType、constructor和autodetect。 no 默认配置，即不采取自动注入，仅依靠手工配置注入。 byName 按照类中声明的实例变量的名称，与XML配置文件中声明的bean定义的beanName的值进行匹配，相匹配的bean定义将被自动绑定到当前实例变量上。 如我们将上面的computer的注入配置修改为: 12&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot; autowire=&quot;byName&quot;&gt;&lt;/bean&gt; 运行结果为: 1Computer&#123;name=&apos;null&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; 程序会自动寻找id为mainEngine、display的bean来完成注入，因为没有id为name的，所以不能自动注入，该项为null。 可以修改配置，添加无法自动注入的属性: 123&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot; autowire=&quot;byName&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;组装机1&quot;/&gt;&lt;/bean&gt; 此时，再次运行: 1Computer&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; byType 与byName类似，byType是按照类中声明的实例变量的Type，与XML配置文件中声明的bean的Type进行匹配，相匹配的bean定义将被自动绑定到当前实例变量上。 如我们将上面的computer的注入配置修改为: 123&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot; autowire=&quot;byType&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;组装机1&quot;/&gt;&lt;/bean&gt; 运行: 1Computer&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; 此处有个问题，当某个实例变量的Type在Spring容器中存在两个，会选择哪个进行注入呢? 假设在上述spring-beans.xml文件中添加如下配置: 1234567891011&lt;bean id=&quot;mainEngine1&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;constructor-arg name=&quot;cost&quot;&gt; &lt;value&gt;3000&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;type&quot;&gt; &lt;value&gt;X900&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;name&quot;&gt; &lt;value&gt;神州&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 此时，Spring容器里存在2个主机实例，我们仍旧通过byType进行自动注入。 运行主函数: 12Exception in thread &quot;main&quot; org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;computer&apos; defined in class path resource [spring-beans.xml]: Unsatisfied dependency expressed through bean property &apos;mainEngine&apos;; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type &apos;com.ruanshubin.springboot.ioc.entity.MainEngine&apos; available: expected single matching bean but found 2: mainEngine,mainEngine1... 很明显，Spring不会帮你做这个决策，当同一个Type存在多个实例时，程序直接会将错误抛出来，由你来做决策。 constructor constructor类型则是针对构造方法参数的类型而进行的自动绑定，它同样是byType类型的绑定模式。不过，constructor是匹配构造方法的参数类型，而不是实例属性的类型。与byType模式类似，如果找到不止一个符合条件的bean定义，那么，容器会返回错误。 autodetect 是byType和constructor模式的结合体，如果对象拥有默认无参数的构造方法，容器会优先考虑byType的自动绑定模式。否则，会使用constructor模式。当然，如果通过构造方法注入绑定后还有其他属性没有绑定，容器也会使用byType对剩余的对象属性进行自动绑定。 依赖检查及继承依赖检查检查依赖是否按照预期绑定完成，其由dependency-check标签进行约束，存在以下4种模式: none 不做依赖检查 simple 容器会对简单属性类型以及相关的collection进行依赖检查，对象引用类型的依赖除外。 object 只对对象引用类型依赖进行检查。 all simple和object的结合体。 继承新建服务器类，继承自计算机类: 12345678910111213141516171819202122public class Server extends Computer&#123; // 名称 private String name; // 主机 private MainEngine mainEngine; // 显示器 private Display display; // GPU型号 private String gpuType; public Server() &#123; &#125; public Server(String name, MainEngine mainEngine, Display display, String gpuType) &#123; super(name, mainEngine, display); this.gpuType = gpuType; &#125; ... get/set方法 toString方法 &#125; 在spring-beans.xml配置文件中增加如下内容: 123&lt;bean id=&quot;server&quot; parent=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Server&quot;&gt; &lt;property name=&quot;gpuType&quot; value=&quot;TC800&quot;/&gt;&lt;/bean&gt; 修改启动类: 1234567public class IocXmlTest &#123; public static void main(String[] args) &#123; XmlBeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;spring-beans.xml&quot;)); Server server = beanFactory.getBean(&quot;server&quot;, Server.class); System.out.println(server); &#125;&#125; 运行结果为: 1Server&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;, gpuType=&apos;TC800&apos;&#125; 可以看到，我们通过parent标签完成了Bean继承的管理。 Bean的scopeSpring2.0前，Bean容器仅有2种作用域类型，即singleton和prototype，2.0后，又引入了3种web相关的scope类型，即request、session、global session。 singleton 对象实例 容器中只存在一个共享实例。 对象存活时间 第一次请求被实例化到容器销毁或者退出。 prototype 对象实例 容器中存在多个实例。 对象存活时间 每次请求即创建1个新的实例，对象实例返回给请求方之后，容器就不再拥有当前返回对象的引用，请求方需要自己负责当前返回对象的后继生命周期的管理工作，包括该对象的销毁。 request Spring容器，即XmlWebApplicationContext会为每个HTTP请求创建一个全新的Request-Processor对象供当前请求使用，当请求结束后，该对象实例的生命周期即告结束。当同时有10个HTTP请求进来的时候，容器会分别针对这10个请求返回10个全新的RequestProcessor 对象实例，且它们之间互不干扰。 session Spring容器会为每个独立的session创建属于它们自己的全新的UserPreferences对象实例。与request相比，除了拥有session scope的bean的实例具有比request scope的bean可能更长的存活时间，其他方面真是没什么差别。 global session global session只有应用在基于portlet的Web应用程序中才有意义，它映射到portlet的global范围的session。如果在普通的基于servlet的Web应用中使用了这个类型的scope，容器会将其作为普通的session类型的scope对待。 自定义scope 在Spring 2.0之后的版本中，容器提供了对scope的扩展点，这样，你可以根据自己的需要或者应用的场景，来添加自定义的scope类型。需要说明的是，默认的singleton和prototype是硬编码到代码中的，而request、session和global session，包括自定义scope类型，则属于可扩展的scope行列，它们都实现了org.springframework.beans.factory.config.Scope接口。 具体如何进行自定义scope的设计开发，以后我们专门写篇文章介绍。 下面看一个有意思的东西: 去除掉MainEngine的toString()方法，并将mainEngine的scope设置为prototype。 1234567891011 &lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot; scope=&quot;prototype&quot;&gt; &lt;constructor-arg name=&quot;cost&quot;&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;type&quot;&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;name&quot;&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 修改主函数: 12345678public class IocXmlTest &#123; public static void main(String[] args) &#123; XmlBeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;spring-beans.xml&quot;)); Computer computer = (Computer) beanFactory.getBean(&quot;computer&quot;); System.out.println(computer.getMainEngine()); System.out.println(computer.getMainEngine()); &#125;&#125; 运行: 12com.ruanshubin.springboot.ioc.entity.MainEngine@4dfa3a9dcom.ruanshubin.springboot.ioc.entity.MainEngine@4dfa3a9d 显然，2次获取的MainEngine实例是同一个。 那么，如何在每次获取MainEngine时，总返回新创建的实例呢，可以使用标签: 123456&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;组装机1&quot;/&gt; &lt;property name=&quot;mainEngine&quot; ref=&quot;mainEngine&quot;/&gt; &lt;property name=&quot;display&quot; ref=&quot;display&quot;/&gt; &lt;lookup-method name=&quot;getMainEngine&quot; bean=&quot;mainEngine&quot;/&gt;&lt;/bean&gt; 再次运行主函数: 12com.ruanshubin.springboot.ioc.entity.MainEngine@480bdb19com.ruanshubin.springboot.ioc.entity.MainEngine@2a556333 达到目的。 同时，可以对Computer的getMainEngine进行改造，使其每次从BeanFactory中取MainEngine得实例，操作方法是使Computer实现BeanFactoryAware接口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Computer implements BeanFactoryAware &#123; private BeanFactory beanFactory; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = beanFactory; &#125; // 名称 private String name; // 主机 private MainEngine mainEngine; // 显示器 private Display display; public Computer() &#123; &#125; public Computer(String name, MainEngine mainEngine, Display display) &#123; this.name = name; this.mainEngine = mainEngine; this.display = display; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public MainEngine getMainEngine() &#123; return beanFactory.getBean(&quot;mainEngine&quot;, MainEngine.class); &#125; public void setMainEngine(MainEngine mainEngine) &#123; this.mainEngine = mainEngine; &#125; public Display getDisplay() &#123; return display; &#125; public void setDisplay(Display display) &#123; this.display = display; &#125;&#125; 此时，去掉以下配置，运行上述主程序: 1&lt;lookup-method name=&quot;getMainEngine&quot; bean=&quot;mainEngine&quot;/&gt; 运行结果为: 12com.ruanshubin.springboot.ioc.entity.MainEngine@402a079ccom.ruanshubin.springboot.ioc.entity.MainEngine@59ec2012 仍然可达到目的。 当然，如果不想实现BeanFactoryAware接口，也可以采用ObjectFactoryCreatingFactoryBean方式。 ObjectFactoryCreatingFactoryBean是Spring提供的一个FactoryBean实现，它返回一个ObjectFactory实例。从ObjectFactoryCreatingFactoryBean返回的这个ObjectFactory实例可以为我们返回容器管理的相关对象。 首先，在spring-beans.xml里配置ObjectFactoryCreatingFactoryBean，并注入主机类。 12345678910111213&lt;bean id=&quot;objectFactory&quot; class=&quot;org.springframework.beans.factory.config.ObjectFactoryCreatingFactoryBean&quot;&gt; &lt;property name=&quot;targetBeanName&quot;&gt; &lt;idref bean=&quot;mainEngine&quot;/&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;组装机1&quot;/&gt; &lt;property name=&quot;display&quot; ref=&quot;display&quot;/&gt; &lt;property name=&quot;objectFactory&quot;&gt; &lt;ref bean=&quot;objectFactory&quot;/&gt; &lt;/property&gt;&lt;/bean&gt; 同时修改Computer类: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Computer&#123; private ObjectFactory objectFactory; public void setObjectFactory(ObjectFactory objectFactory) &#123; this.objectFactory = objectFactory; &#125; // 名称 private String name; // 主机 private MainEngine mainEngine; // 显示器 private Display display; public Computer() &#123; &#125; public Computer(String name, MainEngine mainEngine, Display display) &#123; this.name = name; this.mainEngine = mainEngine; this.display = display; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public MainEngine getMainEngine() &#123; return (MainEngine) objectFactory.getObject(); &#125; public void setMainEngine(MainEngine mainEngine) &#123; this.mainEngine = mainEngine; &#125; public Display getDisplay() &#123; return display; &#125; public void setDisplay(Display display) &#123; this.display = display; &#125;&#125; 运行结果为: 12com.ruanshubin.springboot.ioc.entity.MainEngine@5cb9f472com.ruanshubin.springboot.ioc.entity.MainEngine@56ef9176 写着写着就写多了，更多Spring-IOC容器XML配置的东西，我们后面有机会再讲。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring容器之BeanFactory]]></title>
    <url>%2F2019%2F06%2F04%2FSpring%E5%AE%B9%E5%99%A8%E4%B9%8BBeanFactory%2F</url>
    <content type="text"><![CDATA[引言Spring提供了两种容器类型: BeanFactory ApplicationContext 其中ApplicationContext间接继承自BeanFactory，两者最大的不同是容器初始化策略。 BeanFactory采用懒加载(lazy-load)策略，即当客户端需要访问容器内的某个对象时，才对该对象进行初始化以及依赖注入操作。所以该模式下，启动速度较快，适用于资源有限，对功能要求不是很严格的场景。 ApplicationContext所管理的对象，默认启动之后全部初始化并绑定完成，故启动速度较慢，但其除了拥有BeanFactory的所有支持，还提供事件发布、国际化信息支持等，所以适用于系统资源充足，并且要求更多功能的场景。 本文首先讲解BeanFactory。 BeanFactory、BeanDefinitionRegistry和Bean的关系BeanFactory主要完成2项工作: 业务对象的初始化及注册； 对象间依赖关系的绑定。 看一下BeanFactory的源码： 12345678910111213141516171819202122232425262728public interface BeanFactory &#123; String FACTORY_BEAN_PREFIX = &quot;&amp;&quot;; Object getBean(String var1) throws BeansException; &lt;T&gt; T getBean(String var1, @Nullable Class&lt;T&gt; var2) throws BeansException; Object getBean(String var1, Object... var2) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; var1) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; var1, Object... var2) throws BeansException; boolean containsBean(String var1); boolean isSingleton(String var1) throws NoSuchBeanDefinitionException; boolean isPrototype(String var1) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String var1, ResolvableType var2) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String var1, @Nullable Class&lt;?&gt; var2) throws NoSuchBeanDefinitionException; @Nullable Class&lt;?&gt; getType(String var1) throws NoSuchBeanDefinitionException; String[] getAliases(String var1);&#125; 可以发现，BeanFactory接口只定义了查询相关的方法，例如: 取得某个对象的方法（getBean）、查询某个对象是否存在于容器中的方法（containsBean），或者取得某个bean的状态或者类型的方法等。 而对象的注册管理及依赖绑定则交给BeanFactory的接口实现类来完成，如常见的DefaultListableBeanFactory。 12345public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; ...&#125; DefaultListableBeanFactory还实现了BeanDefinitionRegistry接口，来完成Bean的注册管理。 简单阐释一下BeanFactory、BeanDefinitionRegistry和Bean的关系： Bean是图书，BeanFactory相当于图书馆，而BeanDefinitionRegistry则相当于图书馆的书架。虽然还书和借书均是跟图书馆(BeanFactory)打交道，但是图书馆实际存储书的地方是书架(BeanDefinitionRegistry)。 每个Bean交给BeanFactory管理时，均会包装成BeanDefination接口的实例，BeanDefination实例负责保存Bean所有必要的信息，包括Class类型、是否是抽象类、构造方法参数及其他属性等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement &#123; String SCOPE_SINGLETON = &quot;singleton&quot;; String SCOPE_PROTOTYPE = &quot;prototype&quot;; int ROLE_APPLICATION = 0; int ROLE_SUPPORT = 1; int ROLE_INFRASTRUCTURE = 2; void setParentName(@Nullable String var1); @Nullable String getParentName(); void setBeanClassName(@Nullable String var1); @Nullable String getBeanClassName(); void setScope(@Nullable String var1); @Nullable String getScope(); void setLazyInit(boolean var1); boolean isLazyInit(); void setDependsOn(@Nullable String... var1); @Nullable String[] getDependsOn(); void setAutowireCandidate(boolean var1); boolean isAutowireCandidate(); void setPrimary(boolean var1); boolean isPrimary(); void setFactoryBeanName(@Nullable String var1); @Nullable String getFactoryBeanName(); void setFactoryMethodName(@Nullable String var1); @Nullable String getFactoryMethodName(); ConstructorArgumentValues getConstructorArgumentValues(); default boolean hasConstructorArgumentValues() &#123; return !this.getConstructorArgumentValues().isEmpty(); &#125; MutablePropertyValues getPropertyValues(); default boolean hasPropertyValues() &#123; return !this.getPropertyValues().isEmpty(); &#125; boolean isSingleton(); boolean isPrototype(); boolean isAbstract(); int getRole(); @Nullable String getDescription(); @Nullable String getResourceDescription(); @Nullable BeanDefinition getOriginatingBeanDefinition();&#125; RootBeanDefinition和ChildBeanDefinition是BeanDefinition的两个主要实现类。 BeanFactory的对象注册与依赖绑定方式假设我们有一家饭店，需要有蔬菜采购和厨师做菜，则Restaurant类定义如下: 123456789public class Restaurant &#123; // 厨师 private Chef chef; // 蔬菜 private Vegetable vegetable; 构造方法... get/set方法...&#125; 蔬菜存在多种，我们抽象出Vegetable接口，并存在购买行为。 123public interface Vegetable &#123; public String buy();&#125; 编写2个Vegetable接口的实现类Tomato、Cabbage: 123456789101112131415public class Tomato implements Vegetable &#123; @Override public String buy() &#123; System.out.println(&quot;采购员买来了番茄!&quot;); return &quot;Tomato&quot;; &#125;&#125;public class Cabbage implements Vegetable &#123; @Override public String buy() &#123; System.out.println(&quot;采购员买来了卷心菜!&quot;); return &quot;Cabbage&quot;; &#125;&#125; 厨师也可能有多种，抽象出Chef接口如下: 123public interface Chef &#123; public void cook(String vegetableName);&#125; 并编写2个Chef的实现类: 1234567891011121314public class ChineseChef implements Chef &#123; @Override public void cook(String vegetableName) &#123; System.out.println(&quot;中国厨师正在做&quot; + vegetableName + &quot;!&quot;); &#125;&#125;public class ForeignChef implements Chef &#123; @Override public void cook(String vegetableName) &#123; System.out.println(&quot;外国厨师正在做&quot; + vegetableName + &quot;!&quot;); &#125;&#125; 假设我们现在要开这样一家饭店，需要中国厨师和番茄，那么如何完成对象的注册管理和依赖绑定呢? 直接编码形式所谓直接编码形式，即用Spring的底层容器类来进行Bean的注册和管理，虽然不常用，但却有助于我们了解Spring的IOC是如何运作的。 12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; public static void main(String[] args) &#123; DefaultListableBeanFactory beanRegistry = new DefaultListableBeanFactory(); BeanFactory container = bindViaCode(beanRegistry); // 测试Bean的装配 Restaurant chineseRestaurant = (Restaurant) container.getBean(&quot;chineseRestaurant&quot;); Vegetable vegetable = chineseRestaurant.getVegetable(); String vegetableName = vegetable.buy(); Chef chef = chineseRestaurant.getChef(); chef.cook(vegetableName); // 测试Bean的管理 Chef chef1 = (Chef) container.getBean(&quot;chineseChef&quot;); chef1.cook(&quot;干锅花菜&quot;); &#125; public static BeanFactory bindViaCode(BeanDefinitionRegistry registry)&#123; AbstractBeanDefinition restaurant = new RootBeanDefinition(Restaurant.class); AbstractBeanDefinition chef = new RootBeanDefinition(ChineseChef.class); AbstractBeanDefinition vegetable = new RootBeanDefinition(Tomato.class); // 将Bean注册到容器中 registry.registerBeanDefinition(&quot;chineseRestaurant&quot;, restaurant); registry.registerBeanDefinition(&quot;chineseChef&quot;, chef); registry.registerBeanDefinition(&quot;tomato&quot;, vegetable); // 1. 指定依赖关系(构造方法注入) ConstructorArgumentValues argValues = new ConstructorArgumentValues(); argValues.addIndexedArgumentValue(0, chef); argValues.addIndexedArgumentValue(1, vegetable); restaurant.setConstructorArgumentValues(argValues); // 2. 指定依赖关系(setter方法注入) MutablePropertyValues propertyValues = new MutablePropertyValues(); propertyValues.addPropertyValue(new PropertyValue(&quot;chef&quot;, chef)); propertyValues.addPropertyValue(new PropertyValue(&quot;vegetable&quot;, vegetable)); restaurant.setPropertyValues(propertyValues); // 绑定完成 return (BeanFactory) registry; &#125;&#125; 运行结果如下: 123采购员买来了番茄!中国厨师正在做Tomato!中国厨师正在做干锅花菜! 外部配置文件形式其实就是将Bean的依赖关系放在配置文件中，然后Spring解析配置文件，得到各对象的依赖关系，进而完成对象的注册和依赖管理。 整体的流程如下: BeanDefinitionReader实现类读取配置文件内容，并映射得到待管理Bean的BeanDefinition; BeanDefinitionReader根据配置文件内容定义的依赖关系，通过BeanDefinition指定Bean之间的依赖关系; 将映射后的BeanDefinition注册到BeanDefinitionRegistry中。 上述大部分的工作，如解析文件格式、装配BeanDefinition之类的工作，均由BeanDefinitionReader实现类来完成，BeanDefinitionRegistry仅是负责Bean的保管而已。 整个过程类似于如下代码: 1234BeanDefinitionRegistry beanRegistry = &lt;某个 BeanDefinitionRegistry 实现类，通常为DefaultListableBeanFactory&gt;;BeanDefinitionReader beanDefinitionReader = new BeanDefinitionReaderImpl(beanRegistry);beanDefinitionReader.loadBeanDefinitions(&quot;配置文件路径&quot;);// 现在我们就取得了一个可用的BeanDefinitionRegistry实例 看一下BeanDefinitionReader： 12345678910111213141516171819public interface BeanDefinitionReader &#123; BeanDefinitionRegistry getRegistry(); @Nullable ResourceLoader getResourceLoader(); @Nullable ClassLoader getBeanClassLoader(); BeanNameGenerator getBeanNameGenerator(); int loadBeanDefinitions(Resource var1) throws BeanDefinitionStoreException; int loadBeanDefinitions(Resource... var1) throws BeanDefinitionStoreException; int loadBeanDefinitions(String var1) throws BeanDefinitionStoreException; int loadBeanDefinitions(String... var1) throws BeanDefinitionStoreException;&#125; 可以看出，BeanDefinitionReader通过getRegistry()获取BeanDefinitionRegistry，getResourceLoader()加载配置文件资源用于解析Bean的注册和依赖关系，getBeanClassLoader()获取类加载器用于类的加载，loadBeanDefinitions(..)方法主要运用反射将待管理的Bean封装成BeanDefinition，最后注册到BeanDefinitionRegistry中。 由上图可以看出，Spring的IOC容器默认支持3种文件格式: Properties文件格式 XML文件格式 Groovy文件格式 本文主要讨论前2种文件格式: Properties文件首先在resources目录下创建beans.properties文件: 12345678910# bean的name.(class)=实现类的全路径chef.(class)=com.ruanshubin.springboot.ioc.service.impl.ChineseChefvegetable.(class)=com.ruanshubin.springboot.ioc.service.impl.Tomatorestaurant.(class)=com.ruanshubin.springboot.ioc.domain.Restaurant# 通过构造方法注入restaurant.$0(ref)=chefrestaurant.$1(ref)=vegetable# 通过setter方法注入# restaurant.setChef(ref)=chef# restaurant.setVegetable(ref)=vegetable 然后编写主函数: 123456789101112131415161718192021public class FileTest &#123; public static void main(String[] args) &#123; DefaultListableBeanFactory beanRegistry = new DefaultListableBeanFactory(); BeanFactory container = bindViaPropertiesFile(beanRegistry); // 测试Bean的装配 Restaurant chineseRestaurant = (Restaurant) container.getBean(&quot;restaurant&quot;); Vegetable vegetable = chineseRestaurant.getVegetable(); String vegetableName = vegetable.buy(); Chef chef = chineseRestaurant.getChef(); chef.cook(vegetableName); // 测试Bean的管理 Chef chef1 = (Chef) container.getBean(&quot;chef&quot;); chef1.cook(&quot;蒜蓉空心菜!&quot;); &#125; public static BeanFactory bindViaPropertiesFile(BeanDefinitionRegistry registry)&#123; PropertiesBeanDefinitionReader reader = new PropertiesBeanDefinitionReader(registry); reader.loadBeanDefinitions(&quot;classpath:beans.properties&quot;); return (BeanFactory) registry; &#125;&#125; 运行结果如下: 123采购员买来了番茄!中国厨师正在做Tomato!中国厨师正在做蒜蓉空心菜! XML文件XML配置格式是Spring支持最完整，功能最强大的表达方式，主要得益于: XML良好的语意表达能力； Spring框架从开始就自始至终保持XML配置加载的统一性。 Spring 2.x之前，XML配置文件采用DTD（Document Type Definition）实现文档的格式约束。2.x之后，引入了基于XSD（XML Schema Definition）的约束方式。不过，原来的基于DTD的方式依然有效，因为从DTD转向XSD只是“形式”上的转变。 首先在resources目录下创建beans.xml文件: 1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-//SPRING//DTD BEAN//EN&quot; &quot;http://www.springframework.org/dtd/spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;bean id=&quot;restaurant&quot; class=&quot;com.ruanshubin.springboot.ioc.domain.Restaurant&quot;&gt; &lt;constructor-arg index=&quot;0&quot;&gt; &lt;ref bean=&quot;chef&quot;/&gt; &lt;/constructor-arg&gt; &lt;constructor-arg index=&quot;1&quot;&gt; &lt;ref bean=&quot;vegetable&quot;/&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=&quot;chef&quot; class=&quot;com.ruanshubin.springboot.ioc.service.impl.ForeignChef&quot;/&gt; &lt;bean id=&quot;vegetable&quot; class=&quot;com.ruanshubin.springboot.ioc.service.impl.Cabbage&quot;/&gt;&lt;/beans&gt; 主函数: 123456789101112131415161718192021222324public class FileTest &#123; public static void main(String[] args) &#123; DefaultListableBeanFactory beanRegistry = new DefaultListableBeanFactory(); BeanFactory container = bindViaXmlFile(beanRegistry); // 测试Bean的装配 Restaurant chineseRestaurant = (Restaurant) container.getBean(&quot;restaurant&quot;); Vegetable vegetable = chineseRestaurant.getVegetable(); String vegetableName = vegetable.buy(); Chef chef = chineseRestaurant.getChef(); chef.cook(vegetableName); // 测试Bean的管理 Chef chef1 = (Chef) container.getBean(&quot;chef&quot;); chef1.cook(&quot;法式焗蜗牛&quot;); &#125; public static BeanFactory bindViaXmlFile(BeanDefinitionRegistry registry)&#123; XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(registry); reader.loadBeanDefinitions(&quot;classpath:beans.xml&quot;); return (BeanFactory) registry; // 或者直接如下: // return new XmlBeanFactory(new ClassPathResource(&quot;beans.xml&quot;)); &#125;&#125; 运行结果如下: 123采购员买来了卷心菜!外国厨师正在做Cabbage!外国厨师正在做法式焗蜗牛! 当然，如果你想使用其他格式的配置文件来进行Bean的注册和依赖管理，可以实现自定义的BeanDefinitionReader来达到自定义文件加载的目的。 注解形式基于注解的方式，主要是通过@Autowired及@Component对相关类进行标记，然后通过AbstractApplicationContext借助classpath-scanning功能来完成Bean的注册和依赖管理。 首先为相关类添加注解: 1234567891011121314151617181920@Componentpublic class Restaurant &#123; // 厨师 @Autowired private Chef chef; // 蔬菜 @Autowired private Vegetable vegetable; ... &#125; @Componentpublic class Tomato implements Vegetable &#123; ...&#125;@Componentpublic class ChineseChef implements Chef &#123; ...&#125; @Autowired用于依赖注入，@Component用于Bean注册，接下来配置注解扫描。 在resources目录下新建spring.xml: 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;com.ruanshubin.springboot.ioc&quot;/&gt;&lt;/beans&gt; 会到指定的包（package）下面扫描标注有@Component的类，如果找到，则将它们添加到容器进行管理，并根据它们所标注的@Autowired为这些类注入符合条件的依赖对象。 主函数: 12345678910111213public class AnnotationTest &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;spring.xml&quot;); Restaurant chineseRestaurant = (Restaurant) ctx.getBean(&quot;restaurant&quot;); Vegetable vegetable = chineseRestaurant.getVegetable(); String vegetableName = vegetable.buy(); Chef chef = chineseRestaurant.getChef(); chef.cook(vegetableName); // 测试Bean的管理 Chef chef1 = (Chef) ctx.getBean(&quot;chineseChef&quot;); chef1.cook(&quot;鸡蛋韭菜水饺&quot;); &#125;&#125; 运行结果为: 123采购员买来了番茄!中国厨师正在做Tomato!中国厨师正在做鸡蛋韭菜水饺! 我们再配置Bean时，只是在实体类上加了@Component注解，并没有指定Bean的id或name，ApplicationContext默认采用实体类的小驼峰作为id，如ChineseChef的id为chineseChef，Tomato的id为tomato。 同时，在配置Bean依赖时，@Autowired加在接口之上，如: 12@Autowiredprivate Chef chef; 由于我们只在ChineseChef添加了@Component注解，所以Spring容器里只有1个Chef的实现类，此时，ApplicationContext直接将ChineseChef注入到Restaurant中。 假如Spring容器里有2个Chef的实现类.会出现什么情况呢? 只需要在ForeignChef上添加@Component即可。 1234@Componentpublic class ForeignChef implements Chef &#123; ... &#125; 重新运行主函数，报错: 12Exception in thread &quot;main&quot; org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;restaurant&apos;: Unsatisfied dependency expressed through field &apos;chef&apos;; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type &apos;com.ruanshubin.springboot.ioc.service.Chef&apos; available: expected single matching bean but found 2: chineseChef,foreignChef ... 错误信息很明显，说进行Restaurant依赖注入的时候，发现Chef接口有2个实现类:chineseChef、foreignChef，程序不知道该选择哪个进行注入。 解决上述错误的方式有很多，后面我们专门用1篇文章进行讲解。 参考文献: 王福强. Spring揭秘[M]. 2009. 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程-valatile关键字]]></title>
    <url>%2F2019%2F05%2F28%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-valatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[引言很久之前就想写volatile关键字，但是迟迟没有动笔，主要是volatile涉及到的东西有点多，讲不清楚倒还好，就怕反而把读者绕晕了，哈哈。 volatile关键字是为了保证内存可见性及有序性的，首先介绍并发编程中涉及到的3个问题: 并发编程规则原子性原子具有不可分割性，所谓原子性，指的是一个或多个操作，要么全部执行且执行过程不会被任何因素打断，要么就全部执行，其与事务的语义是一致的。 比如经典的转账问题: 小明给小强转账1000元，该操作分为2步: 小明的账户减少1000元； 小强的账户增加1000元。 如果上述操作是非原子的，假如步骤1执行成功，而步骤2则异常中断，此时就会造成小明平白无故丢失了1000元。 在Java中，主要通过synchronized关键字、Lock接口来实现多个操作的原子性。 可见性所谓可见性，指的线程之间的可见性，一个线程修改的状态对另外的线程是可见的。 在Java中valatile、synchronized和final实现了可见性。 有序性即程序执行的顺序按照代码的先后顺序执行。 1234int i = 0;boolean flag = false;i =1; // 语句1flag = true; // 语句2 程序本来就是按照代码顺序来执行的呀，为啥还要保证？一切因为指令重排序(Instruction Reorder)的存在。 处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 也就是说，语句2可能会在语句1之前执行。 接着看下面的操作: 1234int a = 6; // 语句1int b = 2; // 语句2a = a + 3; // 语句3b = a * a; // 语句4 现在问题来了，语句4可能在语句3之前执行吗? 答案是不可能，因为指令重排序会分析语句间的数据依赖性，假设语句B依赖于语句A，即语句B需要使用语句A的结果，则不会发生指令重排序。 所以，单线程环境下，指令重排序只是为了提高运行速度，并不会影响运算结果，但多线程环境下呢，看以下语句: 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2//线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 在Java中synchronized、Lock、volatile实现了有序性。 volatile关键字是与Java内存模型紧密相关的，所以我们先简单讲解一下Java的内存模型。 Java内存模型众所周知，CPU在执行程序指令的过程中，势必涉及到数据的读取和存入，运行过程中的中间数据存储在物理内存中。 物理内存的数据存取速度和CPU的运行速度相比，基本等同于蜗牛和波音747，所以高速缓存出现了。 高速缓存的速度虽然还是比不上CPU，但是比物理内存(主内存)还是要快多了。 所以程序进行计算时，会将需要用到的数据先从主内存取到高速缓存中，然后CPU从高速缓存中取数据进行计算，计算的中间结果存入高速缓存，计算结束后将结果由高速缓存刷新到主内存。 上述模式在单线程环境下没有问题，但是多线程下可能就会出问题，比如简单的i++操作: 12i=0;i++; 假设线程A和线程B分别执行了i++操作，理论上最终结果应该为2，但实际上也可能为1。 原因是i++操作实际上分为2步: 将主内存中i的值取到高速缓存； CPU从高速缓存取出i，完成+1操作后，存入高速缓存，并刷新到主内存。 如果线程A和B同时执行了步骤1，此时线程A和B的高速缓存中的值均为0，完成+1操作后分别刷新到主内存中，最终结果为1，即出现了缓存一致性问题。 为解决缓存一致性问题，一般采取两种方式： 在总线上加LOCK#锁； 缓存一致性协议。 上述两种方式均是基于硬件指令实现的。 在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 Java内存模型具备一些先天的有序性，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为happens-before原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 happens-before原则主要包括: 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作。 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作。 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作。 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行。 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始。 后4项原则是必然的，具体看一下前4项。 程序次序规则保证了单线程环境下，指令重排序不会影响运行结果。 锁定规则也很显然，当某线程获取对象锁之前，必须先等待其他线程释放锁。 volatile变量规则指的是如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 传递规则实际上就是体现happens-before原则具备传递性。 介绍了并发编程规则及Java的内存模型，下面我们深入分析一下volatile关键字: volatile关键字基本语义 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 禁止进行指令重排序。 第1个语义不多讲，其与缓存一致性协议基本类似，下面看一下第2个语义： 还是沿用上面的例子: 123456789//线程1:context = loadContext(); //语句1volatile inited = true; //语句2//线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); inited由volatile修饰后，则语句1和语句2不会发生重排序，保证inited = true时，运行上下文context必定加载完毕，从而避免了上述多线程下的运行异常。 实现机制下面这段话摘自《深入理解Java虚拟机》： 观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令。 lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 它会强制将对缓存的修改操作立即写入主存； 如果是写操作，它会导致其他CPU中对应的缓存行无效。 应用场景 状态变量 123456789//线程1:context = loadContext(); //语句1volatile inited = true; //语句2//线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 单例模式的双重校验 1234567891011121314public class Singleton &#123; private Singleton() &#123; &#125; private volatile static Singleton instance; public Singleton getInstance()&#123; if(instance==null)&#123; synchronized (Singleton.class)&#123; if(instance==null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 之所以instance需要使用volatile修饰，是因为下述语句可能会发生指令重排序: 1instance = new Singleton(); 上述操作分为2步: 初始化对象； 将对象指针赋给instance。 假设步骤1、2发生了重排序，即步骤2在步骤1之前执行，当其他读取线程进行单例读取时，此时步骤2已执行完成，读取线程判断instance非null，故进行读取，但此时步骤1可能还未完成，即对象还未初始化完成，从而导致读取线程发生异常。 instance添加volatile关键字后，步骤1和2禁止指令重排序，从而避免了上述问题。 ConcurrentHashMap volatile关键字在ConcurrentHashMap中的应用，可以参见我的另外一篇文章: ConcurrentHashMap揭秘-JDK1.7 参考文献： https://www.cnblogs.com/zhengbin/p/5654805.html https://www.cnblogs.com/dolphin0520/p/3920373.html https://blog.csdn.net/u013412772/article/details/80109727 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap揭秘-JDK1.7]]></title>
    <url>%2F2019%2F05%2F28%2FConcurrentHashMap%E6%8F%AD%E7%A7%98-JDK1.7%2F</url>
    <content type="text"><![CDATA[引言HashMap是非线程安全的，而HashTable是线程安全的，但是HashTable实现同步的方法比较暴力，即在所有方法体上添加synchronized关键字，相当于所有读写线程均去读取一把锁，效率比较低下。 另外一种同步Map的方法是使用Collections工具类： 1Collections.synchronized（new HashMap() 该种方法与HashTable实现方式类似，也是通过锁住整表来实现同步的。 而ConcurrentHashMap则避免了上述两种Map同步方式锁住全表的问题。 众所周知，HashMap是根据散列值分段存储的，同步Map在同步的时候锁住了所有的段，而ConcurrentHashMap加锁的时候根据散列值锁住了散列值锁对应的那段，因此提高了并发性能。ConcurrentHashMap也增加了对常用复合操作的支持，比如”若没有则添加”：putIfAbsent()，替换：replace()。这2个操作都是原子操作。 ConcurrentHashMap可以做到读取数据不加锁，并且其内部的结构可以让其在进行写操作的时候能够将锁的粒度保持地尽量地小，不用对整个ConcurrentHashMap加锁。 再次声明，本文介绍的ConcurrentHashMap是JDK1.7版本的，JDK1.8对ConcurrentHashMap做了较多改进，后面会专门写一篇文章介绍。 ConcurrentHashMap的内部结构 可以看到，ConcurrentHashMap内部采用了一种叫Segment的数据结构，很明显它就是一个数组table(哈希桶)，数据的元素就是大家熟悉的HashEntry(哈希链)。 简单来讲，就是ConcurrentHashMap比HashMap多了一次hash过程，第1次hash定位到Segment，第2次hash定位到HashEntry，然后链表搜索找到指定节点。 该种实现方式的缺点是hash过程比普通的HashMap要长，但是优点也很明显，在进行写操作时，只需锁住写元素所在的Segment即可，其他Segment无需加锁，提高了并发读写的效率。 Segment1234567static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; transient volatile int count; transient int modCount; transient int threshold; transient volatile HashEntry&lt;K,V&gt;[] table; final float loadFactor;&#125; 可以看出，Segment继承了ReentrantLock并实现了序列化接口，说明Segment的锁是可重入的。 count: Segment中元素的数量，由volatile修饰，支持内存可见性； modCount: 对table的大小造成影响的操作的数量（比如put或者remove操作）; threshold：扩容阈值; table：链表数组，数组中的每一个元素代表了一个链表的头部; loadFactor: 负载因子。 可以发现，Segment的数据结构与普通的HashMap基本类似，只是通过继承ReentrantLock可实现加锁操作。 HashEntrySegment中的元素是以HashEntry的形式存放在链表数组中的，其结构与普通HashMap的HashEntry基本一致，不同的是Segment的HashEntry，其value由volatile修饰，以支持内存可见性，即写操作对其他读线程即时可见。 123456static final class HashEntry&lt;K,V&gt; &#123; final K key; final int hash; volatile V value; final HashEntry&lt;K,V&gt; next;&#125; 看完数据结构，接着看初始化过程： ConcurrentHashMap的初始化直接跟源码: 123456789101112131415161718192021222324252627282930313233343536373839404142// initialCapacity: 初始容量// loadFactor: 负载因子// concurrencyLevel： ConcurrentHashMap内部的Segment的数量public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); // 若concurrencyLevel大于MAX_SEGMENTS，则concurrencyLevel=MAX_SEGMENTS if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // 求解concurrencyLevel与2的几次方最近(天花板方向) // 如concurrencyLevel=5 则天花板方向上离2^3=8最近，则sshift=3，ssize=8 int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; // segmentShift和segmentMask主要用于元素的hash segmentShift = 32 - sshift; segmentMask = ssize - 1; // 可以看到，实际segment的数量为ssize this.segments = Segment.newArray(ssize); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; // 若initialCapacity / ssize不整除，则将c=c+1 if (c * ssize &lt; initialCapacity) ++c; int cap = 1; // cap为每个segment的初始容量，其值为离c天花板方向最近的2^n // 例：c为5，cap则为2^3=8；c为12，cap则为2^4=16 while (cap &lt; c) cap &lt;&lt;= 1; // 创建Segment for (int i = 0; i &lt; this.segments.length; ++i) this.segments[i] = new Segment&lt;K,V&gt;(cap, loadFactor);&#125; 需要注意的是，concurrencyLevel一经指定，便不能再次改变，原因也很简单，简化元素增多时的rehash过程，若Segment的数量也随元素的增加而进行扩容，则需要进行两次rehash，需要处理全部元素，效率较低。 随着元素的增加，ConcurrentHashMap不会增加Segment的数量，而只会增加Segment中链表数组的容量大小，这样的好处是扩容过程不需要对整个ConcurrentHashMap做rehash，而只需要对Segment里面的元素做一次rehash就可以了。 ConcurrentHashMap的get操作1234567public V get(Object key) &#123; // 首先计算key的hash值 int hash = hash(key.hashCode()); // segmentFor(hash): 定位到key在哪个segment // 调用segment的get(key, hash)获取到指定key的value return segmentFor(hash).get(key, hash);&#125; 接着跟进segmentFor(hash): 123final Segment&lt;K,V&gt; segmentFor(int hash) &#123; return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];&#125; 重新回顾一下，ConcurrentHashMap初始化时，确定的2个参数： 12segmentShift = 32 - sshift;segmentMask = ssize - 1; 其中，ssize = 2^sshift，ssize即为Segment的数量。 我们知道： 12// 通过位运算简化求余操作hash % (2^n) = hash &amp; (2^n -1 ) 可以看出，ConcurrentHashMap的第1次hash没有直接采用key的hash值来进行求余操作，而是采用hash值的高sshift位来进行求余操作的。 而hash值的高sshift位为: 1hash &gt;&gt;&gt; (32-sshift) = hash &gt;&gt;&gt; segmentShift 至此，第1次hash操作就完成了。 下面，我们继续看Segment的get(key, hash)方法，即第2次hash过程： 1234567891011121314151617V get(Object key, int hash) &#123; if (count != 0) &#123; // read-volatile // 取得链表的头部，就是第2次hash过程 HashEntry&lt;K,V&gt; e = getFirst(hash); // 链表搜索，直到hash与key均相等时，返回节点的value while (e != null) &#123; if (e.hash == hash &amp;&amp; key.equals(e.key)) &#123; V v = e.value; if (v != null) return v; return readValueUnderLock(e); // recheck &#125; e = e.next; &#125; &#125; return null;&#125; 首先对count做了非零判断，前边讲解Segment的数据结构时，指出count是volatile修饰的，put、remove等操作会更新count的值，所以当竞争发生的时候，volatile的语义可以保证写操作在读操作之前，也就保证了写操作对后续的读操作都是可见的，这样后面get的后续操作就可以拿到完整的元素内容。 getFirst(hash)完成了第2次hash过程，跟进去： 123456HashEntry&lt;K,V&gt; getFirst(int hash) &#123; // 获取Segment的数组结构 HashEntry&lt;K,V&gt;[] tab = table; // 第2次hash过程，确定key位于哪一个HashEntry return tab[hash &amp; (tab.length - 1)];&#125; 可以看出，第2次hash与第1次hash基本类似，只不过直接用的hash值与Segment的数组大小进行求余，而没有采取hash值高n位的方式。 ConcurrentHashMap的put操作put操作也涉及2次hash定位过程，但是比get操作多了是否扩容、rehash等过程。 put操作的第1次hash与get类似，不再赘述，主要看如何将元素put到Segment中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; // 加锁 lock(); try &#123; int c = count; // 对c进行+1操作，获取新的数组容量 // 如果新的数组容量高于阈值，则先进行扩容操作 if (c++ &gt; threshold) // ensure capacity rehash(); // 获取Segment的数组table HashEntry&lt;K,V&gt;[] tab = table; // 确定在数组中的位置index，即第2次hash过程 int index = hash &amp; (tab.length - 1); // 获取index位置的头结点 HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; // 沿链表遍历，直到找到与元素key或者hash值相同的节点 while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue; // 若key或者hash值相同的节点存在，则进行更新操作 if (e != null) &#123; // value也是volatile修饰的，所以内存即时可见 oldValue = e.value; if (!onlyIfAbsent) e.value = value; &#125; // 若key或者hash值相同的节点不存在，则新建节点，追加到当前链表的头部(头插法) else &#123; oldValue = null; // 更新modCount的值，记录对table的大小造成影响的操作的数量 ++modCount; tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); // 更新count的值，内存即时可见 count = c; // write-volatile &#125; // 返回旧值 return oldValue; &#125; finally &#123; // 释放锁，与synchronize关键字不同，Lock必须显示释放 unlock(); &#125;&#125; 可以看到，Segment的put过程与普通的HashMap基本类似。 ConcurrentHashMap的remove操作与put操作基本类似，首先根据hash值的高sshift位与Segment的数量ssize求余定位到具体的Segment，然后在Segment上执行具体的remove操作。 下面我们看一下Segment如何实现remove操作的。 话不多说，直接怼源码： 12345678910111213141516171819202122232425262728293031323334353637383940V remove(Object key, int hash, Object value) &#123; // 加锁，除了读取操作，其他操作均需要加锁 lock(); try &#123; // 计算新的Segment元素数量 int c = count - 1; // 获取Segment的数组table HashEntry&lt;K,V&gt;[] tab = table; // 第2次hash，确定在table的哪个位置 int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; // 沿链表遍历，直到找到与元素key或者hash值相同的节点 while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue = null; if (e != null) &#123; V v = e.value; if (value == null || value.equals(v)) &#123; oldValue = v; // 更新modCount值 ++modCount; HashEntry&lt;K,V&gt; newFirst = e.next; // 将待删除元素的前面的元素全部复制一遍，然后头插到链表上去 for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value); tab[index] = newFirst; // 更新新的Segment元素数量，内存即时可见 count = c; // write-volatile &#125; &#125; // 返回旧值 return oldValue; &#125; finally &#123; // 释放锁 unlock(); &#125;&#125; 由于，HashEntry中的next是final的，一经赋值以后就不可修改，在定位到待删除元素的位置以后，程序就将待删除元素前面的那一些元素全部复制一遍，然后再一个一个重新接到链表上去。 如: 1234// 原有链表：1--&gt;2--&gt;3--&gt;4--&gt;5// 删除节点3，新的链表为：2--&gt;1--&gt;4--&gt;5 至此，JDK1.7版本的ConcurrentHashMap的基础方法介绍完毕，其他方法的实现方式，读者可自行阅读源码获取，再次不做过多阐述。 参考文献: https://www.cnblogs.com/dolphin0520/p/3932905.html http://ifeve.com/ConcurrentHashMap/ https://www.iteye.com/topic/344876 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的锁机制--ReadWriteLock接口]]></title>
    <url>%2F2019%2F05%2F20%2FJava%E7%9A%84%E9%94%81%E6%9C%BA%E5%88%B6--ReadWriteLock%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[ReentrantLock是排他锁，排他锁在同一时刻仅有一个线程可以进行访问，实际上独占锁是一种相对比较保守的锁策略，独占锁模式下的读/读、读/写、写/写操作都不能同时发生，这在一定程度上降低了吞吐量。然而读操作之间不存在数据竞争问题，如果读/读操作能够以共享锁的方式进行，那会进一步提升性能。 为解决读写冲突问题，Doug Lea设计了ReadWriteLock接口，该接口只定义了两个方法: readLock()用来获取读锁，writeLock()用来获取写锁，将共享资源的读/写操作分开进行管理，类似于数据库中的S锁(共享锁)和X锁(独占锁)，其遵循如下原则： 共享资源只允许加一种锁，或读锁，或写锁，不能同时加； 共享资源可以被多个线程同时加读锁，而写锁只允许加一把； 当共享资源被读锁占用时，写线程只能等待；同样的，当共享资源被写锁占用时，读线程只能等待。 所以，读/写、写/写是互斥的，而读/读是互不影响的，大大提升了读操作的效率。 实例J.U.C中，ReentrantReadWriteLock唯一实现了ReadWriteLock接口。 首先，通过一个简单示例来说明ReentrantReadWriteLock的用法。 假如有多个线程要同时进行读操作的话，首先看synchronized达到的效果： 123456789101112131415161718192021222324252627282930313233343536373839public class SynchronsizedRead &#123; public synchronized void get(Thread thread) throws InterruptedException &#123; long start = System.currentTimeMillis(); for(int i=0; i&lt;10; i++)&#123; System.out.println(thread.getName() + &quot;正在进行读操作...&quot;); Thread.sleep(100); &#125; System.out.println(thread.getName() + &quot;读操作完毕&quot;); &#125; public static void main(String[] args) &#123; final SynchronsizedRead synchronsizedread = new SynchronsizedRead(); new Thread()&#123; @Override public void run() &#123; try &#123; synchronsizedread.get(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); new Thread()&#123; @Override public void run() &#123; try &#123; synchronsizedread.get(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125;&#125; 运行结果为: 123456789101112131415161718192021222324Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0读操作完毕Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1读操作完毕Process finished with exit code 0 可以看到，当持有锁的线程在读取数据的时候，其他读线程只能等待。 接着用ReentrantReadWriteLock来实现上述业务： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class LockRead &#123; private ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(); public void get(Thread thread) throws InterruptedException &#123; reentrantReadWriteLock.readLock().lock(); try&#123; long start = System.currentTimeMillis(); for(int i=0; i&lt;10; i++)&#123; System.out.println(thread.getName() + &quot;正在进行读操作...&quot;); Thread.sleep(100); &#125; System.out.println(thread.getName() + &quot;读操作完毕&quot;); &#125;finally&#123; reentrantReadWriteLock.readLock().unlock(); &#125; &#125; public static void main(String[] args) &#123; final LockRead lockRead = new LockRead(); new Thread()&#123; @Override public void run() &#123; try &#123; lockRead.get(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); new Thread()&#123; @Override public void run() &#123; try &#123; lockRead.get(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125;&#125; 运行结果为: 123456789101112131415161718192021222324Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-0读操作完毕Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1读操作完毕Process finished with exit code 0 可以看到，ReentrantReadWriteLock模式下，可以实现多线程下同时读取数据，从而大大提升了读操作的效率。 源码跟读ReentrantReadWriteLock和ReentrantLock类似的公平锁和非公平锁（默认构造方法是非公平锁），Sync类是一个继承于AQS的抽象类。Sync有FairSync公平锁和NonfairSync非公平锁两个子类： 123456789public ReentrantReadWriteLock() &#123; this(false);&#125; public ReentrantReadWriteLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this);&#125; ReentrantReadWriteLock中包含了下面三个对象：sync对象，读锁readerLock和写锁writerLock。 读锁： 12345678910111213141516171819202122232425262728293031323334353637383940414243public static class ReadLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = -5992448646407690164L; private final Sync sync; protected ReadLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125; public void lock() &#123; // 调用sync的acquireShared(1)方法实现共享锁的释放 sync.acquireShared(1); &#125; // 获取锁(可中断) public void lockInterruptibly() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; // 获取锁 public boolean tryLock() &#123; return sync.tryReadLock(); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; // 释放锁 public void unlock() &#123; sync.releaseShared(1); &#125; public Condition newCondition() &#123; throw new UnsupportedOperationException(); &#125; public String toString() &#123; int r = sync.getReadLockCount(); return super.toString() + &quot;[Read locks = &quot; + r + &quot;]&quot;; &#125;&#125; 写锁： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static class WriteLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = -4992448646407690164L; private final Sync sync; protected WriteLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125; public void lock() &#123; sync.acquire(1); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock( ) &#123; return sync.tryWriteLock(); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125; public String toString() &#123; Thread o = sync.getOwner(); return super.toString() + ((o == null) ? &quot;[Unlocked]&quot; : &quot;[Locked by thread &quot; + o.getName() + &quot;]&quot;); &#125; public boolean isHeldByCurrentThread() &#123; return sync.isHeldExclusively(); &#125; public int getHoldCount() &#123; return sync.getWriteHoldCount(); &#125;&#125; 可以看到，读/写锁均包含了Sync对象，首先查看Sync的构造变量： 12345678910111213// 读锁同步状态占用的位数static final int SHARED_SHIFT = 16;// 每次增加读锁同步状态，就相当于增加SHARED_UNITstatic final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);// 读锁或写锁的最大请求数量（包含重入）static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;// 低16位的MASK，用来计算写锁的同步状态static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;// 返回共享锁数static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;// 返回独占锁数static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125; 在ReentrantLock自定义同步器的实现中，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整形变量）上维护多个读线程和一个写线程的状态，那就需要按位切割使用这个状态变量，读写锁将变量切分成两部分，高16位表示读，低16位表示写，划分方式如下： 当前同步状态表示一个线程已经获取了写锁，且重进入了3次，同时也连续获取了2次读锁。同步状态是通过位运算进行更新的，假设当前同步状态是S，写状态等于S &amp; EXCLUSIVE_MASK，即S &amp; 0x0000FFFF，读状态等于S &gt;&gt;&gt; 16.当写状态加1时，等于S+1，当读状态加1时，等于S+SHARED_UNIT，即S+(1 &lt;&lt; 16)，也就是S + 0x00010000。 即读锁和写锁的状态获取和设置如下： 读锁状态的获取：S &gt;&gt; 16 读锁状态的增加：S + (1 &lt;&lt; 16) 写锁状态的获取：S &amp; 0x0000FFFF 写锁状态的增加：S + 1 Sync类内部存在两个内部类，分别为HoldCounter和ThreadLocalHoldCounter，其中HoldCounter主要与读锁配套使用，其中，HoldCounter源码如下: 12345678// 计数器static final class HoldCounter &#123; // 计数 int count = 0; // Use id, not reference, to avoid garbage retention // 获取当前线程的TID属性的值 final long tid = getThreadId(Thread.currentThread());&#125; 说明：HoldCounter主要有两个属性，count和tid，其中count表示某个读线程重入的次数，tid表示该线程的tid字段的值，该字段可以用来唯一标识一个线程。ThreadLocalHoldCounter的源码如下: 12345678// 本地线程计数器static final class ThreadLocalHoldCounter extends ThreadLocal&lt;HoldCounter&gt; &#123; // 重写初始化方法，在没有进行set的情况下，获取的都是该HoldCounter值 public HoldCounter initialValue() &#123; return new HoldCounter(); &#125;&#125; 说明：ThreadLocalHoldCounter重写了ThreadLocal的initialValue方法，ThreadLocal类可以将线程与对象相关联。在没有进行set的情况下，get到的均是initialValue方法里面生成的那个HolderCounter对象。 Sync类继承自AQS，实现了锁的获取和释放方法。 写锁的获取及释放WriteLock类中的lock和unlock方法： 1234567public void lock() &#123; sync.acquire(1);&#125;public void unlock() &#123; sync.release(1);&#125; 可以看到就是调用的独占式同步状态的获取与释放，因此真实的实现就是Sync的tryAcquire和tryRelease。 跟进tryAcquire： 12345678910111213141516171819202122232425262728293031323334protected final boolean tryAcquire(int acquires) &#123; //当前线程 Thread current = Thread.currentThread(); //获取状态 int c = getState(); //写线程数量（即获取独占锁的重入数） int w = exclusiveCount(c); //当前同步状态state != 0，说明已经有其他线程获取了读锁或写锁 if (c != 0) &#123; // 当前state不为0，此时：如果写锁状态为0说明读锁此时被占用返回false； // 如果写锁状态不为0且写锁没有被当前线程持有返回false if (w == 0 || current != getExclusiveOwnerThread()) return false; //判断同一线程获取写锁是否超过最大次数（65535），支持可重入 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); //更新状态 //此时当前线程已持有写锁，现在是重入，所以只需要修改锁的数量即可。 setState(c + acquires); return true; &#125; //到这里说明此时c=0,读锁和写锁都没有被获取 //writerShouldBlock表示是否阻塞 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; //设置锁为当前线程所有 setExclusiveOwnerThread(current); return true;&#125; 基本流程如下图： 跟进tryRelease: 12345678910111213141516protected final boolean tryRelease(int releases) &#123; //若锁的持有者不是当前线程，抛出异常 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //写锁的新线程数 int nextc = getState() - releases; //如果独占模式重入数为0了，说明独占模式被释放 boolean free = exclusiveCount(nextc) == 0; if (free) //若写锁的新线程数为0，则将锁的持有者设置为null setExclusiveOwnerThread(null); //设置写锁的新线程数 //不管独占模式是否被释放，更新独占重入数 setState(nextc); return free;&#125; 写锁的释放过程还是相对而言比较简单的：首先查看当前线程是否为写锁的持有者，如果不是抛出异常。然后检查释放后写锁的线程数是否为0，如果为0则表示写锁空闲了，释放锁资源将锁的持有线程设置为null，否则释放仅仅只是一次重入锁而已，并不能将写锁的线程清空。 读锁的获取与释放类似于写锁，读锁的lock和unlock的实际实现对应Sync的tryAcquireShared和tryReleaseShared方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647protected final int tryAcquireShared(int unused) &#123; // 获取当前线程 Thread current = Thread.currentThread(); // 获取状态 int c = getState(); //如果写锁线程数 != 0 ，且独占锁不是当前线程则返回失败，因为存在锁降级 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 读锁数量 int r = sharedCount(c); /* * readerShouldBlock():读锁是否需要等待（公平锁原则） * r &lt; MAX_COUNT：持有线程小于最大数（65535） * compareAndSetState(c, c + SHARED_UNIT)：设置读取锁状态 */ // 读线程是否应该被阻塞、并且小于最大值、并且比较设置成功 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; //r == 0，表示第一个读锁线程，第一个读锁firstRead是不会加入到readHolds中 if (r == 0) &#123; // 读锁数量为0 // 设置第一个读线程 firstReader = current; // 读线程占用的资源数为1 firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; // 当前线程为第一个读线程，表示第一个读锁线程重入 // 占用资源数加1 firstReaderHoldCount++; &#125; else &#123; // 读锁数量不为0并且不为当前线程 // 获取计数器 HoldCounter rh = cachedHoldCounter; // 计数器为空或者计数器的tid不为当前正在运行的线程的tid if (rh == null || rh.tid != getThreadId(current)) // 获取当前线程对应的计数器 cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) // 计数为0 //加入到readHolds中 readHolds.set(rh); //计数+1 rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 其中sharedCount方法表示占有读锁的线程数量，源码如下： 1static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125; 说明：直接将state右移16位，就可以得到读锁的线程数量，因为state的高16位表示读锁，对应的第十六位表示写锁数量。 读锁获取锁的过程比写锁稍微复杂些，首先判断写锁是否为0并且当前线程不占有独占锁，直接返回；否则，判断读线程是否需要被阻塞并且读锁数量是否小于最大值并且比较设置状态成功，若当前没有读锁，则设置第一个读线程firstReader和firstReaderHoldCount；若当前线程线程为第一个读线程，则增加firstReaderHoldCount；否则，将设置当前线程对应的HoldCounter对象的值。流程图如下: 读锁的释放，tryReleaseShared方法: 1234567891011121314151617181920212223242526272829303132333435363738protected final boolean tryReleaseShared(int unused) &#123; // 获取当前线程 Thread current = Thread.currentThread(); if (firstReader == current) &#123; // 当前线程为第一个读线程 // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) // 读线程占用的资源数为1 firstReader = null; else // 减少占用的资源 firstReaderHoldCount--; &#125; else &#123; // 当前线程不为第一个读线程 // 获取缓存的计数器 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) // 计数器为空或者计数器的tid不为当前正在运行的线程的tid // 获取当前线程对应的计数器 rh = readHolds.get(); // 获取计数 int count = rh.count; if (count &lt;= 1) &#123; // 计数小于等于1 // 移除 readHolds.remove(); if (count &lt;= 0) // 计数小于等于0，抛出异常 throw unmatchedUnlockException(); &#125; // 减少计数 --rh.count; &#125; for (;;) &#123; // 无限循环 // 获取状态 int c = getState(); // 获取状态 int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // 比较并进行设置 // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; &#125;&#125; 说明：此方法表示读锁线程释放锁。首先判断当前线程是否为第一个读线程firstReader，若是，则判断第一个读线程占有的资源数firstReaderHoldCount是否为1，若是，则设置第一个读线程firstReader为空，否则，将第一个读线程占有的资源数firstReaderHoldCount减1；若当前线程不是第一个读线程，那么首先会获取缓存计数器（上一个读锁线程对应的计数器 ），若计数器为空或者tid不等于当前线程的tid值，则获取当前线程的计数器，如果计数器的计数count小于等于1，则移除当前线程对应的计数器，如果计数器的计数count小于等于0，则抛出异常，之后再减少计数即可。无论何种情况，都会进入无限循环，该循环可以确保成功设置状态state。其流程图如下: 在读锁的获取、释放过程中，总是会有一个对象存在着，同时该对象在获取线程获取读锁是+1，释放读锁时-1，该对象就是HoldCounter。 要明白HoldCounter就要先明白读锁。前面提过读锁的内在实现机制就是共享锁，对于共享锁其实我们可以稍微的认为它不是一个锁的概念，它更加像一个计数器的概念。一次共享锁操作就相当于一次计数器的操作，获取共享锁计数器+1，释放共享锁计数器-1。只有当线程获取共享锁后才能对共享锁进行释放、重入操作。所以HoldCounter的作用就是当前线程持有共享锁的数量，这个数量必须要与线程绑定在一起，否则操作其他线程锁就会抛出异常。 先看读锁获取锁的部分： 1234567891011121314if (r == 0) &#123;//r == 0，表示第一个读锁线程，第一个读锁firstRead是不会加入到readHolds中 firstReader = current; firstReaderHoldCount = 1;&#125; else if (firstReader == current) &#123;//第一个读锁线程重入 firstReaderHoldCount++; &#125; else &#123; //非firstReader计数 HoldCounter rh = cachedHoldCounter;//readHoldCounter缓存 //rh == null 或者 rh.tid != current.getId()，需要获取rh if (rh == null || rh.tid != current.getId()) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); //加入到readHolds中 rh.count++; //计数+1&#125; 这里为什么要搞一个firstRead、firstReaderHoldCount呢？而不是直接使用else那段代码？这是为了一个效率问题，firstReader是不会放入到readHolds中的，如果读锁仅有一个的情况下就会避免查找readHolds。可能就看这个代码还不是很理解HoldCounter。我们先看firstReader、firstReaderHoldCount的定义： 12private transient Thread firstReader = null;private transient int firstReaderHoldCount; 这两个变量比较简单，一个表示线程，当然该线程是一个特殊的线程，一个是firstReader的重入计数。 故而，HoldCounter应该就是绑定线程上的一个计数器，而ThradLocalHoldCounter则是线程绑定的ThreadLocal。从上面我们可以看到ThreadLocal将HoldCounter绑定到当前线程上，同时HoldCounter也持有线程Id，这样在释放锁的时候才能知道ReadWriteLock里面缓存的上一个读取线程（cachedHoldCounter）是否是当前线程。这样做的好处是可以减少ThreadLocal.get()的次数，因为这也是一个耗时操作。需要说明的是这样HoldCounter绑定线程id而不绑定线程对象的原因是避免HoldCounter和ThreadLocal互相绑定而GC难以释放它们（尽管GC能够智能的发现这种引用而回收它们，但是这需要一定的代价），所以其实这样做只是为了帮助GC快速回收对象而已。 参考文献： https://www.cnblogs.com/dolphin0520/p/3923737.html https://www.cnblogs.com/shixm/p/5490026.html https://www.cnblogs.com/xiaoxi/p/9140541.html 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的锁机制--Lock接口]]></title>
    <url>%2F2019%2F05%2F20%2FJava%E7%9A%84%E9%94%81%E6%9C%BA%E5%88%B6--Lock%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[synchronized关键字虽然可以解决大部分多线程锁的问题，但是仍旧存在下述问题： 假如持有锁的某线程因等待长时IO或者其他原因阻塞，其他等待的线程无法响应中断，只能不断等待； 多线程下只有读操作是不会发生冲突的，但synchronized关键字对读和写操作均一视同仁，所以当一个线程进行读取操作时，其他线程只能不断等待； 使用synchronized关键字无法确认线程是否成功获取到锁。 针对上述问题，Doug Lea李大爷实现了一套更加灵活的Java锁机制，即J.U.C的locks包。 下面，我们打开locks包，看看有啥好东西吧。 首先看一下Lock接口： LockLock有下述6个方法，主要分为三大类: 获取锁的方法，分别为lock()、lockInterruptibly()、tryLock()、tryLock(long, TimeUnit); 释放锁的方法，unlock(); 线程协作相关的方法，newCondition()。 synchronsized关键字不需要用户手动释放锁，当synchronized修饰的方法或代码块执行完毕后，系统会自动让线程释放对锁的占用。 与synchronsized关键字不同的是，Lock必须由用户手动执行加锁/释放锁操作，当持有锁的线程发生异常时，该线程不会自动释放锁，可能会导致死锁，故Lock必须在try{}catch{}块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生。 12345678910111213// 初始化锁对象Lock lock = ...;// 加锁操作lock.lock();try&#123; // 执行相应任务 doSomething();&#125;catch(Exception e)&#123; // 处理异常&#125;finally&#123; // 释放锁 lock.unlock();&#125; 与lock()不同的是，tryLock()是由返回值的，获取到锁则返回true，否则返回false，tryLock(long, TimeUnit)为其重载方法，表示获取不到锁之后会等待一定时间，如果在时间期限内获取到锁，则返回true，否则返回false。 lockInterruptibly()方法，当线程获取不到锁，在等待的过程中是可以响应中断的。 不过需要注意的是，通过lockInterruptibly()方法获取到锁的线程，在运行过程中是不能响应中断的，仅是做一个中断标记，待释放锁之后再响应中断。 ReentrantLockJ.U.C包中Lock接口的实现类主要有5个： 除了ReentrantLock外，其他均为其他类的内部类，ReentrantLock除了实现了Lock的接口方法外，还提供了更多的方法： lock()首先看ReentrantLock如何实现Lock接口的lock()方法： 123public void lock() &#123; sync.lock();&#125; 调用的是抽象内部类Sync的lock()方法： 123abstract static class Sync extends AbstractQueuedSynchronizer &#123; abstract void lock(); ...... 既然Sync的lock()方法声明为abstract，则必定有Sync的子类来实现该方法。 ReentrantLock的内部类FairSync、NonfairSync最终实现了lock()方法。 顾名思义，FairSync、NonfairSync分别实现了公平锁和非公平锁，ReentrantLock默认构建的是非公平锁。 12345678public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; // 若fair为true则构建公平锁 sync = fair ? new FairSync() : new NonfairSync();&#125; 公平锁即尽量以请求锁的顺序来获取锁。比如同时有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该锁。 非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。 在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。 下面以NonfairSync为例： 123456789101112131415static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else // 调用AQS的acquire()模板方法 acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 可以看到，NonfairSync调用AQS的acquire(1)方法来实现获取锁操作： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; AQS把acquireQueued()、addWaiter()等相关同步逻辑的方法均实现好了，但是tryAcquire()还需要子类来实现。 ReenTrantLock的内部抽象类Sync实现了AQS非公平的tryAcquire(int)方法，即nonfairTryAcquire(int)： 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; 神奇的是，公平版的tryAcquire(int)方法实现却又不在Sync中，Doug Lea将其放在Sync的子类FairSync中实现。 12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; 可以发现，公平模式和非公平模式下的代码高度相似，只不过是在c == 0的情况下多了一次!hasQueuedPredecessors()过程(hasQueuedPredecessors是AQS的方法)。 其实，类似这样的绕来绕去，Doug Lea在AQS独占和共享模式下响应线程中断的相关代码里也玩过一次，至于为啥，小菜鸟不敢妄猜大佬的想法(主要是怕猜错了，以后被打脸，哈哈)。 最后，总结一下ReenTrantLock的lock()方法： ReenTrantLock的lock()方法是通过其内部抽象类Sync的lock()方法来实现的； Sync没有直接实现lock()方法，由其方法实现由ReentrantLock的内部类FairSync、NonfairSync来完成; Sync继承自AQS，而FairSync、NonfairSync又继承了Sync，故Sync、FairSync、NonfairSync均是AQS的子类； FairSync、NonfairSync的lock()方法是调用AQS的acquire(1)来实现的，AQS的acquire(int)方法又涉及到tryAcquire(int)方法，但是AQS没有实现tryAcquire(int)方法，是由其子类来实现的。 unlock()接着看ReenTrantLock的unlock()方法: 123public void unlock() &#123; sync.release(1);&#125; 调用的是内部抽象类Sync的release(1)方法: 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 主要涉及到tryRelease(int)和unparkSuccessor(Node)方法，AQS直接实现了unparkSuccessor(Node)方法，但只声明了tryRelease(int)方法，说明实现是交给Sync来完成的，果不其然，在Sync中找到了该方法， 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 可以看出，ReenTrantLock的unlock()与lock()一样，均是基于AQS来实现的。 同时，通过lock()和unlock()的相关实现代码，我们发现ReentrantLock与synchronized一样，是可重入锁。 tryLock()123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; 可以发现，tryLock()调用的是Sync的nonfairTryAcquire(int)方法，本质上只使用了AQS的tryAcquire(int)方法，回顾lock()，其依赖的是AQS的acquire(int)方法： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 相当于，tryLock()只走了tryAcquire()这一步，直接尝试获取锁，获取到则返回true，否则返回false；而lock()方法若第一步没有获取锁，则需要继续执行addWaiter、acquireQueued、selfInterrupt等方法。 tryLock(long, TimeUnit)1234public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125; 可以看到，tryLock(long, TimeUnit)调用的是内部抽象类Sync的tryAcquireNanos方法: 1234567public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125; 最终执行的是AQS的doAcquireNanos方法： 123456789101112131415161718192021222324252627282930private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; lockInterruptibly()123public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125; 调用的仍旧是内部抽象类Sync的方法，acquireInterruptibly(int)方法如下： 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125; 最终调用的是AQS的doAcquireInterruptibly(int)方法。 至于newCondition()方法的实现，我会在讲解线程协作的时候具体讲解，此处不再赘述。 至此，我们就把ReentrantLock如何实现Lock()接口讲解完毕了，可以发现，其各个方法的实现均强依赖AQS，所以，各位小伙伴想将ReentrantLock彻底征服，一定要将AQS吃透呀，哈哈。 跟完了源码，下面分享一下如何使用Lock。 如何使用Lock对引言中的程序通过Lock来进行改造： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class CountWithLock &#123; private volatile static int count = 0; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); Lock lock = new ReentrantLock(); // 启动线程A new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; lock.lock(); try&#123; count++; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // 启动线程B new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; lock.lock(); try&#123; count++; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // main线程等待线程A和B计算完毕 countDownLatch.await(); // main线程打印结果 System.out.println(&quot;count: &quot; + CountWithLock.count); &#125;&#125; 多次运行该程序，其结果均是: 123count: 200000Process finished with exit code 0 接着测试一下lockInterruptibly()： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class LockInterruptTest &#123; // 线程工具，用于中断等待的线程 static class ThreadUtil extends Thread&#123; private Thread thread; public ThreadUtil(Thread thread) &#123; this.thread = thread; &#125; @Override public void run() &#123; // 3秒后中断传入的线程 try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread.interrupt(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; // 创建Lock final Lock lock = new ReentrantLock(); lock.lock(); // 主线程休眠1秒，保证主线程在子线程之前获取到锁 Thread.sleep(1000); System.out.println(&quot;主线程获取到锁&quot;); // 创建子线程 Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; long start = System.currentTimeMillis(); try &#123; System.out.println(Thread.currentThread().getName() + &quot; 启动&quot;); lock.lockInterruptibly(); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getName() + &quot; interrupted&quot;); &#125; long end = System.currentTimeMillis(); long use_time = (end - start) / 1000; System.out.println(Thread.currentThread().getName() + &quot; 等待了&quot; + use_time + &quot;秒&quot;); &#125; &#125;); t1.start(); // 3秒后中断等待的子线程t1 new ThreadUtil(t1).start(); System.out.println(&quot;主线程即将进行1000秒的IO操作&quot;); Thread.sleep(1000000); &#125;&#125; 输出结果为: 12345主线程获取到锁主线程即将进行1000秒的IO操作Thread-0 启动Thread-0 interruptedThread-0 等待了3秒 可以看出，lockInterruptibly()方法可以使等待获取锁的线程响应中断，避免长时等待。 上述程序如果采用lock()方法，则等待线程是不会响应中断的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class LockInterruptTest &#123; // 线程工具，用于中断等待的线程 static class ThreadUtil extends Thread&#123; private Thread thread; public ThreadUtil(Thread thread) &#123; this.thread = thread; &#125; @Override public void run() &#123; // 3秒后中断传入的线程 try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread.interrupt(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; // 创建Lock final Lock lock = new ReentrantLock(); lock.lock(); // 主线程休眠1秒，保证主线程在子线程之前获取到锁 Thread.sleep(1000); System.out.println(&quot;主线程获取到锁&quot;); // 创建子线程 Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; long start = System.currentTimeMillis(); try &#123; System.out.println(Thread.currentThread().getName() + &quot; 启动&quot;); lock.lock(); &#125; catch (Exception e) &#123; System.out.println(Thread.currentThread().getName() + &quot; interrupted&quot;); &#125; long end = System.currentTimeMillis(); long use_time = (end - start) / 1000; System.out.println(Thread.currentThread().getName() + &quot; 等待了&quot; + use_time + &quot;秒&quot;); &#125; &#125;); t1.start(); // 3秒后中断等待的子线程t1 new ThreadUtil(t1).start(); System.out.println(&quot;主线程即将进行1000秒的IO操作&quot;); Thread.sleep(1000000); &#125;&#125; 等待3秒之后，结果为： 123主线程获取到锁主线程即将进行1000秒的IO操作Thread-0 启动 说明等待获取锁的线程是不会响应中断。 参考文献： https://www.cnblogs.com/dolphin0520/p/3923737.html https://www.cnblogs.com/shixm/p/5490026.html https://www.cnblogs.com/xiaoxi/p/9140541.html 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的锁机制--synchronsized关键字]]></title>
    <url>%2F2019%2F05%2F20%2FJava%E7%9A%84%E9%94%81%E6%9C%BA%E5%88%B6--synchronsized%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[引言高并发环境下，多线程可能需要同时访问一个资源，并交替执行非原子性的操作，很容易出现最终结果与期望值相违背的情况，或者直接引发程序错误。 举个简单示例，存在一个初始静态变量count=0，两个线程分别对count进行100000次加1操作，期望的结果是200000，实际是这样的吗？写个程序跑下看看： 1234567891011121314151617181920212223242526272829303132333435363738public class CountWithoutSyn &#123; private volatile static int count = 0; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); // 启动线程A new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; count++; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // 启动线程B new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; count++; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // main线程等待线程A和B计算完毕 countDownLatch.await(); // main线程打印结果 System.out.println(&quot;count: &quot; + CountWithoutSyn.count); &#125;&#125; 多次运行上述程序，会发现最终结果可能出现不是200000的情况，如： 123count: 150218Process finished with exit code 0 之所以出现这种情况的原因是，count++不是一个原子性的操作，所谓原子性，说的就是操作不可分割。 count++分为3个步骤： 从内存读取count的值； 对count值执行+1操作； 将count的值写回内存； 比如当前count累加到了101，此时，线程A和B同时拿到了count的值为101，线程A对count加1后将102写回内存，同时线程B也对count加1后将102写回内存，而实际结果应该为103，所以丢失了1次更新。 故高并发环境下，多线程同时对共享变量执行非原子的操作，很容易出现丢失更新的问题。 解决办法很简单，将整个非原子的操作加锁，从而变成原子性的操作就可以了。 Java加锁的方式主要有2种，synchronnized关键字和Lock接口。 下面分别阐述这两种方式，本文先讲解synchronnized。 synchronized在Java中，每一个对象都有一个锁标记(monitor)，也称之为监视器，多线程同时访问某个对象时，线程只有获取了该对象的锁才能访问。 该锁属于典型的互斥锁，即一旦一个线程获取到锁之后，其他线程只能等待。 synchronize关键字可以标记方法或者代码块，当某个线程调用该对象的synchronize方法或者访问synchronize代码块时，该线程便获得了该对象的锁，其他线程暂时无法访问这个方法，只有等待这个方法执行完毕或者代码块执行完毕，该线程才会释放该对象的锁，其他线程才能执行这个方法或者代码块。 对引言中的程序通过synchronized来进行改造： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class CountWithSyn &#123; private volatile static int count = 0; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); Object lock = new Object(); // 启动线程A new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock)&#123; for(int i=0; i&lt;100000; i++)&#123; count++; &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // 启动线程B new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock)&#123; for(int i=0; i&lt;100000; i++)&#123; count++; &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // main线程等待线程A和B计算完毕 countDownLatch.await(); // main线程打印结果 System.out.println(&quot;count: &quot; + CountWithSyn.count); &#125;&#125; 多次运行该程序，其结果均是: 123count: 200000Process finished with exit code 0 synchronized代码块使用起来比synchronized方法要灵活得多。因为也许一个方法中只有一部分代码只需要同步，如果此时对整个方法用synchronized进行同步，会影响程序执行效率。而使用synchronized代码块就可以避免这个问题，synchronized代码块可以实现只对需要同步的地方进行同步。 因为上述程序的非原子操作仅是count++，所以synchronized仅修饰count++即可实现线程安全。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class CountWithSyn &#123; private volatile static int count = 0; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); Object lock = new Object(); // 启动线程A new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; synchronized (lock)&#123; count++; &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // 启动线程B new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; synchronized (lock)&#123; count++; &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // main线程等待线程A和B计算完毕 countDownLatch.await(); // main线程打印结果 System.out.println(&quot;count: &quot; + CountWithSyn.count); &#125;&#125; 需要注意的是： 当一个线程正在访问一个对象的synchronized方法，那么其他线程不能访问该对象的其他synchronized方法。这个原因很简单，因为一个对象只有一把锁，当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的其他synchronized方法。 当一个线程正在访问一个对象的synchronized方法，那么其他线程能访问该对象的非synchronized方法。这个原因很简单，访问非synchronized方法不需要获得该对象的锁，假如一个方法没用synchronized关键字修饰，说明它不会使用到临界资源，那么其他线程是可以访问这个方法的， 如果一个线程A需要访问对象object1的synchronized方法fun1，另外一个线程B需要访问对象object2的synchronized方法fun1，即使object1和object2是同一类型），也不会产生线程安全问题，因为他们访问的是不同的对象，所以不存在互斥问题。 那么，synchronized关键字底层是如何实现的呢？反编译它的字节码看一下，如下述代码的字节码为： 123456789101112131415161718public class SynCode &#123; private Object lock = new Object(); public void method1()&#123; synchronized (lock)&#123; &#125; &#125; public synchronized void method2()&#123; &#125; public void method3()&#123; &#125;&#125; 从反编译获得的字节码可以看出，synchronized代码块实际上多了monitorenter和monitorexit两条指令。monitorenter指令执行时会让对象的锁计数加1，而monitorexit指令执行时会让对象的锁计数减1，其实这个与操作系统里面的PV操作很像，操作系统里面的PV操作就是用来控制多个线程对临界资源的访问。 对于synchronized方法，执行中的线程识别该方法的method_info结构是否有ACC_SYNCHRONIZED标记设置，然后它自动获取对象的锁，调用方法，最后释放锁。如果有异常发生，线程自动释放锁。 对于synchronized方法或者synchronized代码块，当出现异常时，JVM会自动释放当前线程占用的锁，因此不会由于异常导致出现死锁现象。 参考文献： https://www.cnblogs.com/dolphin0520/p/3923737.html https://www.cnblogs.com/shixm/p/5490026.html https://www.cnblogs.com/xiaoxi/p/9140541.html 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈线程间的协作机制]]></title>
    <url>%2F2019%2F05%2F07%2F%E6%B5%85%E8%B0%88%E7%BA%BF%E7%A8%8B%E9%97%B4%E7%9A%84%E5%8D%8F%E4%BD%9C%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[注意：如无特殊说明，本文源码分析基于的Java JDK版本均为1.8。 等待/通知机制假设这样的情景，只要线程A修改了某值value，则线程B则对新的value值进行某些操作，比较容易想到的方法是，线程B不断循环访问value，一旦感知到变化，则执行相应逻辑。 123456789// 线程Aset value = newValue// 线程Bfor(;;)&#123; while(newValue != oldValue)&#123; doSomething(newValue); &#125;&#125; 如果value值发生变化的频率较低，则线程B不断自旋获取value的值，过多的无效尝试极大地浪费系统处理资源。 改进的方法是，每一段时间(如1s)去访问一下： 1234567891011121314// 线程Aset value = newValue// 线程Bfor(;;)&#123; while(newValue != oldValue)&#123; doSomething(newValue); &#125; try &#123; Thread.sleep(1000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 改进后，较少了较多的无效尝试，降低了对处理器资源的浪费，但是休眠时间的大小难以确定： 休眠时间太大，不能在休眠期间及时感知数据的变化，实时性较差； 休眠时间过小，实时性提高的同时，增加了无效尝试的次数，造成了系统处理资源的浪费。 考虑到上述监听机制上述的困境，线程间协作采用的是等待/通知机制。 原理就是，当线程A完成对数据的修改之后，会通过一定的机制通知线程B来获取新的数据值来进行相关业务处理，线程B处理完之后挂起等待后续线程A的通知。 等待/通知机制是所有Java对象均具备的，因为相关方法是定义在所有对象的超类java.lang.Object上的。 相关方法描述如下： 方法名称 描述 notify() 通知一个在对象上等待的线程，使其从wait()返回，而返回的前提是该线程获取到对象的锁 notifyAll() 通知所有等待在该对象上的线程 wait() 调用wait()方法后，会释放对象的锁，并进入WAITING状态 wait(long) 超时等待一段时间，如果没有通知就超时返回 wait(long, int) 超时时间更细粒度的控制，可以达到毫秒 wait()/notify()入门实例1234567891011121314151617181920212223242526272829303132333435363738394041424344public class WaitAndNotifyDemo &#123; public static void main(String[] args) &#123; Object lock = new Object(); // 线程A new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;线程A等待获取锁&quot;); synchronized (lock) &#123; try &#123; System.out.println(&quot;线程A获取锁&quot;); Thread.sleep(3000); System.out.println(&quot;线程A将要运行wait()进入等待&quot;); lock.wait(); System.out.println(&quot;线程A等待结束&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); // 线程B new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;线程B等待获取锁&quot;); synchronized (lock) &#123; try &#123; System.out.println(&quot;线程B获取锁&quot;); Thread.sleep(3000); System.out.println(&quot;线程B将要运行notify()唤醒其他wait状态的线程&quot;); lock.notify(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125;&#125; 运行结果为： 123456789线程A等待获取锁线程A获取锁线程B等待获取锁线程A将要运行wait()进入等待线程B获取锁线程B将要运行notify()唤醒其他wait状态的线程线程A等待结束Process finished with exit code 0 需要注意的是：Thread的sleep()方法仅是让出CPU时间片，让其他线程有机会执行，但是sleep()方法不会释放其持有的对象锁，仅当调用对象的wait()方法才会释放对象锁。 wait()方法进入到Object的wait()方法： 123public final void wait() throws InterruptedException &#123; wait(0);&#125; 可以看出，其底层调用的是Object的重载方法wait(long): 1public final native void wait(long timeout) throws InterruptedException; 重载方法wait(long)是native方法，方法实现可通过OpenJDK来查看(Object.c)来找到： 1234567static JNINativeMethod methods[] = &#123; &#123;&quot;hashCode&quot;, &quot;()I&quot;, (void *)&amp;JVM_IHashCode&#125;, &#123;&quot;wait&quot;, &quot;(J)V&quot;, (void *)&amp;JVM_MonitorWait&#125;, &#123;&quot;notify&quot;, &quot;()V&quot;, (void *)&amp;JVM_MonitorNotify&#125;, &#123;&quot;notifyAll&quot;, &quot;()V&quot;, (void *)&amp;JVM_MonitorNotifyAll&#125;, &#123;&quot;clone&quot;, &quot;()Ljava/lang/Object;&quot;, (void *)&amp;JVM_Clone&#125;,&#125;; 其中，JVM_MonitorWait和JVM_MonitorNotify分别对应于wait()和notify()方法，JVM_MonitorWait方法声明是在jvm.h中，如下所示： 12JNIEXPORT void JNICALLJVM_MonitorWait(JNIEnv *env, jobject obj, jlong ms); 方法实现为: 12345678910JVM_ENTRY(void, JVM_MonitorWait(JNIEnv* env, jobject handle, jlong ms)) JVMWrapper(&quot;JVM_MonitorWait&quot;); Handle obj(THREAD, JNIHandles::resolve_non_null(handle)); assert(obj-&gt;is_instance() || obj-&gt;is_array(), &quot;JVM_MonitorWait must apply to an object&quot;); JavaThreadInObjectWaitState jtiows(thread, ms != 0); if (JvmtiExport::should_post_monitor_wait()) &#123; JvmtiExport::post_monitor_wait((JavaThread *)THREAD, (oop)obj(), ms); &#125; ObjectSynchronizer::wait(obj, ms, CHECK);JVM_END JVM_MonitorWait方法最终调用了ObjectSynchronizer的wait方法: 123456789101112131415161718void ObjectSynchronizer::wait(Handle obj, jlong millis, TRAPS) &#123; if (UseBiasedLocking) &#123; BiasedLocking::revoke_and_rebias(obj, false, THREAD); assert(!obj-&gt;mark()-&gt;has_bias_pattern(), &quot;biases should be revoked by now&quot;); &#125; if (millis &lt; 0) &#123; TEVENT (wait - throw IAX) ; THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), &quot;timeout value is negative&quot;); &#125; ObjectMonitor* monitor = ObjectSynchronizer::inflate(THREAD, obj()); DTRACE_MONITOR_WAIT_PROBE(monitor, obj(), THREAD, millis); monitor-&gt;wait(millis, true, THREAD); /* This dummy call is in place to get around dtrace bug 6254741. Once that&apos;s fixed we can uncomment the following line and remove the call */ // DTRACE_MONITOR_PROBE(waited, monitor, obj(), THREAD); dtrace_waited_probe(monitor, obj, THREAD);&#125; 最终，是通过调用ObjectMonitor的wait()方法来实现等待的，其主要代码如下: 1234567891011121314151617181920212223242526272829303132333435363738void ObjectMonitor::wait(jlong millis, bool interruptible, TRAPS) &#123; ... // create a node to be put into the queue // Critically, after we reset() the event but prior to park(), we must check // for a pending interrupt. ObjectWaiter node(Self); node.TState = ObjectWaiter::TS_WAIT ; Self-&gt;_ParkEvent-&gt;reset() ; OrderAccess::fence(); // ST into Event; membar ; LD interrupted-flag // Enter the waiting queue, which is a circular doubly linked list in this case // but it could be a priority queue or any data structure. // _WaitSetLock protects the wait queue. Normally the wait queue is accessed only // by the the owner of the monitor *except* in the case where park() // returns because of a timeout of interrupt. Contention is exceptionally rare // so we use a simple spin-lock instead of a heavier-weight blocking lock. Thread::SpinAcquire (&amp;_WaitSetLock, &quot;WaitSet - add&quot;) ; AddWaiter (&amp;node) ; Thread::SpinRelease (&amp;_WaitSetLock) ; if ((SyncFlags &amp; 4) == 0) &#123; _Responsible = NULL ; &#125; intptr_t save = _recursions; // record the old recursion count _waiters++; // increment the number of waiters _recursions = 0; // set the recursion level to be 1 exit (Self) ; // exit the monitor guarantee (_owner != Self, &quot;invariant&quot;) ; ... if (node._notified != 0 &amp;&amp; _succ == Self) &#123; node._event-&gt;unpark(); &#125; // The thread is on the WaitSet list - now park() it. ...&#125; 整个调用链路可以总结如下： 1Object.wait()--&gt;Object.wait(long)--&gt;JVM_MonitorWait--&gt;ObjectSynchronizer::wait--&gt;ObjectMonitor::wait 说明对象的Object最终调用的是底层native方法ObjectMonitor::wait，下面介绍一下ObjectMonitor::wait的基本步骤： 将调用wait()方法的线程封装为ObjectWaiter类的对象node； ObjectWriter类声明为： 123456789101112131415161718class ObjectWaiter : public StackObj &#123; public: enum TStates &#123; TS_UNDEF, TS_READY, TS_RUN, TS_WAIT, TS_ENTER, TS_CXQ &#125; ; enum Sorted &#123; PREPEND, APPEND, SORTED &#125; ; ObjectWaiter * volatile _next; ObjectWaiter * volatile _prev; Thread* _thread; ParkEvent * _event; volatile int _notified ; volatile TStates TState ; Sorted _Sorted ; // List placement disposition bool _active ; // Contention monitoring is enabled public: ObjectWaiter(Thread* thread); void wait_reenter_begin(ObjectMonitor *mon); void wait_reenter_end(ObjectMonitor *mon);&#125;; 可以看出，ObjectWaiter是双向链表结构，保存了当前线程_thread及当前的状态TState等数据，每个等待锁的线程都会被封装成ObjectWaiter对象。 通过ObjectMonitor::AddWaiter方法将node添加到_WaitSet列表中; 12345678910111213141516171819inline void ObjectMonitor::AddWaiter(ObjectWaiter* node) &#123; assert(node != NULL, &quot;should not dequeue NULL node&quot;); assert(node-&gt;_prev == NULL, &quot;node already in list&quot;); assert(node-&gt;_next == NULL, &quot;node already in list&quot;); // put node at end of queue (circular doubly linked list) if (_WaitSet == NULL) &#123; _WaitSet = node; node-&gt;_prev = node; node-&gt;_next = node; &#125; else &#123; ObjectWaiter* head = _WaitSet ; ObjectWaiter* tail = head-&gt;_prev; assert(tail-&gt;_next == head, &quot;invariant check&quot;); tail-&gt;_next = node; head-&gt;_prev = node; node-&gt;_next = head; node-&gt;_prev = tail; &#125;&#125; 调用此方法前后需要获取和释放_WaitSet列表的_WaitSetLock锁。从注释中可以看到，_WaitSet列表其实是一个双向循环链表。 通过ObjectMonitor::exit方法释放当前的ObjectMonitor对象，这样其它竞争线程就可以获取该ObjectMonitor对象; 123456789101112131415161718192021222324252627void ATTR ObjectMonitor::exit(TRAPS) &#123; Thread * Self = THREAD ; if (THREAD != _owner) &#123; if (THREAD-&gt;is_lock_owned((address) _owner)) &#123; // Transmute _owner from a BasicLock pointer to a Thread address. // We don&apos;t need to hold _mutex for this transition. // Non-null to Non-null is safe as long as all readers can // tolerate either flavor. assert (_recursions == 0, &quot;invariant&quot;) ; _owner = THREAD ; _recursions = 0 ; OwnerIsThread = 1 ; &#125; else &#123; // NOTE: we need to handle unbalanced monitor enter/exit // in native code by throwing an exception. // TODO: Throw an IllegalMonitorStateException ? TEVENT (Exit - Throw IMSX) ; assert(false, &quot;Non-balanced monitor enter/exit!&quot;); if (false) &#123; THROW(vmSymbols::java_lang_IllegalMonitorStateException()); &#125; return; &#125; &#125; ...&#125; 最终通过底层的park()方法挂起当前线程。 notify()方法与wait()方法类似，最终也是调用的底层native方法:ObjectMonitor::notify(TRAPS)。 12345678910111213141516171819202122232425262728293031323334353637void ObjectMonitor::notify(TRAPS) &#123; CHECK_OWNER(); if (_WaitSet == NULL) &#123; TEVENT (Empty-Notify) ; return ; &#125; DTRACE_MONITOR_PROBE(notify, this, object(), THREAD); int Policy = Knob_MoveNotifyee ; Thread::SpinAcquire (&amp;_WaitSetLock, &quot;WaitSet - notify&quot;) ; ObjectWaiter * iterator = DequeueWaiter() ; if (iterator != NULL) &#123; TEVENT (Notify1 - Transfer) ; guarantee (iterator-&gt;TState == ObjectWaiter::TS_WAIT, &quot;invariant&quot;) ; guarantee (iterator-&gt;_notified == 0, &quot;invariant&quot;) ; if (Policy != 4) &#123; iterator-&gt;TState = ObjectWaiter::TS_ENTER ; &#125; iterator-&gt;_notified = 1 ; ObjectWaiter * List = _EntryList ; if (List != NULL) &#123; assert (List-&gt;_prev == NULL, &quot;invariant&quot;) ; assert (List-&gt;TState == ObjectWaiter::TS_ENTER, &quot;invariant&quot;) ; assert (List != iterator, &quot;invariant&quot;) ; &#125; if (Policy == 0) &#123; // prepend to EntryList &#125; else if (Policy == 1) &#123; // append to EntryList &#125; else if (Policy == 2) &#123; // prepend to cxq &#125; ...&#125; ObjectMonitor::notify(TRAPS)方法的基本步骤为： 若_WaitSet为NULL，即没有需要唤醒的线程，则直接退出； 通过ObjectMonitor::DequeueWaiter方法，获取_WaitSet列表中的第一个ObjectWaiter节点； 12345678inline ObjectWaiter* ObjectMonitor::DequeueWaiter() &#123; // dequeue the very first waiter ObjectWaiter* waiter = _WaitSet; if (waiter) &#123; DequeueSpecificWaiter(waiter); &#125; return waiter;&#125; 根据不同的策略，将取出来的ObjectWaiter节点，加入到_EntryList或则通过Atomic::cmpxchg_ptr指令进行自旋操作cxq。 notifyAll()方法lock.notifyAll()方法最终通过ObjectMonitor的void notifyAll(TRAPS)实现： 123456789101112131415161718192021222324252627void ObjectMonitor::notifyAll(TRAPS) &#123; ... for (;;) &#123; iterator = DequeueWaiter () ; if (iterator == NULL) break ; TEVENT (NotifyAll - Transfer1) ; ++Tally ; ... ObjectWaiter * List = _EntryList ; if (List != NULL) &#123; assert (List-&gt;_prev == NULL, &quot;invariant&quot;) ; assert (List-&gt;TState == ObjectWaiter::TS_ENTER, &quot;invariant&quot;) ; assert (List != iterator, &quot;invariant&quot;) ; &#125; if (Policy == 0) &#123; // prepend to EntryList &#125; else if (Policy == 1) &#123; // append to EntryList &#125; else if (Policy == 2) &#123; // prepend to cxq &#125; &#125;&#125; 该方法和notify()方法比较类似，不同的是，notifyAll()通过for循环取出_WaitSet的ObjectWaiter节点，并根据不同策略，加入到_EntryList或则进行自旋操作。 小结 wait()方法会释放所占有的ObjectMonitor对象； notify()和notifyAll()并不会释放所占有的ObjectMonitor对象，只是将相应的等待线程从_WaitSet转移到_EntryList中，然后等待竞争锁； 真正释放ObjectMonitor对象的时机是，退出同步代码块或同步方法时，即执行monitorexit指令时； 一旦释放ObjectMonitor对象后，_EntityList中ObjectWaiter节点所保存的线程即可以参与竞争ObjectMonitor对象了； wait()/notify()基本就是C/C++版的AQS(啥是AQS，可参见我的另外一篇文章)。 ConditionCondition出现在JDK1.5中的J.U.C包中，由Doug Lea李大爷操刀设计并开发完成。 Condition是个接口，其方法有： await()方法对应于Object的wait(); signal()方法对应于Object的notify(); signalAll()方法对应于Object的notifyAll(); 像Object的wait()/notify()方法必须在Synchronized中调用类似，Condition的await()/siganl()方法必须在Lock中调用。 Condition接口的实现类是AQS中的ConditionObject。 跟进ConditionObject的源码，查看await()的实现方式： 123456789101112131415161718public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 可以发现，其与ObjectMonitor::wait流程基本类似，都是将当前线程封装成node节点，然后添加到等待队列，最后挂起当前线程。 只不过是ConditionObject实现了Java版的wait()流程，如Object的wait()方法是通过native的park()方法挂起当前线程的，而ConditionObject则使用的则是LockSupport工具类的park()方法。 构建Condition对象可以通过Lock接口创建Condition对象，Lock接口中定义了newCondition()方法: 1Condition newCondition(); 获取方式如下所示: 123Lock lock = new ReentrantLock();Condition c1 = lock.newCondition();Condition c2 = lock.newCondition(); ReentrantLock唯一实现了Lock接口，看一下ReentrantLock的对newCondition()的实现： 123public Condition newCondition() &#123; return sync.newCondition();&#125; 发现调用的是内部类的sync的newCondition()方法: 123final ConditionObject newCondition() &#123; return new ConditionObject();&#125; 可以发现，最终创建的就是AQS中的ConditionObject，由其实现Condition接口的各个方法。 实例下面，我们通过Condition的await()/signal()来完成一个小Demo: 首先定义一个服务MyService: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class MyService &#123; // 实例化一个ReentrantLock对象 private ReentrantLock lock = new ReentrantLock(); // 为线程A注册一个Condition public Condition conditionA = lock.newCondition(); // 为线程B注册一个Condition public Condition conditionB = lock.newCondition(); public void awitA()&#123; try&#123; lock.lock(); System.out.println(Thread.currentThread().getName() + &quot;进入了awitA方法&quot;); long timeBefore = System.currentTimeMillis(); // 执行condition等待 conditionA.await(); long timeAfter = System.currentTimeMillis(); System.out.println(Thread.currentThread().getName() + &quot;等待了：&quot; + (timeAfter-timeBefore)/1000 + &quot; s&quot;); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void awitB()&#123; try&#123; lock.lock(); System.out.println(Thread.currentThread().getName() + &quot;进入了awitB方法&quot;); long timeBefore = System.currentTimeMillis(); // 执行condition等待 conditionB.await(); long timeAfter = System.currentTimeMillis(); System.out.println(Thread.currentThread().getName() + &quot;等待了：&quot; + (timeAfter-timeBefore)/1000 + &quot; s&quot;); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void signallA()&#123; try&#123; lock.lock(); System.out.println(&quot;启动唤醒程序&quot;); // 唤醒所有注册conditionA的线程 conditionA.signalAll(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void signallB()&#123; try&#123; lock.lock(); System.out.println(&quot;启动唤醒程序&quot;); // 唤醒所有注册conditionB的线程 conditionB.signalAll(); &#125;finally &#123; lock.unlock(); &#125; &#125;&#125; 然后构建两个线程，均持有MyService对象： 线程A: 12345678910111213public class MyServiceThreadA implements Runnable&#123; private MyService service; public MyServiceThreadA(MyService service) &#123; this.service = service; &#125; @Override public void run() &#123; service.awitA(); &#125;&#125; 线程B: 12345678910111213public class MyServiceThreadB implements Runnable&#123; private MyService service; public MyServiceThreadB(MyService service) &#123; this.service = service; &#125; @Override public void run() &#123; service.awitB(); &#125;&#125; 主函数为: 12345678910111213141516171819public class ApplicationCondition &#123; public static void main(String[] args) throws InterruptedException &#123; MyService service = new MyService(); Runnable runnableA = new MyServiceThreadA(service); Runnable runnableB = new MyServiceThreadB(service); new Thread(runnableA, &quot;a&quot;).start(); new Thread(runnableB, &quot;b&quot;).start(); Thread.sleep(2000); // 唤醒所有持有ConditionA的线程 service.signallA(); Thread.sleep(2000); // 唤醒所有持有ConditionB的线程 service.signallB(); &#125;&#125; 运行结果为: 12345678a进入了awitA方法b进入了awitB方法启动唤醒程序a等待了：2 s启动唤醒程序b等待了：4 sProcess finished with exit code 0 可以看到，在实现线程协作时，Condition具有更大的灵活性，比如现在有3个线程A、B、C，线程A更新了某数据，需要通知线程B去拿新数据做搞事情，而C线程继续休眠，此种情况采用Object的wait()/notify()是难以实现的，因为notify()唤醒的线程是难以控制和指定的，而Condition却可以轻松完成这一切。 总结本文主要介绍了线程协作的两种方式，分别为Object的wait()/notify()和Condition的await()/signal()。 两种方式在原理上基本类似，均实现了等待/通知机制，相比使用Object的wait()、notify()，使用Condition的await()、signal()这种方式实现线程间协作更加安全和高效。因此通常来说比较推荐使用Condition，如阻塞队列实际上使用了Condition来模拟线程间协作。 参考文献: https://www.cnblogs.com/dolphin0520/p/3920385.html http://www.importnew.com/30150.html https://blog.csdn.net/qq_38293564/article/details/80432875 https://www.cnblogs.com/superfj/p/7543927.html 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Java并发中的AQS]]></title>
    <url>%2F2019%2F05%2F05%2F%E6%B5%85%E8%B0%88Java%E5%B9%B6%E5%8F%91%E4%B8%AD%E7%9A%84AQS%2F</url>
    <content type="text"><![CDATA[所谓AQS，指的是AbstractQueuedSynchronizer，它提供了一种实现阻塞锁和一系列依赖FIFO等待队列的同步器的框架，ReentrantLock、Semaphore、CountDownLatch、CyclicBarrier等并发类均是基于AQS来实现的，具体用法是通过继承AQS实现其模板方法，然后将子类作为同步组件的内部类。 了解一个框架最好的方式是读源码，说干就干。 AQS是JDK1.5之后才出现的，由大名鼎鼎的Doug Lea李大爷来操刀设计并开发实现，全部源代码(加注释)2315行，整体难度中等。 12* @since 1.5* @author Doug Lea 基本框架在阅读源码前，首先阐述AQS的基本思想及其相关概念。 AQS基本框架如下图所示： AQS维护了一个volatile语义(支持多线程下的可见性)的共享资源变量state和一个FIFO线程等待队列(多线程竞争state被阻塞时会进入此队列)。 State首先说一下共享资源变量state，它是int数据类型的，其访问方式有3种： getState() setState(int newState) compareAndSetState(int expect, int update) 上述3种方式均是原子操作，其中compareAndSetState()的实现依赖于Unsafe的compareAndSwapInt()方法。 1234567891011121314151617private volatile int state;// 具有内存读可见性语义protected final int getState() &#123; return state;&#125;// 具有内存写可见性语义protected final void setState(int newState) &#123; state = newState;&#125;// 具有内存读/写可见性语义protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 资源的共享方式分为2种： 独占式(Exclusive) 只有单个线程能够成功获取资源并执行，如ReentrantLock。 共享式(Shared) 多个线程可成功获取资源并执行，如Semaphore/CountDownLatch等。 AQS将大部分的同步逻辑均已经实现好，继承的自定义同步器只需要实现state的获取(acquire)和释放(release)的逻辑代码就可以，主要包括下面方法： tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 AQS需要子类复写的方法均没有声明为abstract，目的是避免子类需要强制性覆写多个方法，因为一般自定义同步器要么是独占方法，要么是共享方法，只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。 当然，AQS也支持子类同时实现独占和共享两种模式，如ReentrantReadWriteLock。 CLH队列(FIFO)AQS是通过内部类Node来实现FIFO队列的，源代码解析如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364static final class Node &#123; // 表明节点在共享模式下等待的标记 static final Node SHARED = new Node(); // 表明节点在独占模式下等待的标记 static final Node EXCLUSIVE = null; // 表征等待线程已取消的 static final int CANCELLED = 1; // 表征需要唤醒后续线程 static final int SIGNAL = -1; // 表征线程正在等待触发条件(condition) static final int CONDITION = -2; // 表征下一个acquireShared应无条件传播 static final int PROPAGATE = -3; /** * SIGNAL: 当前节点释放state或者取消后，将通知后续节点竞争state。 * CANCELLED: 线程因timeout和interrupt而放弃竞争state，当前节点将与state彻底拜拜 * CONDITION: 表征当前节点处于条件队列中，它将不能用作同步队列节点，直到其waitStatus被重置为0 * PROPAGATE: 表征下一个acquireShared应无条件传播 * 0: None of the above */ volatile int waitStatus; // 前继节点 volatile Node prev; // 后继节点 volatile Node next; // 持有的线程 volatile Thread thread; // 链接下一个等待条件触发的节点 Node nextWaiter; // 返回节点是否处于Shared状态下 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; // 返回前继节点 final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; // Shared模式下的Node构造函数 Node() &#123; &#125; // 用于addWaiter Node(Thread thread, Node mode) &#123; this.nextWaiter = mode; this.thread = thread; &#125; // 用于Condition Node(Thread thread, int waitStatus) &#123; this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; 可以看到，waitStatus非负的时候，表征不可用，正数代表处于等待状态，所以waitStatus只需要检查其正负符号即可，不用太多关注特定值。 获取资源(独占模式)acquire(int)首先讲解独占模式(Exclusive)下的获取/释放资源过程，其入口方法为: 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; tryAcquire(arg)为线程获取资源的方法函数，在AQS中定义如下： 123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 很明显，该方法是空方法，且由protected修饰，说明该方法需要由子类即自定义同步器来实现。 acquire()方法至少执行一次tryAcquire(arg)，若返回true，则acquire直接返回，否则进入acquireQueued(addWaiter(Node.EXCLUSIVE), arg)方法。 acquireQueued方法分为3个步骤： addWriter()将当前线程加入到等待队列的尾部，并标记为独占模式； acquireQueued()使线程在等待队列中获取资源，直到获取到资源返回，若整个等待过程被中断过，则返回True，否则返回False。 如果线程在等待过程中被中断过，则先标记上，待获取到资源后再进行自我中断selfInterrupt()，将中断响应掉。 下面具体看看过程中涉及到的各函数： tryAcquire(int)tryAcquire尝试以独占的模式获取资源，如果获取成功则返回True，否则直接返回False，默认实现是抛出UnsupportedOperationException，具体实现由自定义扩展了AQS的同步器来完成。 addWaiter(Node)addWaiter为当前线程以指定模式创建节点，并将其添加到等待队列的尾部，其源码为： 123456789101112131415private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 尝试将节点快速插入等待队列，若失败则执行常规插入(enq方法) Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 常规插入 enq(node); return node;&#125; 再看enq(node)方法： 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 可以看到，常规插入与快速插入相比，有2点不同： 常规插入是自旋过程(for(;;))，能够保证节点插入成功； 比快速插入多包含了1种情况，即当前等待队列为空时，需要初始化队列，即将待插入节点设置为头结点，同时为尾节点(因为只有一个嘛)。 常规插入与快速插入均依赖于CAS，其实现依赖于unsafe类，具体代码如下： 12345678private final boolean compareAndSetHead(Node update) &#123; return unsafe.compareAndSwapObject(this, headOffset, null, update);&#125;private final boolean compareAndSetTail(Node expect, Node update) &#123; return unsafe.compareAndSwapObject(this, tailOffset, expect, update);&#125; unsafe中的cas操作均是native方法，由计算机CPU的cmpxchg指令来保证其原子性。 接着看acquireQueued()方法： acquireQueued(Node, int)相关说明已在代码中注释： 12345678910111213141516171819202122232425262728293031323334353637final boolean acquireQueued(final Node node, int arg) &#123; // 标识是否获取资源失败 boolean failed = true; try &#123; // 标识当前线程是否被中断过 boolean interrupted = false; // 自旋操作 for (;;) &#123; // 获取当前节点的前继节点 final Node p = node.predecessor(); // 如果前继节点为头结点，说明排队马上排到自己了，可以尝试获取资源，若获取资源成功，则执行下述操作 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 将当前节点设置为头结点 setHead(node); // 说明前继节点已经释放掉资源了，将其next置空，以方便虚拟机回收掉该前继节点 p.next = null; // help GC // 标识获取资源成功 failed = false; // 返回中断标记 return interrupted; &#125; // 若前继节点不是头结点，或者获取资源失败， // 则需要通过shouldParkAfterFailedAcquire函数 // 判断是否需要阻塞该节点持有的线程 // 若shouldParkAfterFailedAcquire函数返回true， // 则继续执行parkAndCheckInterrupt()函数， // 将该线程阻塞并检查是否可以被中断，若返回true，则将interrupted标志置于true if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; // 最终获取资源失败，则当前节点放弃获取资源 if (failed) cancelAcquire(node); &#125;&#125; 具体看一下shouldParkAfterFailedAcquire函数： 1234567891011121314151617181920212223// shouldParkAfterFailedAcquire是通过前继节点的waitStatus值来判断是否阻塞当前节点的线程的private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 获取前继节点的waitStatus值ws int ws = pred.waitStatus; // 如果ws的值为Node.SIGNAL(-1)，则直接返回true // 说明前继节点完成资源的释放或者中断后，会通知当前节点的，回家等通知就好了，不用自旋频繁地来打听消息 if (ws == Node.SIGNAL) return true; // 如果前继节点的ws值大于0,即为1,说明前继节点处于放弃状态(Cancelled) // 那就继续往前遍历，直到当前节点的前继节点的ws值为0或负数 // 此处代码很关键，节点往前移动就是通过这里来实现的，直到节点的前继节点满足 // if (p == head &amp;&amp; tryAcquire(arg))条件，acquireQueued方法才能够跳出自旋过程 if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 将前继节点的ws值设置为Node.SIGNAL，以保证下次自旋时，shouldParkAfterFailedAcquire直接返回true compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; parkAndCheckInterrupt()函数则简单很多，主要调用LockSupport类的park()方法阻塞当前线程，并返回线程是否被中断过。 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 至此，独占模式下，线程获取资源acquire的代码就跟完了，总结一下过程： 首先线程通过tryAcquire(arg)尝试获取共享资源，若获取成功则直接返回，若不成功，则将该线程以独占模式添加到等待队列尾部，tryAcquire(arg)由继承AQS的自定义同步器来具体实现； 当前线程加入等待队列后，会通过acquireQueued方法基于CAS自旋不断尝试获取资源，直至获取到资源； 若在自旋过程中，线程被中断过，acquireQueued方法会标记此次中断，并返回true。 若acquireQueued方法获取到资源后，返回true，则执行线程自我中断操作selfInterrupt()。 123static void selfInterrupt() &#123; Thread.currentThread().interrupt();&#125; 释放资源(独占模式)讲完获取资源，对应的讲一下AQS的释放资源过程，其入口函数为： 1234567891011public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; // 获取到等待队列的头结点h Node h = head; // 若头结点不为空且其ws值非0，则唤醒h的后继节点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 逻辑并不复杂，通过tryRelease(arg)来释放资源，和tryAcquire类似，tryRelease也是有继承AQS的自定义同步器来具体实现。 tryRelease(int)该方法尝试释放指定量的资源。 123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125; unparkSuccessor(Node)该方法主要用于唤醒等待队列中的下一个阻塞线程。 1234567891011121314151617181920private void unparkSuccessor(Node node) &#123; // 获取当前节点的ws值 int ws = node.waitStatus; // 将当前节点的ws值置0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; // 若后继节点为null或者其ws值大于0(放弃状态)，则从等待队列的尾节点从后往前搜索， // 搜索到等待队列中最靠前的ws值非正且非null的节点 if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 如果后继节点非null，则唤醒该后继节点持有的线程 if (s != null) LockSupport.unpark(s.thread);&#125; 后继节点的阻塞线程被唤醒后，就进入到acquireQueued()的if (p == head &amp;&amp; tryAcquire(arg))的判断中，此时被唤醒的线程将尝试获取资源。 当然，如果被唤醒的线程所在节点的前继节点不是头结点，经过shouldParkAfterFailedAcquire的调整，也会移动到等待队列的前面，直到其前继节点为头结点。 讲解完独占模式下资源的acquire/release过程，下面开始讲解共享模式下，线程如何完成资源的获取和共享。 获取资源(共享模式)理解了独占模式下，资源的获取和释放过程，则共享模式下也就so easy了，首先看一下方法入口： 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 执行tryAcquireShared方法获取资源，若获取成功则直接返回，若失败，则进入等待队列，执行自旋获取资源，具体由doAcquireShared方法来实现。 tryAcquireShared(int)同样的，tryAcquireShared(int)由继承AQS的自定义同步器来具体实现。 123protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125; 其返回值为负值代表失败；0代表获取成功，但无剩余资源；正值代表获取成功且有剩余资源，其他线程可去获取。 doAcquireShared(int)1234567891011121314151617181920212223242526272829303132333435363738private void doAcquireShared(int arg) &#123; // 将线程以共享模式添加到等待队列的尾部 final Node node = addWaiter(Node.SHARED); // 初始化失败标志 boolean failed = true; try &#123; // 初始化线程中断标志 boolean interrupted = false; for (;;) &#123; // 获取当前节点的前继节点 final Node p = node.predecessor(); // 若前继节点为头结点，则执行tryAcquireShared获取资源 if (p == head) &#123; int r = tryAcquireShared(arg); // 若获取资源成功，且有剩余资源，将自己设为头结点并唤醒后续的阻塞线程 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC // 如果中断标志位为真，则线程执行自我了断 if (interrupted) selfInterrupt(); // 表征获取资源成功 failed = false; return; &#125; &#125; // houldParkAfterFailedAcquire(p, node)根据前继节点判断是否阻塞当前节点的线程 // parkAndCheckInterrupt()阻塞当前线程并检查线程是否被中断过，若被中断过，将interrupted置为true if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) // 放弃获取资源 cancelAcquire(node); &#125;&#125; 可以发现，doAcquireShared与独占模式下的acquireQueued大同小异，主要有2点不同： doAcquireShared将线程的自我中断操作放在了方法体内部； 当线程获取到资源后，doAcquireShared会将当前线程所在的节点设为头结点，若资源有剩余则唤醒后续节点，比acquireQueued多了个唤醒后续节点的操作。 上述方法体现了共享的本质，即当前线程吃饱了后，若资源有剩余，会招呼后面排队的来一起吃，好东西要大家一起分享嘛，哈哈。 下面具体看一下setHeadAndPropagate(Node, int)函数： 1234567891011121314private void setHeadAndPropagate(Node node, int propagate) &#123; // 记录原来的头结点，下面过程会用到 Node h = head; // 设置新的头结点 setHead(node); // 如果资源还有剩余，则唤醒后继节点 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 可以看到，实际执行唤醒后继节点的方法是doReleaseShared()，继续追踪： 123456789101112131415161718192021private void doReleaseShared() &#123; // 自旋操作 for (;;) &#123; // 获取等待队列的头结点 Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // 唤醒后继节点的线程 unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 释放资源(共享模式)首先进入到方法入口： 123456789public final boolean releaseShared(int arg) &#123; // 尝试释放资源 if (tryReleaseShared(arg)) &#123; // 唤醒后继节点的线程 doReleaseShared(); return true; &#125; return false;&#125; 同样的，tryReleaseShared(int)由继承AQS的自定义同步器来具体实现。 doReleaseShared()上节讲解setHeadAndPropagate已说明过，不再赘述。 至此，共享模式下的资源获取/释放就讲解完了，下面以一个具体场景来概括一下： 整个获取/释放资源的过程是通过传播完成的，如最开始有10个资源，线程A、B、C分别需要5、4、3个资源。 A线程获取到5个资源，其发现资源还剩余5个，则唤醒B线程； B线程获取到4个资源，其发现资源还剩余1个，唤醒C线程； C线程尝试取3个资源，但发现只有1个资源，继续阻塞； A线程释放1个资源，其发现资源还剩余2个，故唤醒C线程； C线程尝试取3个资源，但发现只有2个资源，继续阻塞； B线程释放2个资源，其发现资源还剩余4个，唤醒C线程； C线程获取3个资源，其发现资源还剩1个，继续唤醒后续等待的D线程； …… 总结本文主要介绍了AQS在独占和共享两种模式下，如何进行资源的获取和释放(tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared)，需要注意的是，在acquire()和acquireShared()方法中，线程在阻塞过程中均是忽略中断的。 AQS也可以通过acquireInterruptibly()/acquireSharedInterruptibly()来支持线程在等待过程中响应中断。 篇幅有限，本文就讲解到这里。对于AQS其他高级特性，感兴趣的读者可跟一下源码。 参考https://www.cnblogs.com/iou123lg/p/9464385.htmlhttps://www.cnblogs.com/waterystone/p/4920797.htmlhttps://www.jianshu.com/p/0da2939391cf 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊一聊ThreadLocal是个啥东东]]></title>
    <url>%2F2019%2F04%2F30%2F%E8%81%8A%E4%B8%80%E8%81%8AThreadLocal%E6%98%AF%E4%B8%AA%E5%95%A5%E4%B8%9C%E4%B8%9C%2F</url>
    <content type="text"><![CDATA[引言 ThreadLocal提供了线程私有的局部变量，可以在整个线程存活的过程中随时取用，从而减少了在同一个线程内多个函数或者组件之间公共变量传递的复杂度。同时，由于ThreadLocal变量的线程私有性，故不存在并发线程安全的问题。 要满足上述特性，需要解决3个问题： 与线程绑定，实现私有性； 提供合适的容器，方便变量的存取； 设计合理的垃圾回收机制，避免内存泄露。 实现原理为解决前2个问题，JDK最早期的设计是在ThreadLocal类内部维护一个线程安全的Map，线程的ID作为Map的key，实例对象作为Map的value，进而达到各个线程值隔离的效果。 该种中心化的模式下，通过Map的key来进行线程的绑定，而Map同时又作为变量的容器，ThreadLocal类需要处理复杂的多线程同步及变量回收问题，笨重且效率较低，所以后期JDK换了一种去中心化的方式，将管理权下放给了下面的各个线程，下面通过源码来阐述。 首先看set方法： 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 可以看到，set方法主要分为以下两个步骤： 通过getMap()获取当前线程的ThreadLocalMap(map)； 通过map.set(this, value)将当前的ThreadLocal(this)作为key，T(value)作为value添加进获取到的ThreadLocalMap(map)中。 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; threadLocals为Thread类的的成员变量，初始化为null。 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; get方法与之类似，可以看到现在的ThreadLocal是通过ThreadLocalMap来实现线程绑定和变量容器的，每个Thread均维护一个ThreadLocalMap映射表，key为ThreadLocal实例本身，而value是真正需要存储的的Object，该种模式带来3个直接的好处： ThreadLocalMap与线程同生命周期，当Thread销毁之后，对应的ThreadLocalMap也随之销毁，减少内存使用量； 映射表的Entity数量变小了，以前是Thread的数量，现在是ThreadLocal的数量，映射表更加轻量，故性能得到有效提高； 每个线程均有自己的ThreadLocalMap，保证了并发环境下的线程安全。 ThreadLocalMapThreadLocalMap是ThreadLocal的静态内部类，它具有HashMap的部分特性，比如容量、扩容阈值等，内部通过Entity类来存储key和value，Entity的定义为： 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; Entry继承自WeakReference，通过上述源码super(k)，可以知道，ThreadLocalMap是使用ThreadLocal的弱引用作为Key的。 分析到这里，可以得到下面ThreadLocal对象之间的引用结构图（其中，实线为强引用，虚线为弱引用）： 可以看到，Java堆上的ThreadLocal对象存在两个引用链，外部声明的强引用和ThreadLocalMap的key的弱引用，考虑以下情况： 删除ThreadLocal外部声明的强引用，即将ThreadLocal Ref置为null，此时只剩ThreadLocalMap的key的弱引用，当下次GC时，Java堆上的ThreadLocal对象将被回收，ThreadLocalMap上的key变为null。 需要注意的是，由于CurrentThread-&gt;Thread-&gt;ThreadLocalMap-&gt;Entity-&gt;value强引用链的存在，即使该Entity的key已经为null，value仍旧不会被回收，只有当线程被销毁之后，value的这部分内存空间才会被回收掉。 一般情况下，上述问题影响不大，但是在线程一直运行不被销毁的环境中(如线程池中的核心线程)，会存在内存泄露的问题。 内存回收由于Entity的value是与线程同生命周期的，所以当线程持续不被回收时，会造成内存泄露，为此ThreadLocalMap通过以下机制来解决上述问题. 首先看ThreadLocalMap的getEntry(ThreadLocal&lt;?&gt; key)方法： 12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125; 首先计算key所属entity在映射表中的位置i，如果映射表中i位置的entity非空且其key与方法传入的key相等，则直接返回entity；否则，调用getEntryAfterMiss(key, i, e)方法。 12345678910111213141516private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; getEntryAfterMiss方法通过i = nextIndex(i, len)，从table的当前位置i往后遍历table中非空的entity，若entity的key与传入的key相等，则返回该entity(可以看出ThreadLocalMap是采用线性探查的方式来解决hash冲突的，探查步长为1)；若entity的key为null，则调用expungeStaleEntry(i)方法。 1234567891011121314151617181920212223242526272829303132333435private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125; expungeStaleEntry(i)首先清理掉当前key为null的entity: 1234// expunge entry at staleSlottab[staleSlot].value = null;tab[staleSlot] = null;size--; 接着进行rehash过程，其基本过程是遍历table中非null的entity，若遍历到的entity，其key为null，则清理掉该entity；若遍历到的entity的key不为null，则检查key的散列值是否属于当前位置，若不属于，将当前位置置空(tab[i] = null;)，不断往后探查，若table的某位置为null，则将entity移动到该位置： 123456tab[i] = null;// Unlike Knuth 6.4 Algorithm R, we must scan until// null because multiple entries could have been stale.while (tab[h] != null) h = nextIndex(h, len);tab[h] = e; 这里的rehash过程，其实还有一种方法，就是当key的散列值j不属于当前位置i时，将table的位置i置空(tab[i] = null;)，然后将位置i原有的entity移动到table的j位置，若发生hash冲突，则往后线性探查。读者可以思考为啥JDK没有采用这种方法。 本质上讲，rehash过程一方面释放掉了key为null的entity的内存，避免了当前线程(CurrentThread)长期存在时的内存泄露问题。同时，rehash()将不属于某位置的entity移动到其他位置，避免了后面可能存在的hash冲突。 在ThreadLocalMap的set()和getEntity()方法中，均会调用expungeStaleEntry(int staleSlot)方法，但是当我们既不添加value也不获取value时，还是可能存在内存泄露的，所以最佳实践是：当ThreadLocal不需要时，手动调用其remove()方法，来删除对应的Entity及其value： 12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; 最终调用的是ThreadLocalMap的remove函数： 1234567891011121314private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125;&#125; 若对应的key存在，remove会调用expungeStaleEntry(i)方法来删除对应的entity和value。 总结 ThreadLocal是通过ThreadLocalMap来实现线程绑定和变量存储的； ThreadLocalMap的实体结构Entity继承自WeakReference，其key是对ThreadLocal对象的弱引用； ThreadLocal的get()、set(T)、remove()均会触发ThreadLocalMap的回收机制，删除无效的Entity。 小贴士：ThreadLocal的源码加注释也就722行，难度不大，设计得很是精巧，推荐读者阅读。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务隔离那些事儿]]></title>
    <url>%2F2019%2F04%2F26%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%2F</url>
    <content type="text"><![CDATA[在高并发环境下，由于多用户同时对数据库进行读/写操作，数据的可见性和操作的原子性需要通过事务机制来保障。 下面我们通过4个典型场景来讲解数据库的事务隔离机制。 首先在Mysql数据库中创建1张表： 123456CREATE TABLE `account` ( `id` int(11) NOT NULL COMMENT &apos;ID&apos;, `name` varchar(255) DEFAULT NULL COMMENT &apos;姓名&apos;, `account` float(255,0) DEFAULT NULL COMMENT &apos;账户余额&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 插入两条测试数据： 12insert into account values(1, &quot;小明&quot;, 1000);insert into account values(1, &quot;小强&quot;, 1000); 丢失更新假设现在有2个线程操作account表: 12345678910111213 线程A 线程B 读取到小明的account=1000 读取到小明的account=1000 set account=account+200 写回account=1200 set account=account+300 写回account=1300 很明显，在这种多线程更新操作下，线程A的更新丢失了，小明本来应该收到500元，结果只收到了300元。 还我血汗钱，小明要杀程序员祭天了… 于是，聪明的程序员引入了X锁来解决更新丢失的问题。 所谓X锁，又称排他锁(Exclusive Lock)或写锁，即某线程对数据添加X锁后，则独占该数据，其他线程不能更新该数据。该线程释放X锁后，其他线程获取到X锁后才可以进行更新操作，也就是说X锁属于独占锁，比较重。 于是上述的转账操作优化为: 1234567891011121314151617181920212223 线程A 线程B 获取account的X锁(成功) 读取到小明的account=1000 获取account的X锁(失败) set account=account+200 写回account=1200 ...... 释放account的X锁 获取account的X锁(成功) 读取到小明的account=1200 set account=account+300 写回account=1500 释放account的X锁 X锁优化对应的就是数据库事务隔离的最低级别Read Uncommited。 即Read Uncommited可以避免丢失更新。 脏读Read Uncommited虽然可以解决更新丢失的问题，但是X锁并不能约束其他线程并行的读取数据。 比如下述场景： 1234567891011121314151617181920 线程A 线程B 获取account的X锁(成功) 读取到小明的account=1000 set account=account+200 写回account=1200 读取到小明的account=1200 Rollback account恢复为1000 释放account的X锁 尴尬了！ 小明现在的数据是错误的 我们用mysql模拟上述操作： 客户端A: 123mysql&gt; set session transaction isolation level read uncommitted;mysql&gt; start transaction;mysql&gt; select * from account; 再起一个客户端B: 123mysql&gt; set session transaction isolation level read uncommitted;mysql&gt; start transaction;mysql&gt; update account set account=account+200 where id=1 此时，客户端B的事务还未commit，通过客户端A执行select操作： 可以看到，客户端A的事务看到了客户端B的事务里未提交的修改数据。 此时，数据库中小明的account仍然是1000，可以起一个客户端C(未开启事务)来验证: 也就是说，客户端A中读取的数据与数据库中实际值不一致，出现了脏读。 出现脏读的原因主要是X锁仅对多线程的更新操作添加了约束，而对读取操作没做要求。 解决方法也就呼之欲出了，对读取操作也进行加锁呗。 那么是不是直接对读取操作也加X锁呢？ 这样就太重了，而且由于X锁的独占性，当多线程环境下仅有读操作时，也需要频繁的加锁和释放锁，但实际上仅有读操作时，并发环境下并不会引发脏读(因为并没有线程更改数据嘛)。 于是，聪明的程序员引入了S锁来解决脏读的问题，同时又保证了锁的轻量性。 S锁，又称共享锁(Share Lock)或读锁，S锁与X锁的关系可以用1句话总结： 如果一个数据加了X锁，就没法加S锁；同样加了S锁，就没法加X锁。 当然，加了S锁的数据还可以继续添加S锁，因为并发读是互不影响的。 同时，在高并发环境下，为了防止单个线程长时间被S锁锁住，故有如下约定: 读数据前添加S锁，读完之后立即释放。 添加S锁机制之后，上面的流程优化如下： 123456789101112131415161718192021 线程A 线程B 获取account的X锁(成功) 读取到小明的account=1000 set account=account+200 写回account=1200 获取account的S锁(失败) Rollback ...... account恢复为1000 释放account的X锁 获取account的S锁(成功)读取到小明的account=1000 很明显，S锁限制了读时写和写时读，只有当写线程commit释放X锁之后，读线程才能获取到S锁完成数据的读取。 这种只能更新数据commit之后，才能读取到最新数据的事务隔离级别称为Read Committed。 即Read Committed可以避免脏读。 不可重复读在Read Committed事务隔离级别下，我们为了防止高并发环境下读线程长时间被锁住，做了以下规定： 读数据前添加S锁，读完之后立即释放。 此时，会出现以下问题： 12345678910111213141516171819202122 线程A 线程B 获取account的S锁(成功) 读取到的account=1000 释放account的S锁 获取account的X锁(成功) set account=account+200 做其他事情... 写回account=1200 释放account的X锁 获取account的S锁(成功) 重新读取到的account=1200 What? 与之前读的不一样了？ 此时，在同一个事务中重新读取的数据发生了变化，即不可重复读。 同样用mysql数据库演示上述过程： 客户端A: 123mysql&gt; set session transaction isolation level read committed;mysql&gt; start transaction;mysql&gt; select * from account; 此时再起一个客户端B: 12345mysql&gt; set session transaction isolation level read committed;mysql&gt; start transaction;mysql&gt; update account set account=account+200 where id=1;mysql&gt; select * from account;mysql&gt; commit; 此时，在客户端A的事务中继续查询: 故客户端A同一个事务中小明的account出现了2个不同的值，即出现了不可重复读。 而解决不可重复读的方法也很简单，把S锁的规定升级一下即可： 读数据前添加S锁，事务提交之后才可以释放。 此时，上面的流程变为： 123456789101112131415161718192021222324 线程A 线程B获取account的S锁(成功)读取到的account=1000 获取account的X锁(失败) 做其他事情... 获取account的S锁(成功) 读取到的account=1000 ...... 提交事务 释放account的S锁 获取account的X锁(成功) set account=account+200 写回account=1200 释放account的X锁 此时对应的数据库事务隔离级别即为Repeatable Read。 Repeatable Read解决了不可重复读的问题。 幻读通过X锁和S锁的组合应用，我们解决了数据的更新丢失、脏读、不可重复读3个问题，但由于X锁和S锁仅是对数据的更新(修改)和读取进行了限制，而对数据的添加和删除未做限制，那么即使在Repeatable Read隔离级别下，仍然会出现如下问题： 12345678910111213141516171819202122 线程A 线程B 获取数据的S锁(成功) 查询account表 [(1, &quot;小明&quot;, 1000) (2, &quot;小强&quot;, 1000)] 做其他事情... 插入数据(3, &quot;小花&quot;, 1000) 提交 插入数据(3, &quot;小花&quot;, 1000) 报错：&apos;3&apos; for key &apos;PRIMARY&apos; 查询account表[(1, &quot;小明&quot;, 1000)(2, &quot;小强&quot;, 1000)] What?这哪里有id为3的数据，眼花了？ 线程B的插入操作让线程A出现了幻觉，所以该种异常称之为幻读。 同样用mysql数据库演示上述过程： 客户端A: 123mysql&gt; set session transaction isolation level repeatable read;mysql&gt; start transaction;mysql&gt; select * from account; 此时再起一个客户端B: 12345mysql&gt; set session transaction isolation level repeatable read;mysql&gt; start transaction;mysql&gt; insert into account values(3, &quot;小红&quot;, 1000);mysql&gt; select * from account;mysql&gt; commit; 此时，客户端A在事务中继续执行： 12mysql&gt; insert into account values(3, &quot;小阁&quot;, 1500);mysql&gt; select * from account; 还有一种幻读，指的是： 12345678910111213141516 线程A 线程B 获取数据的S锁(成功) 查询account表中的人数 返回2 做其他事情... 插入数据(3, &quot;小花&quot;, 1000) 提交查询account表中的人数 返回3 What? 刚才还是2的？ 只是MySQL的InnoDB引擎默认的Repeatable Read级别已经通过MVCC自动帮我们解决了，所以该级别下, 我们也模拟不出该种幻读的场景。 至于MVCC是啥，后面抽空再聊，哈哈… 说实话，幻读和不可重复读很容易混淆： 不可重复读，主要是说在同一事务中多次读取一条记录, 发现该记录中某些列值被修改过； 幻读，主要是说在同一事务中多次读取一个范围内的记录(包括查询所有结果或者聚合统计)、插入时，发现结果不一致。 解决幻读，只能放出我们的终极大招了，对整个事务加X锁，将事务的执行串行化，对应的数据库事务隔离级别为Serializable。 即Serializable解决了幻读的问题。 总结 Read Uncommitted通过X锁来实现，锁住数据更新的阶段; Read Committed通过X锁和S锁来实现，且读完即释放S锁; Repeatable Read通过X锁和S锁来实现，事务提交之后释放S锁; Serializeable通过X锁来实现，锁住整个事务。 隔离级别 丢失更新 脏读 不可重复读 幻读 Read Uncommitted No Yes Yes Yes Read Committed No No Yes Yes Repeatable Read No No No Yes Serializeable No No No No 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RestTemplate源码解读]]></title>
    <url>%2F2019%2F04%2F25%2FRestTemplate%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[引言SpringCloud的微服务均是以Http接口的形式来暴露自身服务的，因此在调用远程服务的时候必须使用HTTP客户端，可选的方案有JDK原生的URL Connection、Apache的Http Client、Netty的异步Http Client，Spring的RestTemplate和Fegin。 今天主要介绍一下Spring的RestTemplate。 源码跟读通过源码可以看到RestTemplate进行请求的很多方法最终调用的均是doExecute方法。 可以看出，主要分为创建请求Request，执行请求Request，处理返回结果response3个步骤。 创建请求跟进createRequest()方法，发现该方法是由HttpAccessor负责实现的。 其基本思路是传入请求地址url和请求方法method，然后由ClientHttpRequestFactory工厂负责Request的创建，ClientHttpRequestFactory为一个接口，其实现类主要有： HttpAccessor提供了get/set方法，方便传入不同的ClientHttpRequestFactory实现类，如果需要自定义ClientHttpRequestFactory工厂，直接implements ClientHttpRequestFactory复写方法，然后注入HttpAccessor即可。 HttpAccessor默认使用的是SimpleClientHttpRequestFactory工厂实现类。 继续跟进SimpleClientHttpRequestFactory工厂实现类。 它提供了两种请求创建方法，分别支持同步和异步请求： createRequest(URI uri, HttpMethod httpMethod) createAsyncRequest(URI uri, HttpMethod httpMethod) 上述两种方法均包括打开连接、准备连接、创建连接3个步骤。 先看openConnection方法，它的实现比较简单，有代理Proxy存在，则传入Proxy打开连接，否则则直接通过URL打来连接。 prepareConnection方法主要根据传入的参数，进行连接前的一些配置工作，比如设置连接超时、读取超时、根据不同请求method设置相应配置参数等。 最后创建连接的时候，根据bufferRequestBody是否为True，创建2种不同的连接，分别为批处理连接和流处理连接。 1return (ClientHttpRequest)(this.bufferRequestBody ? new SimpleBufferingClientHttpRequest(connection, this.outputStreaming) : new SimpleStreamingClientHttpRequest(connection, this.chunkSize, this.outputStreaming)); 执行请求切回到RestTemplate类的doExecute方法，可以看到建立http连接，拿到ClientHttpRequest后，执行请求的方法为execute()。 ClientHttpRequest为接口，仅有一个execute()方法，看一下ClientHttpRequest的实现类： 其中用的比较多的是AbstractClientHttpRequest抽象类，SimpleStreamingClientHttpRequest和SimpleBufferingClientHttpRequest分别继承了AbstractClientHttpRequest，复写某些方法以支持流/批处理请求。 跟进AbstractClientHttpRequest抽象类的execute()方法， execute()内部调用的是executeInternal()，由子类来具体实现，可以看一下SimpleBufferingClientHttpRequest的方法实现，其他子类实现方式大同小异。 可以看到，主要是做了一些添加请求头、返回设置等的操作，最后得到请求的返回类SimpleClientHttpResponse。 至此，我们就拿到请求的返回了，下一步就是处理返回结果了。 处理返回结果返回结果处理主要分为两步： handleResponse(url, method, response) responseExtractor.extractData(response) 其中，handleResponse(url, method, response)主要负责对请求的异常进行处理。 可以看到，handleResponse()方法首先获取请求错误的处理器errorHandler，然后把response交给它进行后续的处理。 而responseExtractor.extractData(response)主要负责返回数据的解析。 responseExtractor为接口，其实现类为： 其中ResponseEntityResponseExtractor和HeadersExtractor为RestTemplate的内部类，主要处理返回的headers和entity，我们重点关注返回消息的转化处理类HttpMessageConverterExtractor。 可以看到，extractData先将response交给responseWrapper，如果responseWrapper有消息体且非空，则进行返回消息的读取操作。 消息的读取需要借助HttpMessageConverter接口，HttpMessageConverter具有多种实现类，以完成不同格式消息的读取，相当于消息解码器或转换头。 可以看到，在构建HttpMessageConverterExtractor实例的时候，需要传入HttpMessageConverter的接口集合messageConverters，用于对不同返回格式消息的读取。 首先，得到messageConverters的迭代器，然后遍历迭代器，依次执行不同HttpMessageConverter读取操作，最终完成返回消息体的读取操作。 迭代过程中，如果当前MessageConverter属于GenericHttpMessageConverter的接口实现，则执行： 1return genericMessageConverter.read(this.responseType, (Class)null, responseWrapper); 否则： 1return messageConverter.read(this.responseClass, responseWrapper); 总结 RestTemplate是Spring提供的用于访问Rest服务的客户端； RestTemplate提供了多种便捷访问远程Http服务的方法,能够大大提高客户端的编写效率； 调用RestTemplate的默认构造函数，RestTemplate对象在底层通过使用java.net包下的实现创建HTTP请求； 可以通过使用ClientHttpRequestFactory指定不同的HTTP请求方式； 在设计模式上，主要通过工厂模式来完成各类Http客户端的创建。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Springboot</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>RestTemplate</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo框架的HelloWorld]]></title>
    <url>%2F2018%2F12%2F14%2FDubbo%E6%A1%86%E6%9E%B6%E7%9A%84HelloWorld%2F</url>
    <content type="text"><![CDATA[随着微服务的流行，Dubbo和Spring Cloud框架受到越来越多的关注，本文主要基于1个简单Demo来介绍Dubbo框架的工作流程。 Dubbo是什么? Apache Dubbo (incubating) is a high-performance, java based, open source RPC framework. Dubbo是： 一个分布式服务框架； 致力于提供高性能和透明化的RPC远程服务调用方案； 阿里巴巴SOA服务化治理方案的核心框架，每天为2,000+个服务提供3,000,000,000+次访问量支持。 注：SOA是Service-Oriented Architecture的英文简称，即面向服务的架构，其主要解决多服务凌乱的问题，因此有人也称之为服务治理。 dubbo的工作流程如下： 其中： Provider为服务提供者，负责发布服务； Consumer为服务消费者，负责调用服务； Container为Dubbo容器，其依赖于Spring容器； Registry为注册中心，当Container启动时会将所有可提供的服务在Registry进行注册，其作用是告知Consumer有哪些服务，以及服务的地址； Monitor为监听器，负责服务注册、调用等流程的监控； 其中虚线为异步访问，实线为同步访问； 蓝色虚线代表Dubbo启动时完成的功能，红色虚线(实线)为程序运行过程中执行的功能。 注册中心Dubbo支持以下4种注册中心： Multicast 不需要启动任何中心节点，只要广播地址一样，就可以互相发现。组播受网络结构限制，只适合小规模应用或开发阶段使用。 Zookeeper 其优点是支持网络集群。 Redis 使用Redis的Key/Map结构存储数据； 主Key为服务名和类型； Map中的Key为URL地址； Map中的Value为过期时间，用于判断脏数据，脏数据由监控中心删除。(注意：服务器时间必需同步，否则过期检测会不准确)； 使用Redis的Publish/Subscribe事件通知数据变更； Simple 本身为普通的Dubbo服务，可以减少第三方依赖，使整体通讯方式一致，不支持集群，可作为自定义注册中心的参考，但不适合直接用于生产环境。 负载均衡策略Dubbo支持以下4种负载均衡策略： Random LoadBalance 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance 轮询，按公约后的权重设置轮询比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive LoadBalance 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance 一致性 Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 算法参见：http://en.wikipedia.org/wiki/Consistent_hashing 缺省只对第一个参数 Hash，如果要修改，请配置 缺省用 160 份虚拟节点，如果要修改，请配置 示例编写下面通过1个简单Demo实际体验一把Dubbo。 构建环境 Java 1.8.0_191 Zookeeper-3.4.10 dubbo 2.5.9 dubbo-monitor-simple-2.5.3 IntelliJ IDEA 2018.1 dubbo_service首先，基于Maven构建dubbo_service工程，其作用仅是定义服务的接口。 对应的pom.xml文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;groupId&gt;com.ruanshubin&lt;/groupId&gt; &lt;artifactId&gt;dubbo_service&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.5.9&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.101tec/zkclient --&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.11&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; DemoService 12345package com.ruanshubin.service;public interface DemoService &#123; String sayHello(String name);&#125; dubbo_providerdubbo_provider为服务提供者，故其需要实现前面定义的服务接口。 其pom.xml文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;groupId&gt;com.ruanshubin&lt;/groupId&gt; &lt;artifactId&gt;dubbo_provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruanshubin&lt;/groupId&gt; &lt;artifactId&gt;dubbo_service&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- 打包操作 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;mainClass&gt;&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 接口实现类DemoServiceImpl 123456789101112package com.ruanshubin.service.Impl;import com.ruanshubin.service.DemoService;public class DemoServiceImpl implements DemoService &#123; @Override public String sayHello(String name) &#123; System.out.println(&quot;服务被调用！&quot;); return &quot;Hello &quot; + name; &#125;&#125; 下面需要编写Container的启动类Provider。 1234567891011121314package com.ruanshubin.dubbo;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;public class Provider &#123; public static void main(String[] args) throws IOException &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;provider.xml&quot;); context.start(); System.out.println(&quot;服务启动成功！&quot;); System.in.read(); // 按任意键退出，该行代码的目的是保持容器的启动状态 &#125;&#125; 其中，provider.xml为Provider端的启动配置文件，具体为： 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=&quot;hello-world-app&quot; /&gt; &lt;!-- 配置注册中心 --&gt; &lt;dubbo:registry address=&quot;10.194.224.61:2181?backup=10.194.224.62:2181,10.194.224.63:2181&quot; protocol=&quot;zookeeper&quot;/&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt; &lt;!-- 声明需要暴露的服务接口 --&gt; &lt;dubbo:service interface=&quot;com.ruanshubin.service.DemoService&quot; ref=&quot;demoService&quot; /&gt; &lt;!-- 和本地bean一样实现服务 --&gt; &lt;bean id=&quot;demoService&quot; class=&quot;com.ruanshubin.service.Impl.DemoServiceImpl&quot; /&gt;&lt;/beans&gt; dubbo_consumerdubbo_consumer为服务消费方，先从注册中心拉取服务列表，然后调用相应服务。 其启动类Consumer如下： 123456789101112131415161718package com.ruanshubin.dubbo;import com.ruanshubin.service.DemoService;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Consumer &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;consumer.xml&quot;); // 获取服务实例 DemoService service = context.getBean(&quot;demoService&quot;, DemoService.class); // 调取服务的方法，调用10次来测试负载均衡 for(int i=0; i&lt;10; i++)&#123; String result = service.sayHello(args[0]); System.out.println(result); &#125; &#125;&#125; 其中，consumer.xml为Consumer端的启动配置文件，具体为： 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=&quot;hello-world-app&quot; /&gt; &lt;!-- 配置注册中心 --&gt; &lt;dubbo:registry address=&quot;10.194.224.61:2181?backup=10.194.224.62:2181,10.194.224.63:2181&quot; protocol=&quot;zookeeper&quot;/&gt; &lt;!-- 声明需要调用的服务接口 --&gt; &lt;dubbo:reference interface=&quot;com.ruanshubin.service.DemoService&quot; id=&quot;demoService&quot; /&gt;&lt;/beans&gt; 对dubbo_service执行install后，然后分别对dubbo_provider和dubbo_consumer执行package打包。 示例测试监控中心及管理控制台为方便查看服务的启动和调用(消费)情况，需要安装监控中心及管理控制台，其具体安装步骤如下： 监控中心 12345678910111213141516171819202122232425262728# 创建安装目录[root@slave1 software]# mkdir dubbo# 上传安装包、解压[root@slave1 ~]# mv dubbo-monitor-simple-2.5.3-assembly.tar.gz /usr/software/dubbo/tar -zxvf dubbo-monitor-simple-2.5.3-assembly.tar.gz# 修改配置文件，主要是修改注册中心的地址dubbo.registry.address# 这里填上设置好的Zookeeper集群地址[root@slave1 dubbo-monitor-simple-2.5.3]# vim conf/dubbo.propertiesdubbo.container=log4j,spring,registry,jettydubbo.application.name=simple-monitordubbo.application.owner=#dubbo.registry.address=multicast://224.5.6.7:1234dubbo.registry.address=zookeeper://slave1:2181?backup=slave2:2181,slave3:2181#dubbo.registry.address=redis://127.0.0.1:6379#dubbo.registry.address=dubbo://127.0.0.1:9090dubbo.protocol.port=7070dubbo.jetty.port=9090dubbo.jetty.directory=$&#123;user.home&#125;/monitordubbo.charts.directory=$&#123;dubbo.jetty.directory&#125;/chartsdubbo.statistics.directory=$&#123;user.home&#125;/monitor/statisticsdubbo.log4j.file=logs/dubbo-monitor-simple.logdubbo.log4j.level=WARN# 修改完配置文件，然后启动bin/start.sh 管理控制台1234567891011121314151617181920212223242526272829# 首先安装tomcat容器# 创建安装目录mkdir /usr/software/tomcat# 将安装包移动到安装目录mv ~/apache-tomcat-8.5.35.tar.gz /usr/software/tomcat# 切换到安装目录并解压cd /usr/software/tomcat tar -zxvf apache-tomcat-8.5.35.tar.gz# 启动bin/startup.sh# 登录界面 IP:8080# 清空tomcat/webapps/ROOT目录[root@slave1 apache-tomcat-8.5.35]# rm -rf webapps/ROOT/*# 解压dubbo-admin.war至tomcat/webapps/ROOT[root@slave1 apache-tomcat-8.5.35]# mv ~/dubbo-admin-2.5.4-jdk1.8.war /usr/software/dubbo/apache-tomcat-8.5.35[root@slave1 apache-tomcat-8.5.35]# unzip dubbo-admin-2.5.4-jdk1.8.war -d webapps/ROOT/# 修改配置文件，主要是配置管理控制台的注册中心地址，及用户名密码[root@slave1 apache-tomcat-8.5.35]# cd webapps/ROOT/WEB-INF/[root@slave1 WEB-INF]# vim dubbo.propertiesdubbo.registry.address=zookeeper://slave1:2181?backup=slave2:2181,slave3:2181dubbo.admin.root.password=rootdubbo.admin.guest.password=guest# 启动tomcatbin/startup.sh 管理控制台默认Web端口号为8080。 部署测试首先，将Provider端部署包dubbo_provider-1.0-SNAPSHOT.jar上传到相应机器，这里我上传了4台机器： 在4台机器上分别执行下述命令： 1java -jar dubbo_provider-1.0-SNAPSHOT.jar 注意：部署的机器须保证有对应版本的Java环境。 登录Dubbo的管理控制台，可以看到DemoService服务已经存在，并存在于4台机器上。 随便找一台与之前4台机器联网、有Java环境的机器，打开终端输入以下命令： 1java -jar dubbo_consumer-1.0-SNAPSHOT.jar World 可以看出，调用远程服务成功。 下面看看4台机器被调用的次数： 1号机器调用5次： 2号机器被调用3次： 3号机器被调用2次： 4号机器被调用0次： 之所以这样的原因是：Dubbo默认的负载均衡策略为Random。 Dubbo有4种均衡策略，其具体的工作机制是怎么样的呢，篇幅有限，我们下次出一篇专门讲。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文搞懂原码、反码、补码]]></title>
    <url>%2F2018%2F12%2F10%2F%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%8E%9F%E7%A0%81%E3%80%81%E5%8F%8D%E7%A0%81%E3%80%81%E8%A1%A5%E7%A0%81%2F</url>
    <content type="text"><![CDATA[计算机底层均是以二进制表示的，数字也不例外，本文旨在探讨一下数字的原码、反码和补码。 概念需要声明的是，本文涉及到的数字及运算均基于8位bit下的值。 原码最高位为符号位，0代表正数，1代表负数，非符号位为该数字绝对值的二进制表示。 如： 127的原码为0111 1111-127的原码为1111 1111 反码正数的反码与原码一致； 负数的反码是对原码按位取反，只是最高位(符号位)不变。 如: 127的反码为0111 1111-127的反码为1000 0000 补码正数的补码与原码一致； 负数的补码是该数的反码加1。 如： 127的补码为0111 1111-127的补码为1000 0001 总结一下就是： 正数的原码、反码、补码是一致的； 负数的补码是反码加1，反码是对原码按位取反，只是最高位(符号位)不变； 计算机数字运算均是基于补码的。 下面就来探讨一下，为啥要用补码来表示数字。 补码有啥好？如果计算机内部采用原码来表示数，那么在进行加法和减法运算的时候，需要转化为两个绝对值的加法和减法运算； 计算机既要实现加法器，又要实现减法器，代价有点大，那么可不可以只用一种类型的运算器来实现加和减的远算呢？ 很容易想到的就是化减为加，举一个生活中的例子来说明这个问题： 时钟一圈是360度，当然也存在365度，但其实它和5度是一样的； 相同的道理，-30度表示逆时针旋转30度，其与顺时针旋转330度是一样的； 这里数字360表示时钟的一圈，在计算机里类似的概念叫模，它可以实现化减为加，本质上是将溢出的部分舍去而不改变结果。 易得，单字节(8位)运算的模为256=2^8。 在没有符号位的情况下，127+2=129，即： 这时，我们将最高位作为符号位，计算机数字均以补码来表示，则1000 0001的原码为减1后按位取反得1111 1111，也就是-127。 也就是说，计算机里的129即表示-127，相当于模256为一圈，顺时针的129则和逆时针127即-127是一样的。 故可以得到以下结论： 负数的补码为模减去该数的绝对值。 如-5的补码为： -5=256-5=251=1111 1011(二进制) 同样的，临界值-128也可以表示出来： -128=256-128=128=1000 0000(二进制) 但是正128就会溢出了，故单字节(8位)表示的数字范围为-128—127。 最后，我们来看一下，补码是如何通过模的溢出舍弃操作来完成化减为加的！ 16-5=16+(-5)=11 1 0000 1011将溢出位舍去，得0000 1011(二进制)=11。 好的，本文分享就到这里，希望能够帮助到大家。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git教程--本地库提交到GitHub远程库]]></title>
    <url>%2F2018%2F12%2F09%2FGit%E6%95%99%E7%A8%8B--%E6%9C%AC%E5%9C%B0%E5%BA%93%E6%8F%90%E4%BA%A4%E5%88%B0GitHub%E8%BF%9C%E7%A8%8B%E5%BA%93%2F</url>
    <content type="text"><![CDATA[Git操作安装Git客户端客户端下载地址 Git配置 打开Git Bash，键入以下配置信息。 12git config --global user.name &quot;You Name&quot;git config --global user.email &quot;yourmail@server.com&quot; 初始化本地库 创建本地库文件夹并切换到该文件夹： 12mkdir MyGitcd MyGit 初始化 1git init 提交代码 创建代码文件后，将本地文件添加到Git版本库中： 12git add filenamegit commit -m &quot;First commit&quot; Github配置生成公开密钥 注册GitHub账号后，打开Git Bash，键入以下命令生成公开密钥。 1ssh-keygen -C &apos;yourmail@server.com&apos; -t rsa 一路回车即可以，然后会在C:\Users\你的Windows用户名\目录下出现.ssh文件夹，包含id_rsa和id_rsa.pub两个文件，其中id_rsa.pub即为公开密钥，用Notepad++打开，复制其中内容； GitHub上设置公开密钥回到 GitHub 个人首页，点击 Account Settings -&gt; SSH and GPG key -&gt; New SSH key。title 可以随便取名字，Key 里面添加的内容为 id_rsa.pub 文件内所有的代码，然后点击 Apply 即可。 测试与GitHub是否连接成功 打开Git Bash，键入以下代码： 1ssh -T git@github.com 若返回以下内容，则说明连接成功。 1Hi Your Name! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 推送项目文件至GitHub 打开Git Bash，键入以下代码： 12git remote add origin git@github.com:youusername/MyGit.gitgit push -u origin master 推送成功后，即可在GitHub上看到Push上的项目文件。 若出现以下错误： 1fatal: remote origin already exists. 则执行以下代码后，再执行上述代码即可解决上述问题。 1git remote rm origin 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Spark Streaming处理Kafka数据流]]></title>
    <url>%2F2018%2F12%2F08%2F%E4%BD%BF%E7%94%A8Spark%20Streaming%E5%A4%84%E7%90%86Kafka%E6%95%B0%E6%8D%AE%E6%B5%81%2F</url>
    <content type="text"><![CDATA[Kafka作为优秀的日志采集系统，可以作为Spark Streaming的高级数据源，本文主要介绍如何使用Spark Streaming实时处理Kafka传递过来的数据流。 系统软件本文实验基于的各软件版本如下： Java 1.8.0_191 Scala 2.11 hadoop-3.0.3 zookeeper-3.4.10 Spark 2.3.2 kafka_2.12-2.0.1 kafka-manager-1.3.3.17 具体步骤启动Kafka集群启动Kafka集群之前首先启动Zookeeper集群： 在安装有Zookeeper的机器上执行下述命令： 12cd /usr/software/zookeeper/zookeeper-3.4.10/bin/./zkServer.sh start 另外打开一个终端，输入以下命令启动Kafka集群： 12cd /usr/software/kafka/kafka_2.12-2.0.1/bin./kafka-server-start.sh ../config/server.properties 测试Kafka集群是否可以正常使用 12345cd /usr/software/kafka/kafka_2.12-2.0.1./bin/kafka-topics.sh --create --zookeeper slave1:2181,slave2:2181,slave3:2181 --replication-factor 3 --partitions 3 --topic wordsender//这个topic叫wordsender，2181是zookeeper默认的端口号，partition是topic里面的分区数，replication-factor是备份的数量//可以用list列出所有创建的topics,来查看上面创建的topic是否存在./bin/kafka-topics.sh --list --zookeeper slave1:2181,slave2:2181,slave3:2181 Kafka脚本测试数据的生成和消费下面使用Kafka的producer脚本生成一些数据： 1234567cd /usr/software/kafka/kafka_2.12-2.0.1/bin./kafka-console-producer.sh --broker-list master:9092 --topic wordsender执行上述命令后，即进入producer的console界面，输入一些数据：Hello WorldHello SparkHello Kafka 另外打开一个终端使用Kafka的consumer脚本消费上述producer脚本生成的数据： 12cd /usr/software/kafka/kafka_2.12-2.0.1/bin/./kafka-console-consumer.sh --bootstrap-server master:9092 --topic wordsender --from-beginning 需要注意的是，在旧版本的kafka-console-consumer.sh中，是通过—zookeeper来消费数据的，而新版本的kafka则删除了该方法，统一使用—bootstrap-server，后面跟的是broker-list参数。 编写相应程序测试Kafka的数据生产及消费本实验基于Maven作为项目构建工具，选择的IDE为IntelliJ IDEA 2018.1 ，采用的编程语言为Scala。 创建Maven工程后，项目处右键Add Frameworks Support: 首先，我们来编写producer端的代码： pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.ruanshubin&lt;/groupId&gt; &lt;artifactId&gt;SparkAndKafka&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;spark.version&gt;2.3.2&lt;/spark.version&gt; &lt;scala.version&gt;2.11&lt;/scala.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-core_$&#123;scala.version&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-streaming_$&#123;scala.version&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-sql_$&#123;scala.version&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-streaming-kafka-0-8_2.11&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.scala-tools&lt;/groupId&gt; &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt; &lt;version&gt;2.15.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;createDependencyReducedPom&gt;false&lt;/createDependencyReducedPom&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;mainClass&gt;com.ruanshubin.kafka.KafkaWordCount&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 必须使用spark-streaming-kafka-0-8_2.11，不能使用spark-streaming-kafka_2.11，因为该Jar打包的时候会遗漏org.apache.spark.Logging相关包。 spark-streaming-kafka-0-8_2.11的版本号一定与Scala和Spark版本严格对应，否则会报错。 KafkaWordProducer.scala 1234567891011121314151617181920212223242526272829303132333435package com.ruanshubin.kafkaimport java.utilimport org.apache.kafka.clients.producer.&#123;KafkaProducer, ProducerConfig, ProducerRecord&#125;object KafkaWordProducer &#123; def main(args: Array[String]): Unit = &#123; if(args.length &lt; 4)&#123; System.err.println(&quot;Usage: KafkaWordCountProducer &lt;metadataBrokerList&gt; &lt;topic&gt; +&quot; + &quot;&lt;messagePerSec&gt; &lt;wordPerMessage&gt;&quot;) System.exit(1) &#125; val Array(brokers, topic, messagesPerSec, wordPerMessage) = args val props = new util.HashMap[String, Object]() props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokers) props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;) props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;) val producer = new KafkaProducer[String, String](props) while(true)&#123; (1 to messagesPerSec.toInt).foreach&#123; messageNum =&gt; val str = (1 to wordPerMessage.toInt).map(x =&gt; scala.util.Random.nextInt(10) .toString).mkString(&quot; &quot;) print(str) println() val message = new ProducerRecord[String, String](topic, null, str) producer.send(message) &#125; Thread.sleep(1000) &#125; &#125;&#125; 上述程序的作用就是每秒钟产生messagesPerSec条消息，每条消息包含wordPerMessage个单词(这里用10以内的随机整数代替单词)。 数据产生端producer有了，下面我们编写消费端consumer的代码： KafkaWordCount 消费者主要将生产者传递过来的消息执行WordCount操作: 12345678910111213141516171819202122232425262728293031323334package com.ruanshubin.kafkaimport org.apache.spark.SparkConfimport org.apache.spark.streaming.kafka.KafkaUtilsimport org.apache.spark.streaming.&#123;Minutes, Seconds, StreamingContext&#125;// spark-streaming-kafka-0-8_2.11的版本号一定要与Scala版本和Spark版本号对应起来object KafkaWordCount &#123; def main(args: Array[String]): Unit = &#123; LoggerPro.setStreamingLogLevels() val sc = new SparkConf().setAppName(&quot;KafkaWordCount&quot;).setMaster(&quot;local[2]&quot;) val ssc = new StreamingContext(sc, Seconds(10)) // 设置检查点 ssc.checkpoint(&quot;/root/spark/checkpoint&quot;) // Zookeeper服务器地址 val zkQuorum = &quot;slave1:2181,slave2:2181,slave3:2181&quot; // consumer所在的group，可在一个group中设置多个consumer，加快消息消费的速度 val group = &quot;handsome_boy&quot; // topic的名称 val topics = &quot;wordsender&quot; // 每个topic的分区数 val numThreads = 3 val topicMap = topics.split(&quot;,&quot;).map((_,numThreads.toInt)).toMap val lineMap = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap) val lines = lineMap.map(_._2) val words = lines.flatMap(_.split(&quot; &quot;)) val pair = words.map(x =&gt; (x, 1)) val wordCounts = pair.reduceByKeyAndWindow(_ + _, _ - _,Minutes(2), Seconds(10), 3) wordCounts.print ssc.start ssc.awaitTermination &#125;&#125; LoggerPro的目的是设置日志的打印级别，从而让结果输出的更为清晰，避免被大量的打印信息淹没。 1234567891011121314151617package com.ruanshubin.kafkaimport org.apache.log4j.&#123;Level, Logger&#125;import org.apache.spark.internal.Loggingobject LoggerPro extends Logging&#123; def setStreamingLogLevels(): Unit =&#123; val log4jInitialized = Logger.getRootLogger.getAllAppenders.hasMoreElements if(!log4jInitialized)&#123; logInfo(&quot;Setting log level to [ERROR] for streaming example.&quot; + &quot; To override add a custom log4j.properties to the classPath&quot;) Logger.getRootLogger.setLevel(Level.ERROR) &#125; &#125;&#125; 最终的项目结构如下图所示： 打包、提交集群运行 Maven打包 提交服务器 将项目target目录下生成的可执行Jar包上传到服务器指定目录，这里我上传到/usr/software/spark/mycode/streaming。 启动Kafka Manager 为了直观观察到数据流的流转，我们启动Kafka Manager： 12cd /usr/software/kafka/kafka-manager-1.3.3.17/bin./kafka-manager -Dhttp.port=9002 运行 首先启动Producer端： 12cd /usr/software/spark/spark-2.3.2-bin-hadoop2.7/bin/./spark-submit --class &quot;com.ruanshubin.kafka.KafkaWordProducer&quot; /usr/software/spark/mycode/streaming/SparkAndKafka-1.0-SNAPSHOT.jar slave1:9092,slave2:9092,slave3:9092 wordsender 3 5 新打开一个终端,启动消费者： 12cd /usr/software/spark/spark-2.3.2-bin-hadoop2.7/bin/./spark-submit --class &quot;com.ruanshubin.kafka.KafkaWordCount&quot; /usr/software/spark/mycode/streaming/SparkAndKafka-1.0-SNAPSHOT.jar 可以看到，Spark Streaming在实时消费Kafka里传过来的数据。 同时，查看Kafka Manger也可以看到数据在实时得产生和消费。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Bigdata</category>
      </categories>
      <tags>
        <tag>Spark Streaming</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据环境搭建（Hadoop,Spark,Zookeeper,Hbase,Kafka）]]></title>
    <url>%2F2018%2F12%2F07%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%EF%BC%88Hadoop%2CSpark%2CZookeeper%2CHbase%2CKafka%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本教程基于4台机器(预装有CentOS7 Linux系统)完成Hadoop集群及其相关组件的搭建，1个master，3个slave。 Linux环境准备基础设置 修改主机名 12hostnamectl set-hostname masterreboot 依次将其他3台机器设置为slave1,slave2,slave3。 修改IP地址 123456789101112131415161718192021222324vim /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=&quot;Ethernet&quot;PROXY_METHOD=&quot;none&quot;BROWSER_ONLY=&quot;no&quot;BOOTPROTO=&quot;static&quot;DEFROUTE=&quot;yes&quot;IPV4_FAILURE_FATAL=&quot;no&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;IPV6_DEFROUTE=&quot;yes&quot;IPV6_FAILURE_FATAL=&quot;no&quot;IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot;NAME=&quot;ens33&quot;UUID=&quot;c35b7341-8921-48f5-ad7a-08cb5af4ba54&quot;DEVICE=&quot;ens33&quot;ONBOOT=&quot;yes&quot;IPADDR=xxx.xxx.xxx.xxxNETMASK=255.255.255.0GATEWAY=xxx.xxx.xxx.xxxDNS1=8.8.8.8DNS2=8.8.4.4service network restart 关闭防火墙 12systemctl stop firewalldsystemctl disable firewalld ssh通信 12345678// 生成密钥ssh-keygen -t rsa// 将公钥追加到验证表中cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys // 将公钥追加到其他主机验证表中ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave1ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave2ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave3 网络配置 推荐使用桥接模式，且IP与宿主机处于同一区段，网关、子页掩码、DNS与宿主机保持一致，IP采用静态或DHCP均可，推荐使用静态模式，以防IP经常变化，频繁修改/etc/hosts等配置文件。需要注意的是，IP设置使用静态模式时，需要在宿主机上ping一下相关IP，以防IP已被占用，设置之后引起冲突。 配置hosts，以便DNS解析主机名 1234567891011vim /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6xxx.xxx.xxx.xxx masterxxx.xxx.xxx.xxx slave1xxx.xxx.xxx.xxx slave2xxx.xxx.xxx.xxx slave3拷贝给其他主机:scp /etc/hosts root@slave1:/etc/ Java环境安装包拷贝、解压将压缩包拷贝至Linux系统中，移动到/usr/software/java目录下,并解压： 12mv jdk-8u191-linux-x64.tar.gz /usr/software/javatar -zxvf jdk-8u191-linux-x64.tar.gz 设置环境变量123456vim /etc/profileexport JAVA_HOME=/usr/software/java/jdk1.8.0_191export JRE_HOME=$JAVA_HOME/jreexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport CLASS_PATH=.:$JAVA_HOME/lib:$JRE_HOME/lib Esc[:wq]保存后，执行以下命令让其当即生效： 1source /etc/profile 输入： 123456java -version出现以下信息则表明hadoop安装成功：java version &quot;1.8.0_191&quot;Java(TM) SE Runtime Environment (build 1.8.0_191-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode) Hadoop全家桶Hadoop集群安装包拷贝、解压将压缩包拷贝至Linux系统中，移动到/usr/software/hadoop目录下,并解压： 12mv hadoop-3.0.3.tar.gz /usr/software/hadooptar -zxvf hadoop-3.0.3.tar.gz 设置环境变量1234vim /etc/profileexport HADOOP_INSTALL=/usr/software/hadoop/hadoop-3.0.3export PATH=$PATH:$HADOOP_INSTALL/bin:$HADOOP_INSTALL/sbin Esc[:wq]保存后，执行以下命令让其当即生效： 1source /etc/profile 修改启动文件主要为hadoop指定java环境： 1234567vim vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/hadoop-env.sh添加如下内容后保存：JAVA_HOME=/usr/software/java/jdk1.8.0_191使其当即生效：source /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/hadoop-env.sh 输入： 123456789hadoop version出现以下信息则表明hadoop安装成功：Hadoop 3.0.3Source code repository https://yjzhangal@git-wip-us.apache.org/repos/asf/hadoop.git -r 37fd7d752db73d984dc31e0cdfd590d252f5e075Compiled by yzhang on 2018-05-31T17:12ZCompiled with protoc 2.5.0From source with checksum 736cdcefa911261ad56d2d120bf1faThis command was run using /usr/software/hadoop/hadoop-3.0.3/share/hadoop/common/hadoop-common-3.0.3.jar 修改配置文件 core-site.xml 主要配置HDFS的地址和端口号。 1234567891011121314vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/core-site.xml&lt;configuration&gt; &lt;!-- 指定HDFS老大(namenode)的通信地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定hadoop运行时产生文件的存储路径 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/software/hadoop/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml 主要配置分布式文件系统。 1234567891011121314151617181920212223242526272829vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/hdfs-site.xml&lt;configuration&gt; &lt;!-- 设置namenode的http通讯地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address&lt;/name&gt; &lt;value&gt;master:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置secondary namenode的http通讯地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;slave1:50090&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置namenode的存放路径 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/usr/software/hadoop/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置datanode的存放路径 --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/usr/software/hadoop/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置hdfs副本数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml 主要是配置JobTracker的地址和端口。 123456789vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/mapred-site.xml&lt;configuration&gt; &lt;!-- 设置框架MR使用YARN --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn-site.xml 主要设置resourcemanager以及reducer取数据的方式。 1234567891011121314151617181920vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/yarn-site.xml&lt;configuration&gt; &lt;!-- 设置resourcemanager在哪个节点 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置reducer取数据的方式是mapreduce_shuffle --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; master和slaves 12345678910111213vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/mastermaster#######################################################vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/slavesslave1slave2slave3# 需要注意的是：hadoop3.0之后，默认配置文件中无slaves，以workers替代，设置方式与slaves等同。 启动集群 格式化集群的文件系统 1hadoop namenode -format 启动hadoop集群 1start-all.sh 关闭hadoop集群 1stop-all.sh HDFS的web界面端口：50070 YARN的web界面端口：8088 Spark安装Scala环境 安装包拷贝、解压 将压缩包拷贝至Linux系统中，移动到/usr/software/scala目录下,并解压： 12mv scala-2.12.7.tgz /usr/software/scalatar -zxvf scala-2.12.7.tgz 设置环境变量 1234vim /etc/profileexport SCALA_HOME=/usr/software/scala/scala-2.12.7export PATH=$PATH:$SCALA_HOME/bin Esc[:wq]保存后，执行以下命令让其当即生效： 1source /etc/profile 输入： 12345678scala出现以下信息则表明hadoop安装成功：Welcome to Scala 2.12.7 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_191).Type in expressions for evaluation. Or try :help.scala&gt; Spark集群 安装包拷贝、解压 将压缩包拷贝至Linux系统中，移动到/usr/software/spark目录下,并解压： 12mv spark-2.3.2-bin-hadoop2.7.tgz /usr/software/sparktar -zxvf spark-2.3.2-bin-hadoop2.7.tgz 设置环境变量 1234vim /etc/profileexport SPARK_HOME=/usr/software/spark/spark-2.3.2-bin-hadoop2.7export PATH=$PATH:$SPARK_HOME/bin Esc[:wq]保存后，执行以下命令让其当即生效： 1source /etc/profile 配置spark参数 12345678910111213141516cd /usr/software/spark/spark-2.3.2-bin-hadoop2.7/conf/cp spark-env.sh.template spark-env.shvim spark-env.sh添加如下内容：export JAVA_HOME=/usr/software/java/jdk1.8.0_191export SCALA_HOME=/usr/software/scala/scala-2.12.7export SPARK_MASTER_IP=xxx.xxx.xxx.xxxexport SPARK_WORKER_MEMORY=8gexport HADOOP_CONF_DIR=/usr/software/hadoop/hadoop-3.0.3/etc/hadoopvim slavesslave1slave2slave3 spark集群启动1234cd /usr/software/spark/spark-2.3.2-bin-hadoop2.7/sbin/./start-all.sh注意：spark和hadoop的启动脚本名称是相同的，又因为hadoop已经将sbin目录配置进Path环境变量中去了，所以启动spark时，需要进入spark的sbin目录。 web界面端口：8080 Zookeeper集群本教程中，我们使用slave1,slave2,slave3三台机器搭建zookeeper集群。 首先在slave1上进行相关安装，然后将配置好的目录复制到其他机器上(slave2, slave3)即可。 安装包拷贝、解压 将压缩包拷贝至Linux系统中，移动到/usr/software/zookeeper目录下,并解压： 12mv zookeeper-3.4.10.tar.gz /usr/software/zookeepertar -zxvf zookeeper-3.4.10.tar.gz 配置文件修改 12345678910111213cd /usr/software/zookeeper/zookeeper-3.4.10/confcp ./zoo_sample.cfg ./zoo.cfgvim zoo.cfgtickTime=2000initLimit=10syncLimit=5dataDir=/usr/software/zookeeper/zookeeper-3.4.10/data # 修改存放zookeeper数据的目录clientPort=2181# 添加3个节点的信息server.1=slave1:2888:3888server.2=slave2:2888:3888server.3=slave3:2888:3888 配置参数说明 tickTime：zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔,也就是说每个tickTime时间就会发送一个心跳。 initLimit：配置zookeeper接受客户端（这里所说的客户端不是用户连接zookeeper服务器的客户端,而是zookeeper服务器集群中连接到leader的follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。 当已经超过10个心跳的时间（也就是tickTime）长度后 zookeeper 服务器还没有收到客户端的返回信息,那么表明这个客户端连接失败。总的时间长度就是 10*2000=20秒。 syncLimit：标识leader与follower之间发送消息,请求和应答时间长度,最长不能超过多少个tickTime的时间长度,总的时间长度就是5*2000=10秒。 dataDir：zookeeper保存数据的目录,默认情况下zookeeper将写数据的日志文件也保存在这个目录里； clientPort：客户端连接Zookeeper服务器的端口,Zookeeper会监听这个端口接受客户端的访问请求； server.A=B:C:D中的A是一个数字,表示这个是第几号服务器,B是这个服务器的IP地址，C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的leader服务器交换信息的端口，D是在leader挂掉时专门用来进行选举leader所用的端口。 创建ServerID标识 除了修改zoo.cfg配置文件外,zookeeper集群模式下还要配置一个myid文件,这个文件需要放在dataDir目录下。 12345/usr/software/zookeeper/zookeeper-3.4.10/datavim myid1[ESC] + wq保存即可 同时在slave2,slave3相同路径下创建myid文件，并分别输入2, 3保存。 集群启动 在每台机器上分别执行以下命令： 12cd /usr/software/zookeeper/zookeeper-3.4.10/bin/./zkServer.sh start 可以输入以下命令查看机器zookeeper的状态： 1234[root@slave1 bin]# ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /usr/software/zookeeper/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: follower 可以看出，当前节点为zookeeper的从节点。 Hbase集群本案例基于4台机器搭建Hbase集群： 安装包拷贝、解压 将压缩包拷贝至Linux系统中，移动到/usr/software/hbase目录下,并解压： 12mv hbase-1.2.8-bin.tar.gz /usr/software/hbasetar -zxvf hbase-1.2.8-bin.tar.gz hbase-site.xml 1234567891011121314151617181920212223242526272829303132333435cd /usr/software/hbase/hbase-1.2.8/confvim hbase-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.master&lt;/name&gt; &lt;value&gt;master:60000&lt;/value&gt; &lt;description&gt;hbase的主节点与端口号&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master.maxclockskew&lt;/name&gt; &lt;value&gt;180000&lt;/value&gt; &lt;description&gt;时间同步允许的时间差&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;description&gt;hbase共享目录，持久化hbase数据&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;是否为分布式&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;slave1,slave2,slave3&lt;/value&gt; &lt;description&gt;指定zookeeper&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;description&gt;备份数&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; regionservers 123456cd /usr/software/hbase/hbase-1.2.8/confvim regionservers slave1slave2slave3 将配置好的hbase目录同步到另外3台机器。 启动hbase 12cd /usr/software/hbase/hbase-1.2.8/bin./start-hbase.sh 启动后，在master节点jps看到HMaster进程，slave节点多出HRegionServer进程。 Hbase的Web管理界面：16010 Kafka集群本案例基于4台机器搭建Kafka集群： 安装包拷贝、解压 将压缩包拷贝至Linux系统中，移动到/usr/software/kafka目录下,并解压： 12mv kafka_2.12-2.0.1.tgz /usr/software/kafkatar -zxvf kafka_2.12-2.0.1.tgz 修改配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465cd /usr/software/kafka/kafka_2.12-2.0.1/configvim vim server.properties broker.id=0listeners=PLAINTEXT://master:9092# The number of threads that the server uses for receiving requests from the network and sending responses to the networknum.network.threads=3# The number of threads that the server uses for processing requests, which may include disk I/Onum.io.threads=8# The send buffer (SO_SNDBUF) used by the socket serversocket.send.buffer.bytes=102400# The receive buffer (SO_RCVBUF) used by the socket serversocket.receive.buffer.bytes=102400# The maximum size of a request that the socket server will accept (protection against OOM)socket.request.max.bytes=104857600############################# Log Basics ############################## A comma separated list of directories under which to store log fileslog.dirs=/usr/software/kafka/kafka_2.12-2.0.1/logs# The default number of log partitions per topic. More partitions allow greater# parallelism for consumption, but this will also result in more files across# the brokers.num.partitions=1# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.# This value is recommended to be increased for installations with data dirs located in RAID array.num.recovery.threads.per.data.dir=1############################# Internal Topic Settings ############################## The replication factor for the group metadata internal topics &quot;__consumer_offsets&quot; and &quot;__transaction_state&quot;# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1# The minimum age of a log file to be eligible for deletion due to agelog.retention.hours=168sage.max.byte=5242880 # 消息保存的最大值5Mdefault.replication.factor=3 # kafka保存消息的副本数，如果一个副本失效了，另两个还可以继续提供服务replica.fetch.max.bytes=5242880 # 取消息的最大直接数# A size-based retention policy for logs. Segments are pruned from the log unless the remaining# segments drop below log.retention.bytes. Functions independently of log.retention.hours.#log.retention.bytes=1073741824# The maximum size of a log segment file. When this size is reached a new log segment will be created.log.segment.bytes=1073741824# The interval at which log segments are checked to see if they can be deleted according# to the retention policieslog.retention.check.interval.ms=300000############################# Zookeeper ############################## Zookeeper connection string (see zookeeper docs for details).# This is a comma separated host:port pairs, each corresponding to a zk# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.# You can also append an optional chroot string to the urls to specify the# root directory for all kafka znodes.zookeeper.connect=slave1:2181,slave2:2181,slave3:2181# Timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000############################# Group Coordinator Settings ############################## The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.# The default value for this is 3 seconds.# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.group.initial.rebalance.delay.ms=0# 主要修改broker.id，log.dirs，zookeeper.connect 将配置好的hbase目录同步到另外3台机器，并修改配置文件中的broker.id。 启动 12/usr/software/kafka/kafka_2.12-2.0.1/bin./kafka-server-start.sh -daemon ../config/server.properties kafka manager安装 安装详情 kafka manager安装时默认的Web端口为9000,与hadoop的RPC端口冲突，故启动时需要指定另外一个端口号，如： 1bin/kafka-manager -Dhttp.port=9002 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Bigdata</category>
      </categories>
      <tags>
        <tag>Bigdata</tag>
        <tag>环境搭建</tag>
      </tags>
  </entry>
</search>
