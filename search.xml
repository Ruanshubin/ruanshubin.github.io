<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Flink的分布式缓存]]></title>
    <url>%2F2019%2F09%2F16%2FFlink%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[分布式缓存Flink提供了一个分布式缓存，类似于hadoop，可以使用户在并行函数中很方便的读取本地文件，并把它放在taskmanager节点中，防止task重复拉取。 此缓存的工作机制如下：程序注册一个文件或者目录(本地或者远程文件系统，例如hdfs或者s3)，通过ExecutionEnvironment注册缓存文件并为它起一个名称。 当程序执行，Flink自动将文件或者目录复制到所有taskmanager节点的本地文件系统，仅会执行一次。用户可以通过这个指定的名称查找文件或者目录，然后从taskmanager节点的本地文件系统访问它。 示例在ExecutionEnvironment中注册一个文件： 1234// 获取运行环境ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();// 注册一个文件 本地文件或者分布式文件env.registerCachedFile(&quot;flink-common\\src\\main\\resources\\cache.txt&quot;, &quot;cache&quot;); 在用户函数中访问缓存文件或者目录(这里是一个map函数)。这个函数必须继承RichFunction,因为它需要使用RuntimeContext读取数据: 1234567891011121314151617DataSet&lt;String&gt; result = data.map(new RichMapFunction&lt;String, String&gt;() &#123; String cacheString; @Override public void open(Configuration parameters) throws Exception &#123; super.open(parameters); File cache = getRuntimeContext().getDistributedCache().getFile(&quot;cache&quot;); cacheString = FileUtils.readFileUtf8(cache); &#125; @Override public String map(String value) throws Exception &#123; return cacheString + &quot;: &quot; + value; &#125; &#125;); 完整代码见：https://github.com/Ruanshubin/awesome-flink/tree/master/flink-common/src/main/java/com/ruanshubin/bigdata/flink/common/cache 开源推荐在学习Flink的过程中，本人将涉及到的测试案例、源码解读、开发技巧等系统整理了一下，并开源到Github上，地址为： https://github.com/Ruanshubin/awesome-flink 欢迎大家Star支持！]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink的Window源码剖析]]></title>
    <url>%2F2019%2F08%2F19%2FFlink%E7%9A%84Window%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Window 可以看到，GlobalWindow和TimeWindow均继承自抽象类Window，其源码如下： 123public abstract class Window &#123; public abstract long maxTimestamp();&#125; 可以看出，Window抽象类仅有一个maxTimestamp()方法用于获取仍属于该窗口的最大时间戳。 TimeWindow首先看TimeWindow的数据结构： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public class TimeWindow extends Window &#123; private final long start; private final long end; public TimeWindow(long start, long end) &#123; this.start = start; this.end = end; &#125; public long getStart() &#123; return start; &#125; public long getEnd() &#123; return end; &#125; @Override public long maxTimestamp() &#123; return end - 1; &#125; @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (o == null || getClass() != o.getClass()) &#123; return false; &#125; TimeWindow window = (TimeWindow) o; return end == window.end &amp;&amp; start == window.start; &#125; @Override public int hashCode() &#123; return MathUtils.longToIntWithBitMixing(start + end); &#125; @Override public String toString() &#123; return &quot;TimeWindow&#123;&quot; + &quot;start=&quot; + start + &quot;, end=&quot; + end + &apos;&#125;&apos;; &#125; public boolean intersects(TimeWindow other) &#123; return this.start &lt;= other.end &amp;&amp; this.end &gt;= other.start; &#125; public TimeWindow cover(TimeWindow other) &#123; return new TimeWindow(Math.min(start, other.start), Math.max(end, other.end)); &#125; ...... public static void mergeWindows(Collection&lt;TimeWindow&gt; windows, MergingWindowAssigner.MergeCallback&lt;TimeWindow&gt; c) &#123; List&lt;TimeWindow&gt; sortedWindows = new ArrayList&lt;&gt;(windows); Collections.sort(sortedWindows, new Comparator&lt;TimeWindow&gt;() &#123; @Override public int compare(TimeWindow o1, TimeWindow o2) &#123; return Long.compare(o1.getStart(), o2.getStart()); &#125; &#125;); List&lt;Tuple2&lt;TimeWindow, Set&lt;TimeWindow&gt;&gt;&gt; merged = new ArrayList&lt;&gt;(); Tuple2&lt;TimeWindow, Set&lt;TimeWindow&gt;&gt; currentMerge = null; for (TimeWindow candidate: sortedWindows) &#123; if (currentMerge == null) &#123; currentMerge = new Tuple2&lt;&gt;(); currentMerge.f0 = candidate; currentMerge.f1 = new HashSet&lt;&gt;(); currentMerge.f1.add(candidate); &#125; else if (currentMerge.f0.intersects(candidate)) &#123; currentMerge.f0 = currentMerge.f0.cover(candidate); currentMerge.f1.add(candidate); &#125; else &#123; merged.add(currentMerge); currentMerge = new Tuple2&lt;&gt;(); currentMerge.f0 = candidate; currentMerge.f1 = new HashSet&lt;&gt;(); currentMerge.f1.add(candidate); &#125; &#125; if (currentMerge != null) &#123; merged.add(currentMerge); &#125; for (Tuple2&lt;TimeWindow, Set&lt;TimeWindow&gt;&gt; m: merged) &#123; if (m.f1.size() &gt; 1) &#123; c.merge(m.f1, m.f0); &#125; &#125; &#125; public static long getWindowStartWithOffset(long timestamp, long offset, long windowSize) &#123; return timestamp - (timestamp - offset + windowSize) % windowSize; &#125;&#125; 该窗口主要用于实现时间驱动的相关操作。 可以看到。TimeWindow由start和end2个时间戳组成，最大时间戳为end-1，同时，TimeWindow提供了getWindowStartWithOffset静态方法，用于获取时间戳所属时间窗的起点，其中的offset为偏移量。例如，没有偏移量的话，小时滚动窗口将按时间纪元来对齐，也就是1:00:00—1:59:59,2:00:00—2:59:59等，如果你指定了15分钟的偏移，你将得到1:15:00—2:14:59,2:15:00—3:14:59等。时间偏移主要用于调准非0时区的窗口，例如:在中国你需要指定8小时的时间偏移。 intersects方法用于判断2个时间窗是否有交集，cover方法用于求2个时间窗的合集，mergeWindows用于将时间窗集合进行合并，该方法是实现Session Window的关键。 对于session window来说，我们需要窗口变得更灵活。基本的思想是这样的：SessionWindows assigner 会为每个进入的元素分配一个窗口，该窗口以元素的时间戳作为起始点，时间戳加会话超时时间为结束点，也就是该窗口为[timestamp, timestamp+sessionGap)。比如我们现在到了两个元素，它们被分配到两个独立的窗口中，两个窗口目前不相交，如图： 当第三个元素进入时，分配到的窗口与现有的两个窗口发生了叠加，情况变成了这样： 由于我们支持了窗口的合并，WindowAssigner可以合并这些窗口。它会遍历现有的窗口，并告诉系统哪些窗口需要合并成新的窗口。Flink 会将这些窗口进行合并，合并的主要内容有两部分： 需要合并的窗口的底层状态的合并（也就是窗口中缓存的数据，或者对于聚合窗口来说是一个聚合值）； 需要合并的窗口的Trigger的合并（比如对于EventTime来说，会删除旧窗口注册的定时器，并注册新窗口的定时器）。 总之，结果是三个元素现在在同一个窗口中： 需要注意的是，对于每一个新进入的元素，都会分配一个属于该元素的窗口，都会检查并合并现有的窗口。在触发窗口计算之前，每一次都会检查该窗口是否可以和其他窗口合并，直到trigger触发后，会将该窗口从窗口列表中移除。对于 event time 来说，窗口的触发是要等到大于窗口结束时间的 watermark 到达，当watermark没有到，窗口会一直缓存着。所以基于这种机制，可以做到对乱序消息的支持。 这里有一个优化点可以做，因为每一个新进入的元素都会创建属于该元素的窗口，然后合并。如果新元素连续不断地进来，并且新元素的窗口一直都是可以和之前的窗口重叠合并的，那么其实这里多了很多不必要的创建窗口、合并窗口的操作，我们可以直接将新元素放到那个已存在的窗口，然后扩展该窗口的大小，看起来就像和新元素的窗口合并了一样。 GlobalWindow接着看GlobalWindow： 12345678910111213141516171819202122232425262728293031323334public class GlobalWindow extends Window &#123; private static final GlobalWindow INSTANCE = new GlobalWindow(); private GlobalWindow() &#123; &#125; public static GlobalWindow get() &#123; return INSTANCE; &#125; @Override public long maxTimestamp() &#123; return Long.MAX_VALUE; &#125; @Override public boolean equals(Object o) &#123; return this == o || !(o == null || getClass() != o.getClass()); &#125; @Override public int hashCode() &#123; return 0; &#125; @Override public String toString() &#123; return &quot;GlobalWindow&quot;; &#125; /** * 序列化相关操作 */&#125; GlobalWindow提供了get()静态方法用于获取GlobalWindow实例，maxTimestamp()统一返回Long的最大值，而hashCode统一返回0。 该窗口主要用于实现数据驱动的相关操作。 WindowAssigner顾名思义，WindowAssigner用来决定某个元素被分配到哪个/哪些窗口中去。 1234567891011121314151617public abstract class WindowAssigner&lt;T, W extends Window&gt; implements Serializable &#123; private static final long serialVersionUID = 1L; public abstract Collection&lt;W&gt; assignWindows(T element, long timestamp, WindowAssignerContext context); public abstract Trigger&lt;T, W&gt; getDefaultTrigger(StreamExecutionEnvironment env); public abstract TypeSerializer&lt;W&gt; getWindowSerializer(ExecutionConfig executionConfig); public abstract boolean isEventTime(); public abstract static class WindowAssignerContext &#123; public abstract long getCurrentProcessingTime(); &#125;&#125; 首先看assignWindows方法，其输入element为待分配的元素，timestamp为element持有的时间戳，context为该分配器的上下文容器，返回值为element所属的窗口集合，也就说，同一条数据元素，可能会被分配到多个窗口中去。但并不是将该数据复制到多个窗口中去，Window本身只是一个ID标识符，其内部可能存储了一些元数据，如TimeWindow中有开始和结束时间，但是并不会存储窗口中的元素。窗口中的元素实际存储在 Key/Value State 中，key为Window，value为元素集合（或聚合值）。为了保证窗口的容错性，该实现依赖了 Flink 的 State 机制（参见 state 文档）。 接着看其他方法，getDefaultTrigger用于返回该窗口默认的触发器，getWindowSerializer用于返回窗口的序列化器，isEventTime用于判断是否基于event time来进行元素的分配。 最后看一下WindowAssignerContext这个上下文容器，其是一个内部静态抽象类，提供了getCurrentProcessingTime方法用于获取当前的processing time。 看一下WindowAssigner的实现类，GlobalWindows主要用于实现CountWindow，MergingWindowAssigner主要用于实现SessionWindow，剩下的分别基于processing time和event time实现了翻滚窗口和滑动窗口。 先捡软柿子捏，首先看较为简单的GlobalWindows： GlobalWindows12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class GlobalWindows extends WindowAssigner&lt;Object, GlobalWindow&gt; &#123; private static final long serialVersionUID = 1L; private GlobalWindows() &#123;&#125; @Override public Collection&lt;GlobalWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; return Collections.singletonList(GlobalWindow.get()); &#125; @Override public Trigger&lt;Object, GlobalWindow&gt; getDefaultTrigger(StreamExecutionEnvironment env) &#123; return new NeverTrigger(); &#125; @Override public String toString() &#123; return &quot;GlobalWindows()&quot;; &#125; public static GlobalWindows create() &#123; return new GlobalWindows(); &#125; @Internal public static class NeverTrigger extends Trigger&lt;Object, GlobalWindow&gt; &#123; private static final long serialVersionUID = 1L; @Override public TriggerResult onElement(Object element, long timestamp, GlobalWindow window, TriggerContext ctx) &#123; return TriggerResult.CONTINUE; &#125; @Override public TriggerResult onEventTime(long time, GlobalWindow window, TriggerContext ctx) &#123; return TriggerResult.CONTINUE; &#125; @Override public TriggerResult onProcessingTime(long time, GlobalWindow window, TriggerContext ctx) &#123; return TriggerResult.CONTINUE; &#125; @Override public void clear(GlobalWindow window, TriggerContext ctx) throws Exception &#123;&#125; @Override public void onMerge(GlobalWindow window, OnMergeContext ctx) &#123; &#125; &#125; @Override public TypeSerializer&lt;GlobalWindow&gt; getWindowSerializer(ExecutionConfig executionConfig) &#123; return new GlobalWindow.Serializer(); &#125; @Override public boolean isEventTime() &#123; return false; &#125;&#125; GlobalWindows提供了create静态方法用于返回GlobalWindows实例，assignWindows方法会将上游的元素全都分配到一个单例GlobalWindow中，其默认的Trigger为NeverTrigger，即永不触发fire计算。 TumblingProcessingTimeWindows和TumblingEventTimeWindowsTumblingProcessingTimeWindows和TumblingEventTimeWindows的assignWindows方法： 123456789101112131415161718192021222324// TumblingProcessingTimeWindows@Overridepublic Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; // 获取当前的processing time final long now = context.getCurrentProcessingTime(); // 计算当前processing time所属窗口的start long start = TimeWindow.getWindowStartWithOffset(now, offset, size); return Collections.singletonList(new TimeWindow(start, start + size));&#125;// TumblingEventTimeWindows@Overridepublic Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; if (timestamp &gt; Long.MIN_VALUE) &#123; // Long.MIN_VALUE is currently assigned when no timestamp is present // 以元素自带的时间戳(event time)计算窗口的start long start = TimeWindow.getWindowStartWithOffset(timestamp, offset, size); return Collections.singletonList(new TimeWindow(start, start + size)); &#125; else &#123; throw new RuntimeException(&quot;Record has Long.MIN_VALUE timestamp (= no timestamp marker). &quot; + &quot;Is the time characteristic set to &apos;ProcessingTime&apos;, or did you forget to call &quot; + &quot;&apos;DataStream.assignTimestampsAndWatermarks(...)&apos;?&quot;); &#125;&#125; 可以看到，其逻辑是相似的，区别就在于窗口的start时间，一个使用的是WindowAssignerContext获取的当前时间戳，另外一个则是利用元素的EventTime，通过TimeWindow的getWindowStartWithOffset方法计算得到的。 SlidingProcessingTimeWindows和SlidingEventTimeWindows接着看滑动窗口，以SlidingProcessingTimeWindows为例： 123456789101112131415@Overridepublic Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; // 获取当前系统的Processing Time timestamp = context.getCurrentProcessingTime(); // 初始化窗口集合，窗口个数为size/slide List&lt;TimeWindow&gt; windows = new ArrayList&lt;&gt;((int) (size / slide)); long lastStart = TimeWindow.getWindowStartWithOffset(timestamp, offset, slide); // 计算窗口集合 for (long start = lastStart; start &gt; timestamp - size; start -= slide) &#123; windows.add(new TimeWindow(start, start + size)); &#125; return windows;&#125; 上述代码可能不够直观，我们以一个简单例子来解释上述方法。 假设基础数据如下： 1234timestamp=73;offset=6;size=60;slide=10; 计算过程： 1234567891011121314集合的大小为：60/10=6上一次起始起始时间:lastStart=timestamp-(timestamp-offset+slide)%slide=73-(73-6+10)%10=73-7=66则for(start=66; start&gt;73-60; start=start-10)&#123; windows.add(new TimeWindow(start, start + size));&#125;windows集合为：[66, 126][56, 116][46, 106][36, 96][26, 86][16, 76] SlidingEventTimeWindows与SlidingProcessingTimeWindows的assignWindows基本一致，只是额外添加了一层对timestamp的判断，只有当timestamp &gt; Long.MIN_VALUE才会进入到窗口分配，否则抛异常。 1234567891011121314151617@Overridepublic Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; if (timestamp &gt; Long.MIN_VALUE) &#123; List&lt;TimeWindow&gt; windows = new ArrayList&lt;&gt;((int) (size / slide)); long lastStart = TimeWindow.getWindowStartWithOffset(timestamp, offset, slide); for (long start = lastStart; start &gt; timestamp - size; start -= slide) &#123; windows.add(new TimeWindow(start, start + size)); &#125; return windows; &#125; else &#123; throw new RuntimeException(&quot;Record has Long.MIN_VALUE timestamp (= no timestamp marker). &quot; + &quot;Is the time characteristic set to &apos;ProcessingTime&apos;, or did you forget to call &quot; + &quot;&apos;DataStream.assignTimestampsAndWatermarks(...)&apos;?&quot;); &#125;&#125; MergingWindowAssigner12345678910public abstract class MergingWindowAssigner&lt;T, W extends Window&gt; extends WindowAssigner&lt;T, W&gt; &#123; private static final long serialVersionUID = 1L; public abstract void mergeWindows(Collection&lt;W&gt; windows, MergeCallback&lt;W&gt; callback); public interface MergeCallback&lt;W&gt; &#123; void merge(Collection&lt;W&gt; toBeMerged, W mergeResult); &#125;&#125; MergingWindowAssigner主要提供了MergeCallback抽象接口，然后将该接口传递给TimeWindow的mergeWindows方法来进行窗口的合并(具体可看TimeWindow)。 123public static void mergeWindows(Collection&lt;TimeWindow&gt; windows, MergingWindowAssigner.MergeCallback&lt;TimeWindow&gt; c) &#123; ......&#125; Trigger触发器。决定了一个窗口何时能够被计算或清除，每个窗口都会拥有一个自己的Trigger。 123456789101112131415161718192021222324252627282930313233343536373839public abstract class Trigger&lt;T, W extends Window&gt; implements Serializable &#123; private static final long serialVersionUID = -4104633972991191369L; public abstract TriggerResult onElement(T element, long timestamp, W window, TriggerContext ctx) throws Exception; public abstract TriggerResult onProcessingTime(long time, W window, TriggerContext ctx) throws Exception; public abstract TriggerResult onEventTime(long time, W window, TriggerContext ctx) throws Exception; public boolean canMerge() &#123; return false; &#125; public void onMerge(W window, OnMergeContext ctx) throws Exception &#123; throw new UnsupportedOperationException(&quot;This trigger does not support merging.&quot;); &#125; public abstract void clear(W window, TriggerContext ctx) throws Exception; public interface TriggerContext &#123; long getCurrentProcessingTime(); MetricGroup getMetricGroup(); long getCurrentWatermark(); void registerProcessingTimeTimer(long time); void registerEventTimeTimer(long time); void deleteProcessingTimeTimer(long time); void deleteEventTimeTimer(long time); &lt;S extends State&gt; S getPartitionedState(StateDescriptor&lt;S, ?&gt; stateDescriptor); @Deprecated &lt;S extends Serializable&gt; ValueState&lt;S&gt; getKeyValueState(String name, Class&lt;S&gt; stateType, S defaultState); @Deprecated &lt;S extends Serializable&gt; ValueState&lt;S&gt; getKeyValueState(String name, TypeInformation&lt;S&gt; stateType, S defaultState); &#125; public interface OnMergeContext extends TriggerContext &#123; &lt;S extends MergingState&lt;?, ?&gt;&gt; void mergePartitionedState(StateDescriptor&lt;S, ?&gt; stateDescriptor); &#125;&#125; 当元素加入窗口时，onElement方法被调用，主要完成定时器的注册，当基于processing time的timer被触发后，onProcessingTime方法被调用，同样的，当基于event time的timer被触发后，onEventTime方法被调用。 其实现类有以下几种： 常用的主要有CountTrigger、EventTimeTrigger、ProcessingTimeTrigger，下面分别看看这几个触发器。 CountTrigger1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class CountTrigger&lt;W extends Window&gt; extends Trigger&lt;Object, W&gt; &#123; private static final long serialVersionUID = 1L; // 当窗口中的元素&gt;=maxCount时，窗口操作将被触发 private final long maxCount; // 声明count的ReducingStateDescriptor，相当于一个分布式环境下的共享变量，主要记录当前窗口中元素的数量 private final ReducingStateDescriptor&lt;Long&gt; stateDesc = new ReducingStateDescriptor&lt;&gt;(&quot;count&quot;, new Sum(), LongSerializer.INSTANCE); private CountTrigger(long maxCount) &#123; this.maxCount = maxCount; &#125; @Override public TriggerResult onElement(Object element, long timestamp, W window, TriggerContext ctx) throws Exception &#123; // 获取窗口中的元素的数量 ReducingState&lt;Long&gt; count = ctx.getPartitionedState(stateDesc); // 执行+1操作 count.add(1L); // 若count值&gt;=maxCount，则窗口执行fire操作，否则continue if (count.get() &gt;= maxCount) &#123; count.clear(); return TriggerResult.FIRE; &#125; return TriggerResult.CONTINUE; &#125; @Override public TriggerResult onEventTime(long time, W window, TriggerContext ctx) &#123; return TriggerResult.CONTINUE; &#125; @Override public TriggerResult onProcessingTime(long time, W window, TriggerContext ctx) throws Exception &#123; return TriggerResult.CONTINUE; &#125; @Override public void clear(W window, TriggerContext ctx) throws Exception &#123; // 清空共享变量 ctx.getPartitionedState(stateDesc).clear(); &#125; @Override public boolean canMerge() &#123; return true; &#125; @Override public void onMerge(W window, OnMergeContext ctx) throws Exception &#123; // 当发生窗口merge时，合并共享变量 ctx.mergePartitionedState(stateDesc); &#125; @Override public String toString() &#123; return &quot;CountTrigger(&quot; + maxCount + &quot;)&quot;; &#125; // 提供of(long maxCount)方法返回CountTrigger的实例 public static &lt;W extends Window&gt; CountTrigger&lt;W&gt; of(long maxCount) &#123; return new CountTrigger&lt;&gt;(maxCount); &#125; private static class Sum implements ReduceFunction&lt;Long&gt; &#123; private static final long serialVersionUID = 1L; @Override public Long reduce(Long value1, Long value2) throws Exception &#123; return value1 + value2; &#125; &#125;&#125; ProcessingTimeTrigger当processing time超过窗口的end值时，窗口将执行fire操作： 123456789101112131415161718192021222324@Overridepublic TriggerResult onElement(Object element, long timestamp, TimeWindow window, TriggerContext ctx) &#123; // 注册processing time的时钟，相当于定了个闹钟，闹钟时间为window.maxTimestamp() ctx.registerProcessingTimeTimer(window.maxTimestamp()); return TriggerResult.CONTINUE;&#125;@Overridepublic TriggerResult onEventTime(long time, TimeWindow window, TriggerContext ctx) throws Exception &#123; // 不做处理 return TriggerResult.CONTINUE;&#125;@Overridepublic TriggerResult onProcessingTime(long time, TimeWindow window, TriggerContext ctx) &#123; // 当闹钟定的时间到了，执行fire操作 return TriggerResult.FIRE;&#125;@Overridepublic void clear(TimeWindow window, TriggerContext ctx) throws Exception &#123; // 清除时钟 ctx.deleteProcessingTimeTimer(window.maxTimestamp());&#125; 可以看到，onElement方法主要用于注册时钟，时钟时间到达后(onProcessingTime)，会触发窗口的fire操作。 EventTimeTriggerEventTimeTrigger与ProcessingTimeTrigger类似： 123456789101112131415161718192021222324252627@Overridepublic TriggerResult onElement(Object element, long timestamp, TimeWindow window, TriggerContext ctx) throws Exception &#123; if (window.maxTimestamp() &lt;= ctx.getCurrentWatermark()) &#123; // if the watermark is already past the window fire immediately return TriggerResult.FIRE; &#125; else &#123; ctx.registerEventTimeTimer(window.maxTimestamp()); return TriggerResult.CONTINUE; &#125;&#125;@Overridepublic TriggerResult onEventTime(long time, TimeWindow window, TriggerContext ctx) &#123; return time == window.maxTimestamp() ? TriggerResult.FIRE : TriggerResult.CONTINUE;&#125;@Overridepublic TriggerResult onProcessingTime(long time, TimeWindow window, TriggerContext ctx) throws Exception &#123; return TriggerResult.CONTINUE;&#125;@Overridepublic void clear(TimeWindow window, TriggerContext ctx) throws Exception &#123; ctx.deleteEventTimeTimer(window.maxTimestamp());&#125; onElement方法会检查当前窗口的最大时间戳是否大于水印，若大于水印，则直接触发窗口的fire操作，若小于水印，则注册EventTime的时钟，当水印时间到达时钟设定值时，会触发窗口的fire操作。 最后，我们看一个很有用的Trigger工具类—PurgingTrigger。 PurgingTrigger首先看PurgingTrigger的构造器： 123private PurgingTrigger(Trigger&lt;T, W&gt; nestedTrigger) &#123; this.nestedTrigger = nestedTrigger;&#125; PurgingTrigger会将传入的nestedTrigger进行”二次处理”，当nestedTrigger执行fire操作时，PurgingTrigger会将其转换为fire+purge操作。 1234567891011121314151617@Overridepublic TriggerResult onElement(T element, long timestamp, W window, TriggerContext ctx) throws Exception &#123; TriggerResult triggerResult = nestedTrigger.onElement(element, timestamp, window, ctx); return triggerResult.isFire() ? TriggerResult.FIRE_AND_PURGE : triggerResult;&#125;@Overridepublic TriggerResult onEventTime(long time, W window, TriggerContext ctx) throws Exception &#123; TriggerResult triggerResult = nestedTrigger.onEventTime(time, window, ctx); return triggerResult.isFire() ? TriggerResult.FIRE_AND_PURGE : triggerResult;&#125;@Overridepublic TriggerResult onProcessingTime(long time, W window, TriggerContext ctx) throws Exception &#123; TriggerResult triggerResult = nestedTrigger.onProcessingTime(time, window, ctx); return triggerResult.isFire() ? TriggerResult.FIRE_AND_PURGE : triggerResult;&#125; 典型的修饰器模式。 KeyedStream的countWindow(long size)直接应用了PurgingTrigger工具类。 123public WindowedStream&lt;T, KEY, GlobalWindow&gt; countWindow(long size) &#123; return window(GlobalWindows.create()).trigger(PurgingTrigger.of(CountTrigger.of(size)));&#125; Evictor可以译为“驱逐者”。在Trigger触发之后，在窗口被处理前/后，Evictor（如果有Evictor的话）会用来剔除窗口中不需要的元素，相当于一个filter。 123456789101112131415public interface Evictor&lt;T, W extends Window&gt; extends Serializable &#123; void evictBefore(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, W window, EvictorContext evictorContext); void evictAfter(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, W window, EvictorContext evictorContext); interface EvictorContext &#123; long getCurrentProcessingTime(); MetricGroup getMetricGroup(); long getCurrentWatermark(); &#125;&#125; 其主要有如下实现类： CountEvictor1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class CountEvictor&lt;W extends Window&gt; implements Evictor&lt;Object, W&gt; &#123; private static final long serialVersionUID = 1L; // 窗口的最大元素数量 private final long maxCount; // 是否在计算后驱逐元素 private final boolean doEvictAfter; private CountEvictor(long count, boolean doEvictAfter) &#123; this.maxCount = count; this.doEvictAfter = doEvictAfter; &#125; private CountEvictor(long count) &#123; this.maxCount = count; // 默认在计算前执行Evictor操作 this.doEvictAfter = false; &#125; @Override public void evictBefore(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, W window, EvictorContext ctx) &#123; // 若doEvictAfter为false if (!doEvictAfter) &#123; evict(elements, size, ctx); &#125; &#125; @Override public void evictAfter(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, W window, EvictorContext ctx) &#123; // 若doEvictAfter为true if (doEvictAfter) &#123; evict(elements, size, ctx); &#125; &#125; private void evict(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, EvictorContext ctx) &#123; if (size &lt;= maxCount) &#123; return; &#125; else &#123; int evictedCount = 0; // Iterator&lt;TimestampedValue&lt;Object&gt;&gt; iterator是按照元素到达时间排序的有序迭代器，第1个元素为时间最old的 for (Iterator&lt;TimestampedValue&lt;Object&gt;&gt; iterator = elements.iterator(); iterator.hasNext();)&#123; iterator.next(); evictedCount++; if (evictedCount &gt; size - maxCount) &#123; break; &#125; else &#123; // 将多余的元素剔除 iterator.remove(); &#125; &#125; &#125; &#125; /** * Creates a &#123;@code CountEvictor&#125; that keeps the given number of elements. * Eviction is done before the window function. * * @param maxCount The number of elements to keep in the pane. */ public static &lt;W extends Window&gt; CountEvictor&lt;W&gt; of(long maxCount) &#123; return new CountEvictor&lt;&gt;(maxCount); &#125; public static &lt;W extends Window&gt; CountEvictor&lt;W&gt; of(long maxCount, boolean doEvictAfter) &#123; return new CountEvictor&lt;&gt;(maxCount, doEvictAfter); &#125;&#125; KeyedStream的countWindow(long size, long slide)方法应用CountEvictor实现了滑动窗口。 12345public WindowedStream&lt;T, KEY, GlobalWindow&gt; countWindow(long size, long slide) &#123; return window(GlobalWindows.create()) .evictor(CountEvictor.of(size)) .trigger(CountTrigger.of(slide));&#125; TimeEvictorTimeEvictor与CountEvictor类似，TimeEvictor基于时间驱动，故其windowSize参数对应CountEvictor的maxCount，均表征窗口的大小，重点看一下evict方法： 1234567891011121314151617private void evict(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, EvictorContext ctx) &#123; if (!hasTimestamp(elements)) &#123; return; &#125; // 获取所有元素时间戳的最大值 long currentTime = getMaxTimestamp(elements); // 获取evict分割线 long evictCutoff = currentTime - windowSize; for (Iterator&lt;TimestampedValue&lt;Object&gt;&gt; iterator = elements.iterator(); iterator.hasNext(); ) &#123; TimestampedValue&lt;Object&gt; record = iterator.next(); // 若元素的时间戳不大于evict分割线，执行删除操作 if (record.getTimestamp() &lt;= evictCutoff) &#123; iterator.remove(); &#125; &#125;&#125; DeltaEvictor12345678910111213141516171819202122232425public class DeltaEvictor&lt;T, W extends Window&gt; implements Evictor&lt;T, W&gt; &#123; private static final long serialVersionUID = 1L; // 求两元素间距离的函数 DeltaFunction&lt;T&gt; deltaFunction; // 阈值 private double threshold; private final boolean doEvictAfter; ...... private void evict(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, EvictorContext ctx) &#123; // 获取最新的元素 TimestampedValue&lt;T&gt; lastElement = Iterables.getLast(elements); for (Iterator&lt;TimestampedValue&lt;T&gt;&gt; iterator = elements.iterator(); iterator.hasNext();)&#123; TimestampedValue&lt;T&gt; element = iterator.next(); // 若当前元素与最新元素之间的距离超过阈值，则删除该元素 if (deltaFunction.getDelta(element.getValue(), lastElement.getValue()) &gt;= this.threshold) &#123; iterator.remove(); &#125; &#125; &#125; ...... &#125; 由上述代码易知，基于DeltaEvictor可以实现CountEvictor和TimeEvictor，只要实现各自的DeltaFunction即可，所以DeltaEvictor更具有一般性。 开源推荐在学习Flink的过程中，本人将涉及到的测试案例、源码解读、开发技巧等系统整理了一下，并开源到Github上，地址为： https://github.com/Ruanshubin/awesome-flink 欢迎大家Star支持！]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink的Window初探]]></title>
    <url>%2F2019%2F08%2F15%2FFlink%E7%9A%84Window%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[Flink 认为 Batch 是 Streaming 的一个特例，所以 Flink 底层引擎是一个流式引擎，在上面实现了流处理和批处理。而窗口（window）就是从 Streaming 到 Batch 的一个桥梁。 引言在流处理应用中，数据是连续不断的，因此我们不可能等到所有数据都到了才开始处理。当然我们可以每来一个消息就处理一次，但是有时我们需要做一些聚合类的处理。 基于窗口驱动方式可分为: 时间驱动的（Time Window，例如：每30秒钟） 数据驱动的（Count Window，例如：每一百个元素） 基于窗口处理方式可分为： 翻滚窗口（Tumbling Window，无重叠） 滚动窗口（Sliding Window，有重叠） 会话窗口（Session Window，活动间隙） 需要说明的是，Flink将Time分为3种: event time（事件时间：事件发生时的时间） ingestion time（摄取时间：事件进入流处理系统的时间） processing time（处理时间：消息被计算处理的时间） Count WindowCount Window 是根据元素个数对数据流进行分组的。 Tumbling Count Window当我们想要每100个用户购买行为事件统计购买总数，那么每当窗口中填满100个元素了，就会对窗口进行计算，这种窗口我们称之为翻滚计数窗口（Tumbling Count Window），通过使用 DataStream API，我们可以这样实现： 12345678910// Stream of (userId, buyCnts)val buyCnts: DataStream[(Int, Int)] = ...val tumblingCnts: DataStream[(Int, Int)] = buyCnts // key stream by sensorId .keyBy(0) // tumbling count window of 100 elements size .countWindow(100) // compute the buyCnt sum .sum(1) Sliding Count WindowCount Window 也支持 Sliding Window，虽在上图中未描述出来，但和Sliding Time Window含义是类似的，例如计算每10个元素计算一次最近100个元素的总和，代码示例如下: 12345val slidingCnts: DataStream[(Int, Int)] = vehicleCnts .keyBy(0) // sliding count window of 100 elements size and 10 elements trigger interval .countWindow(100, 10) .sum(1) Time WindowTumbling Time Window统计每一分钟中用户购买的商品的总数，需要将用户的行为事件按每一分钟进行切分，这种切分被成为翻滚时间窗口（Tumbling Time Window）。 翻滚窗口能将数据流切分成不重叠的窗口，每一个事件只能属于一个窗口。通过使用DataStream API，可以这样实现： 12345678910// Stream of (userId, buyCnt)val buyCnts: DataStream[(Int, Int)] = ...val tumblingCnts: DataStream[(Int, Int)] = buyCnts // key stream by userId .keyBy(0) // tumbling time window of 1 minute length .timeWindow(Time.minutes(1)) // compute sum over buyCnt .sum(1) Sliding Time Window对于某些应用，它们需要的窗口是不间断的，需要平滑地进行窗口聚合。比如，我们可以每30秒计算一次最近一分钟用户购买的商品总数。这种窗口我们称为滑动时间窗口（Sliding Time Window）。在滑窗中，一个元素可以对应多个窗口。通过使用 DataStream API，我们可以这样实现： 12345val slidingCnts: DataStream[(Int, Int)] = buyCnts .keyBy(0) // sliding time window of 1 minute length and 30 secs trigger interval .timeWindow(Time.minutes(1), Time.seconds(30)) .sum(1) Session Window在这种用户交互事件流中，我们首先想到的是将事件聚合到会话窗口中（一段用户持续活跃的周期），由非活跃的间隙分隔开。如上图所示，就是需要计算每个用户在活跃期间总共购买的商品数量，如果用户30秒没有活动则视为会话断开（假设raw data stream是单个用户的购买行为流）。Session Window 的示例代码如下： 12345678// Stream of (userId, buyCnts)val buyCnts: DataStream[(Int, Int)] = ... val sessionCnts: DataStream[(Int, Int)] = vehicleCnts .keyBy(0) // session window based on a 30 seconds session gap interval .window(ProcessingTimeSessionWindows.withGap(Time.seconds(30))) .sum(1) session 是指一段持续活跃的期间，由活跃间隙分隔开。通俗一点说，消息之间的间隔小于超时阈值（sessionGap）的，则被分配到同一个窗口，间隔大于阈值的，则被分配到不同的窗口。 目前开源领域大部分的流计算引擎都有窗口的概念，但是没有对 session window 的支持，要实现 session window，需要用户自己去做完大部分事情。而当 Flink 1.1.0 版本正式发布时，Flink 将会是开源流计算领域第一个内建支持 session window 的引擎。 在 Flink 1.1.0 之前，Flink 也可以通过自定义的window assigner和trigger来实现一个基本能用的session window。 基于GlobleWindow这个window assigner，将所有元素都分配到同一个窗口中，然后指定一个自定义的trigger来触发执行窗口。这个trigger的触发机制是，对于每个到达的元素都会根据其时间戳（timestamp）注册一个会话超时的定时器（timestamp+sessionTimeout），并移除上一次注册的定时器。最新一个元素到达后，如果超过 sessionTimeout 的时间还没有新元素到达，那么trigger就会触发，当前窗口就会是一个session window。处理完窗口后，窗口中的数据会清空，用来缓存下一个session window的数据。 但是这种session window的实现是非常弱的，无法应用到实际生产环境中的。因为它无法处理乱序 event time 的消息。 Flink 1.1.0 版本中，Flink提供了对session window的直接支持，用户可以通过SessionWindows.withGap()来轻松地定义session widnow，而且能够处理乱序消息。Flink对session window的支持主要借鉴自Google的DataFlow。 Window APIWindow Assigner用来决定某个元素被分配到哪个/哪些窗口中去。 Window本身只是一个ID标识符，其内部可能存储了一些元数据，如TimeWindow中有开始和结束时间，但是并不会存储窗口中的元素。窗口中的元素实际存储在 Key/Value State 中，key为Window，value为元素集合（或聚合值）。为了保证窗口的容错性，该实现依赖了 Flink 的 State 机制（参见 state 文档）。 Trigger触发器。决定了一个窗口何时能够被计算或清除，每个窗口都会拥有一个自己的Trigger。 Trigger的返回结果可以是 continue（不做任何操作），fire（处理窗口数据），purge（移除窗口和窗口中的数据），或者 fire + purge。一个Trigger的调用结果只是fire的话，那么会计算窗口并保留窗口原样，也就是说窗口中的数据仍然保留不变，等待下次Trigger fire的时候再次执行计算。一个窗口可以被重复计算多次知道它被 purge 了。在purge之前，窗口会一直占用着内存。 Evictor可以译为“驱逐者”。在Trigger触发之后，在窗口被处理之前，Evictor（如果有Evictor的话）会用来剔除窗口中不需要的元素，相当于一个filter。 当Trigger fire了，窗口中的元素集合就会交给Evictor（如果指定了的话）。Evictor 主要用来遍历窗口中的元素列表，并决定最先进入窗口的多少个元素需要被移除。剩余的元素会交给用户指定的函数进行窗口的计算。如果没有 Evictor 的话，窗口中的所有元素会一起交给函数进行计算。 上述三个组件的不同实现的不同组合，可以定义出非常复杂的窗口。Flink 中内置的窗口也都是基于这三个组件构成的，当然内置窗口有时候无法解决用户特殊的需求，所以 Flink 也暴露了这些窗口机制的内部接口供用户实现自定义的窗口。 在后面的章节里，我们会从源码剖析Flink的Window机制。 开源推荐在学习Flink的过程中，本人将涉及到的测试案例、源码解读、开发技巧等系统整理了一下，并开源到Github上，地址为： https://github.com/Ruanshubin/awesome-flink 欢迎大家Star支持！]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark从入门到放弃--3RDD和共享变量]]></title>
    <url>%2F2019%2F06%2F14%2FSpark%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83--3RDD%E5%92%8C%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[为进行分布式环境下数据资源的描述，Spark引入了2类抽象概念： 第1个抽象概念是RDD。 RDD基本介绍RDD全称为Resilient Distributed Dataset，即弹性分布式数据集，设计理念源自AMP实验室发表的论文《Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing》。 RDDs是跨集群节点分区的元素集合，可以执行并行操作。 RDDs可以读取HDFS中的文件进行创建，或者由Driver程序的已有Scala集合进行转化后创建。用户可以将RDDs持久存储在内存中，以便在并行操作中复用。 RDD操作一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可以分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算。RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，不能直接修改，只能基于稳定的物理存储中的数据集来创建RDD，或者通过在其他RDD上执行确定的转换操作（如map、join和groupBy）而创建得到新的RDD。 RDD提供了一组丰富的操作以支持常见的数据运算，分为Action和Transformation两种类型。 Action操作 用于执行计算并指定输出的形式，行动操作（比如count、collect等）接受RDD但是返回非RDD（即输出一个值或结果）。 Transformation操作 指定RDD之间的相互依赖关系，转换操作（比如map、filter、groupBy、join等）接受RDD并返回RDD。 RDD提供的转换接口都非常简单，都是类似map、filter、groupBy、join等粗粒度的数据转换操作，而不是针对某个数据项的细粒度修改。因此，RDD比较适合对于数据集中元素执行相同操作的批处理式应用，而不适合用于需要异步、细粒度状态的应用，比如Web应用系统、增量式的网页爬虫等。正因为这样，这种粗粒度转换接口设计，会使人直觉上认为RDD的功能很受限、不够强大。但是，实际上RDD已经被实践证明可以很好地应用于许多并行计算应用中，可以具备很多现有计算框架（比如MapReduce、SQL、Pregel等）的表达能力，并且可以应用于这些框架处理不了的交互式数据挖掘应用。 懒执行及DAGRDD采用了懒执行策略，即在RDD的执行过程中，真正的计算发生在RDD的Action操作，对于Action之前的所有Transformation操作，Spark只是记录下Transformation操作应用的一些基础数据集以及RDD生成的轨迹，即相互之间的依赖关系，而不会触发真正的计算。 如上图，从输入中逻辑上生成A和C两个RDD，经过一系列Transformation操作，逻辑上生成了F（也是一个RDD），之所以说是逻辑上，是因为这时候计算并没有发生，Spark只是记录了RDD之间的生成和依赖关系。当F要进行输出时，也就是当F进行Action操作的时候，Spark才会根据RDD的依赖关系生成DAG，并从起点开始真正的计算。 上述这一系列处理称为一个“血缘关系（Lineage）”，即DAG拓扑排序的结果。采用惰性调用，通过血缘关系连接起来的一系列RDD操作就可以实现管道化（pipeline），避免了多次转换操作之间数据同步的等待，而且不用担心有过多的中间数据，因为这些具有血缘关系的操作都管道化了，一个操作得到的结果不需要保存为中间数据，而是直接管道式地流入到下一个操作进行处理。同时，这种通过血缘关系把一系列操作进行管道化连接的设计方式，也使得管道中每次操作的计算变得相对简单，保证了每个操作在处理逻辑上的单一性；相反，在MapReduce的设计中，为了尽可能地减少MapReduce过程，在单个MapReduce中会写入过多复杂的逻辑。 RDD依赖RDD中不同的操作会使得不同RDD中的分区会产生不同的依赖。RDD中的依赖关系分为窄依赖（Narrow Dependency）与宽依赖（Wide Dependency）。 其实宽、窄依赖的区分非常简单： 若每个父RDD分区仅流向1个子RDD分区，则为窄依赖； 若每个父RDD分区流向多个子RDD分区，则为宽依赖。 对于窄依赖的RDD，可以以流水线的方式计算所有父分区，不会造成网络之间的数据混合。对于宽依赖的RDD，则通常伴随着Shuffle操作，即首先需要计算好所有父分区数据，然后在节点之间进行Shuffle。 Stage划分Spark通过分析各个RDD的依赖关系生成了DAG，再通过分析各个RDD中的分区之间的依赖关系来决定如何划分Stage(阶段)。 具体划分方法是： 在DAG中进行反向解析，遇到宽依赖就断开，遇到窄依赖就把当前的RDD加入到当前的Stage中； 将窄依赖尽量划分在同一个Stage中，可以实现流水线计算。 假设从HDFS中读入数据生成3个不同的RDD（即A、C和E），通过一系列转换操作后再将计算结果保存回HDFS。对DAG进行解析时，在依赖图中进行反向解析，由于从RDD A到RDD B的转换以及从RDD B和F到RDD G的转换，都属于宽依赖，因此，在宽依赖处断开后可以得到三个阶段，即阶段1、阶段2和阶段3。可以看出，在阶段2中，从map到union都是窄依赖，这两步操作可以形成一个流水线操作，比如，分区7通过map操作生成的分区9，可以不用等待分区8到分区9这个转换操作的计算结束，而是继续进行union操作，转换得到分区13，这样流水线执行大大提高了计算的效率。 任务调度器Spark的任务调度器包括DAGScheduler和TaskScheduler。 DAGScheduler把一个Spark作业转换成Stage的DAG（Directed Acyclic Graph有向无环图），根据RDD和Stage之间的关系找出开销最小的调度方法，然后把Stage以TaskSet的形式提交给TaskScheduler。 DAGScheduler决定了运行Task的理想位置，并把这些信息传递给下层的TaskScheduler。此外，DAGScheduler还处理由于Shuffle数据丢失 导致的失败，这有可能需要重新提交运行之前的Stage（非Shuffle数据丢失导致的Task失败由TaskScheduler处理）。 TaskScheduler维护所有TaskSet，当Executor向Driver发送心跳时，TaskScheduler会根据其资源剩余情况分配 相应的Task。另外TaskScheduler还维护着所有Task的运行状态，重试失败的Task。 RDD运行 创建RDD对象； SparkContext负责计算RDD之间的依赖关系，构建DAG； DAGScheduler负责把DAG图分解成多个阶段，每个阶段中包含了多个任务，每个任务会被任务调度器分发给各个工作节点（Worker Node）上的Executor去执行。 Spark的第2抽象概念是共享变量。 共享变量默认情况下，Spark在不同节点的task上并行运行函数时，它会将函数使用的每个变量的副本发送给每个任务。 当需要在tasks之间，或者task与driver之间共享某个变量时，共享变量便登场了。 Spark支持2种类型的共享变量: 广播变量(broadcast variables) 其可以在所有节点的内存中缓存某个Value。 广播变量允许开发人员在每个节点（Worker or Executor）缓存只读变量，而不是在Task之间传递这些变量。使用广播变量能够高效地在集群每个节点创建大数据集的副本。同时Spark还使用高效的广播算法分发这些变量，从而减少通信的开销。 Spark应用程序Job的执行由一系列调度Stage(阶段)构成，而这些调度Stage通过Shuffle进行分隔。Spark能够在每个调度Stage自动广播任务所需通用的数据，这些数据在广播时需进行序列化缓存，并在任务运行前进行反序列化。这就意味着当多个调度Stage的任务需要相同的数据，显示地创建广播变量才有用。 计数器(accumulators) 仅用于执行变量的累加操作，如计数或求和。 Accumulator只提供了累加的功能，但是却给我们提供了多个task对一个变量并行操作的功能。task只能对Accumulator进行累加操作，不能读取它的值。只有Driver程序可以读取Accumulator的值。 累加器只能由Spark内部进行更新，并保证每个任务在累加器的更新操作仅执行一次，也就是说重启任务也不应该更新。在转换操作中，用户必须意识到任务和作业的调度过程重新执行会造成累加器的多次更新。 累加器同样具有Spark懒加载的求值模型。如果它们在RDD的操作中进行更新，它们的值只在RDD进行行动操作时才进行更新。 参考文献: http://spark.apache.org/docs/latest/rdd-programming-guide.html http://dblab.xmu.edu.cn/blog/985-2/ https://www.cnblogs.com/1130136248wlxk/articles/6289717.html https://blog.csdn.net/anbang713/article/details/81588829 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark从入门到放弃--2运行架构]]></title>
    <url>%2F2019%2F06%2F14%2FSpark%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83--2%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[术语表讲解Spark运行架构之前，我们先科普一下Spark集群的相关术语: 基本流程Spark应用运行在集群中的独立进程集中，并通过主进程(Driver)中的SparkContext对象进行进程间的控制协调，其运行架构如下图所示: Cluster Manager(CM)主要负责应用的资源管理，在集群上运行Spark应用时，先由Driver的SparkContext连接CM申请计算资源，然后在集群的Worker节点上启动相应的Exector进程，Executor运行情况将随着心跳发送到资源管理器上。 具体执行任务时，先由SparkContext构建成DAG图，将DAG图分解成Stage，并把Taskset发送给Task Scheduler。Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行同时SparkContext将应用程序代码发放给Executor。 Task在Executor上运行，运行完毕释放所有资源。 SparkContext可以连接不同种类的CM，比如Spark的Standalone、Yarn及Mesos等。 整个架构需要注意以下几点: 不同应用间的Exector是互相独立的，其task也是运行在不同的线程中，该种模式的优点是应用在调度端(每个Driver调度自己的tasks)和执行端(不同应用的tasks运行在不同JVMs中)均是相互独立的。 Spark与底层Cluster Manager类型无关，只要它能获取相应资源，启动Executor进程，并且Executor进程间可以相互通信即可。 Executor上有一个BlockManager存储模块，类似于键值存储系统（把内存和磁盘共同作为存储设备），在处理迭代计算任务时，不需要把中间结果写入到HDFS等文件系统，而是直接放在这个存储系统上，后续有需要时就可以直接读取；在交互式查询场景下，也可以把表提前缓存到这个存储系统上，提高读写IO性能。 任务采用了数据本地性和推测执行等优化机制。数据本地性是尽量将计算移到数据所在的节点上进行，即“计算向数据靠拢”，因为移动计算比移动数据所占的网络资源要少得多。而且，Spark采用了延时调度机制，可以在更大的程度上实现执行过程优化。比如，拥有数据的节点当前正被其他的任务占用，那么，在这种情况下是否需要将数据移动到其他的空闲节点呢？答案是不一定。因为，如果经过预测发现当前节点结束当前任务的时间要比移动数据的时间还要少，那么，调度就会等待，直到当前节点可用。 参考文献: http://spark.apache.org/docs/latest/cluster-overview.html http://dblab.xmu.edu.cn/blog/972-2/ 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark从入门到放弃--1概述]]></title>
    <url>%2F2019%2F06%2F13%2FSpark%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83--1%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[什么是Spark先甩出官网链接: http://spark.apache.org/ 通俗来讲，Spark是一个大数据计算框架。 其具有以下特性: 快速性 Spark在批数据和流数据处理上均具有高效地性能，其快速性主要依赖于DAG任务执行器、计算优化和内存执行引擎。 易用性 支持Java, Scala, Python, R, and SQL等语言，并提供了80多种常用算子，可以使你快速构建并行应用。 普适性 Spark提供了丰富的组件，主要包括SQL、DataFrames、MLlib、GraphX及Spark Streaming，适用于多种场景下的计算任务。 兼容性 Spark可运行在Hadoop(Yarn)、Apache Mesos、Kubernetes(K8s)、独立集群或者云服务器(集群)上，并且支持接入不同种类的数据源。 发展历程 Spark在2009年由Matei Zaharia在加州大学伯克利分校AMPLab开创。 2010年通过BSD许可协议开源发布。 2013年6月，该项目被捐赠给Apache软件基金会并切换许可协议至Apache2.0。 2014年2月，Spark成为Apache的顶级项目。 2014年11月，Databricks团队使用Spark刷新数据排序世界记录。 2014年5月底Spark1.0.0发布。 2014年9月Spark1.1.0发布。 2014年12月Spark1.2.0发布。 … 2016年1月4号Spark1.6.0发布。 … 2016年6月26号Spark2.0发布。 … 时至今日的2.4.3版本。 Spark作为Hadoop生态中重要的一员，其发展速度堪称恐怖，不过其作为一个完整的技术栈，在技术和环境的双重刺激下，得到如此多的关注也是有依据的。核心在于内存计算模型代替Hadoop生态的MapReduce离线计算模型，用更加丰富Transformation和Action算子来替代map,reduce两种算子。 使用Spark的另外一个好处是，Spark的社区比较活跃，且框架一直处于不断优化中，开发过程中若出现问题，方便寻找解决方案。 从Github上也可以看出，直至今日，Spark仍处于Commit高度活跃的状态。 主要组件 Spark Core 包含Spark的基本功能；尤其是定义RDD的API、操作以及这两者上的动作。其他Spark的库都是构建在RDD和Spark Core之上的。 Spark SQL 提供通过Apache Hive的SQL变体Hive查询语言（HiveQL）与Spark进行交互的API。每个数据库表被当做一个RDD，Spark SQL查询被转换为Spark操作。 Spark Streaming 对实时数据流进行处理和控制。Spark Streaming允许程序能够像普通RDD一样处理实时数据。 MLlib 一个常用机器学习算法库，算法被实现为对RDD的Spark操作。这个库包含可扩展的学习算法，比如分类、回归等需要对大量数据集进行迭代的操作。 GraphX 控制图、并行图操作和计算的一组算法和工具的集合。GraphX扩展了RDD API，包含控制图、创建子图、访问路径上所有顶点的操作。 参考文献: http://spark.apache.org/ https://www.cnblogs.com/qingyunzong/p/8886338.html https://hacpai.com/article/1499870999066 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-IOC的XML配置]]></title>
    <url>%2F2019%2F06%2F05%2FSpring-IOC%E7%9A%84XML%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[引言在Springboot编程实践中，我们偏向使用注解的方式进行Bean的注册和依赖注入等，但XML格式的容器信息管理方式仍是Spring提供的最为强大、支持最为全面的方式，本文对Spring-IOC的XML配置进行详细的讲解。 和BeanFactory和ApplicationContext的XML配置均采用统一的格式，在Spring2.0之前，这种格式由Spring提供的DTD规定，即在配置文件的头部，需要以下形式的DOCTYPE声明: 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-//SPRING//DTD BEAN//EN&quot;&quot;http://www.springframework.org/dtd/spring-beans.dtd&quot;&gt;&lt;beans&gt; ...&lt;/beans&gt; 从Spring 2.0版本之后，Spring在继续保持向前兼容的前提下，既可以继续使用DTD方式的 DOCTYPE进行配置文件格式的限定，又引入了基于XML Schema的文档声明： 123456789101112131415161718192021&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:util=&quot;http://www.springframework.org/schema/util&quot; xmlns:jee=&quot;http://www.springframework.org/schema/jee&quot; xmlns:lang=&quot;http://www.springframework.org/schema/lang&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-2.0.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-2.0.xsd http://www.springframework.org/schema/lang http://www.springframework.org/schema/lang/spring-lang-2.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.0.xsd&quot;&gt; ...&lt;/beans&gt; 是配置文件的顶层元素，其可以包含0或1个和多个以及或者 可以配置所有的全局行为，主要包括: default-lazy-init 取值true或false，默认值false，用来标志是否对所有的进行延迟初始化。 default-autowire 可以取值为no、byName、byType、constructor以及autodetect。默认值为 no ，如果使用自动绑定的话，用来标志全体bean使用哪一种默认绑定方式。 default-dependency-check 可以取值none、objects、simple以及all，默认值为none，即不做依赖检查。 default-init-method 如果所管辖的按照某种规则，都有同样名称的初始化方法的话，可以在这里统一指定这个初始化方法名，而不用在每一个上都重复单独指定。 default-destroy-method 与default-init-method相对应，如果所管辖的bean有按照某种规则使用了相同名称的对象销毁方法，可以通过这个属性统一指定。 、和 配置文件的描述信息。 通常情况下，可以根据模块功能或者层次关系，将配置信息分门别类地放到多个配置文件中。在想加载主要配置文件，并将主要配置文件所依赖的配置文件同时加载时，可以在这个主要的配置文件中通过元素对其所依赖的配置文件进行引用。比如，如果A.xml中的定义可能依赖B.xml中的某些定义，那么就可以在A.xml中使用将B.xml引入到A.xml，以类似于 的形式。 可以通过为某些起一些“外号”（别名），通常情况下是为了减少输入。比如，假设有个 ，它的名称为dataSourceForMasterDatabase ，你可以为其添加一个 ，像这样 。以后通过dataSourceForMasterDatabase或者 masterDataSource来引用这个都可以。 id属性 对象在容器里的标识，若未配置，则的id取类名的小驼峰。 除了使用id，也可以使用name来进行标识，它与id的区别是， name可以使用id不能使用的一些字符，比如/。而且还可以通过逗号、空格或者冒号分割指定多个name。name的作用跟使用为id指定多个别名基本相同： 1234&lt;bean id=&quot;person&quot; name=&quot;/china/person,/england/person&quot;/ class=&quot;com.ruanshubin.springboot.entity.Person&quot;&gt;等同于:&lt;alias name=&quot;person&quot; alias=&quot;/china/person&quot;/&gt;&lt;alias name=&quot;person&quot; alias=&quot;/england/person&quot;/&gt; class属性 每个注册到容器的对象都需要通过元素的class属性指定其类型。 依赖注入为了演示依赖注入，我们新建3个实体类，分别为主机、显示器和电脑。 1234567891011121314151617181920212223242526272829303132333435363738public class MainEngine &#123; // 名称 private String name; // 型号 private String type; // 花费 private Integer cost; ... 构造器及get/set方法 toString方法 &#125; public class Display &#123; // 名称 private String name; // 型号 private String type; // 花费 private Integer cost; ... 构造器及get/set方法 toString方法 &#125; public class Computer &#123; // 名称 private String name; // 主机 private MainEngine mainEngine; // 显示器 private Display display; ... 构造器及get/set方法 toString方法 &#125; 构造方法注入在resources目录下新建spring-beans.xml文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:util=&quot;http://www.springframework.org/schema/util&quot; xmlns:jee=&quot;http://www.springframework.org/schema/jee&quot; xmlns:lang=&quot;http://www.springframework.org/schema/lang&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-2.0.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-2.0.xsd http://www.springframework.org/schema/lang http://www.springframework.org/schema/lang/spring-lang-2.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.0.xsd&quot;&gt; &lt;bean id=&quot;display&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Display&quot;&gt; &lt;constructor-arg&gt; &lt;value&gt;惠普&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;V300&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;1000&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;constructor-arg&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot;&gt; &lt;constructor-arg&gt; &lt;value&gt;组装机1&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;ref bean=&quot;mainEngine&quot;&gt;&lt;/ref&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;ref bean=&quot;display&quot;&gt;&lt;/ref&gt; &lt;/constructor-arg&gt; &lt;/bean&gt;&lt;/beans&gt; 编写主函数: 1234567public class IocXmlTest &#123; public static void main(String[] args) &#123; XmlBeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;spring-beans.xml&quot;)); Computer computer = (Computer) beanFactory.getBean(&quot;computer&quot;); System.out.println(computer); &#125;&#125; 运行结果为: 1Computer&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; 可以发现，如果注入的属性为基本数据类型(及其包装类)、String等，则使用进行注入，若为Java对象，则使用的方式进行注入。 同时，上述的顺序要与Java类中属性的顺序要严格一致，否则会出现问题，如将mainEngine的配置修改为: 1234567891011&lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;constructor-arg&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 重新运行主类，结果为: 1Computer&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;T600&apos;, type=&apos;戴尔&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; 可以发现，主机的名称和型号互换，造成异常。 此时，可以添加index标签，其表征了属性的顺序编号，从0开始。 1234567891011&lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;constructor-arg index=&quot;1&quot;&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg index=&quot;0&quot;&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 还有type标签，用于各属性类型不同时配置： 123456789101112&lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;!--不添加type标签会报错--&gt; &lt;constructor-arg type=&quot;Integer&quot;&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 最强大的是name标签，不管的顺序是否与实体类各属性的顺序是否一致，只要保证name一致即可安全注入，如将mainEngine的配置修改为: 1234567891011&lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;constructor-arg name=&quot;cost&quot;&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;type&quot;&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;name&quot;&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 虽然的顺序与实体类的属性顺序完全相反，但是通过name一对一绑定，运行结果仍旧为: 1Computer&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; setter方法注入setter方法使用完成依赖注入，如: 12345&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;组装机1&quot;/&gt; &lt;property name=&quot;mainEngine&quot; ref=&quot;mainEngine&quot;/&gt; &lt;property name=&quot;display&quot; ref=&quot;display&quot;/&gt;&lt;/bean&gt; 需要指出的是，除了value和ref标签，Spring还提供了bean、idref、value、null、list、set、map、props。 具体使用场景，本文不做过多介绍，大家可自行Google。 自动注入autowire除了可以通过配置明确指定bean之间的依赖关系，Spirng还提供了根据bean定义的某些特点将相互依赖的某些bean直接自动绑定的功能。通过 的autowire属性，可以指定当前bean定义采用某种类型的自动绑定模式。这样，你就无需手工明确指定该bean定义相关的依赖关系，从而也可以免去一些手工输入的工作量。 Spring提供了5种自动绑定模式，即 no、byName、byType、constructor和autodetect。 no 默认配置，即不采取自动注入，仅依靠手工配置注入。 byName 按照类中声明的实例变量的名称，与XML配置文件中声明的bean定义的beanName的值进行匹配，相匹配的bean定义将被自动绑定到当前实例变量上。 如我们将上面的computer的注入配置修改为: 12&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot; autowire=&quot;byName&quot;&gt;&lt;/bean&gt; 运行结果为: 1Computer&#123;name=&apos;null&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; 程序会自动寻找id为mainEngine、display的bean来完成注入，因为没有id为name的，所以不能自动注入，该项为null。 可以修改配置，添加无法自动注入的属性: 123&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot; autowire=&quot;byName&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;组装机1&quot;/&gt;&lt;/bean&gt; 此时，再次运行: 1Computer&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; byType 与byName类似，byType是按照类中声明的实例变量的Type，与XML配置文件中声明的bean的Type进行匹配，相匹配的bean定义将被自动绑定到当前实例变量上。 如我们将上面的computer的注入配置修改为: 123&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot; autowire=&quot;byType&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;组装机1&quot;/&gt;&lt;/bean&gt; 运行: 1Computer&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;&#125; 此处有个问题，当某个实例变量的Type在Spring容器中存在两个，会选择哪个进行注入呢? 假设在上述spring-beans.xml文件中添加如下配置: 1234567891011&lt;bean id=&quot;mainEngine1&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot;&gt; &lt;constructor-arg name=&quot;cost&quot;&gt; &lt;value&gt;3000&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;type&quot;&gt; &lt;value&gt;X900&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;name&quot;&gt; &lt;value&gt;神州&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 此时，Spring容器里存在2个主机实例，我们仍旧通过byType进行自动注入。 运行主函数: 12Exception in thread &quot;main&quot; org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;computer&apos; defined in class path resource [spring-beans.xml]: Unsatisfied dependency expressed through bean property &apos;mainEngine&apos;; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type &apos;com.ruanshubin.springboot.ioc.entity.MainEngine&apos; available: expected single matching bean but found 2: mainEngine,mainEngine1... 很明显，Spring不会帮你做这个决策，当同一个Type存在多个实例时，程序直接会将错误抛出来，由你来做决策。 constructor constructor类型则是针对构造方法参数的类型而进行的自动绑定，它同样是byType类型的绑定模式。不过，constructor是匹配构造方法的参数类型，而不是实例属性的类型。与byType模式类似，如果找到不止一个符合条件的bean定义，那么，容器会返回错误。 autodetect 是byType和constructor模式的结合体，如果对象拥有默认无参数的构造方法，容器会优先考虑byType的自动绑定模式。否则，会使用constructor模式。当然，如果通过构造方法注入绑定后还有其他属性没有绑定，容器也会使用byType对剩余的对象属性进行自动绑定。 依赖检查及继承依赖检查检查依赖是否按照预期绑定完成，其由dependency-check标签进行约束，存在以下4种模式: none 不做依赖检查 simple 容器会对简单属性类型以及相关的collection进行依赖检查，对象引用类型的依赖除外。 object 只对对象引用类型依赖进行检查。 all simple和object的结合体。 继承新建服务器类，继承自计算机类: 12345678910111213141516171819202122public class Server extends Computer&#123; // 名称 private String name; // 主机 private MainEngine mainEngine; // 显示器 private Display display; // GPU型号 private String gpuType; public Server() &#123; &#125; public Server(String name, MainEngine mainEngine, Display display, String gpuType) &#123; super(name, mainEngine, display); this.gpuType = gpuType; &#125; ... get/set方法 toString方法 &#125; 在spring-beans.xml配置文件中增加如下内容: 123&lt;bean id=&quot;server&quot; parent=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Server&quot;&gt; &lt;property name=&quot;gpuType&quot; value=&quot;TC800&quot;/&gt;&lt;/bean&gt; 修改启动类: 1234567public class IocXmlTest &#123; public static void main(String[] args) &#123; XmlBeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;spring-beans.xml&quot;)); Server server = beanFactory.getBean(&quot;server&quot;, Server.class); System.out.println(server); &#125;&#125; 运行结果为: 1Server&#123;name=&apos;组装机1&apos;, mainEngine=MainEngine&#123;name=&apos;戴尔&apos;, type=&apos;T600&apos;, cost=3600&#125;, display=Display&#123;name=&apos;惠普&apos;, type=&apos;V300&apos;, cost=1000&#125;, gpuType=&apos;TC800&apos;&#125; 可以看到，我们通过parent标签完成了Bean继承的管理。 Bean的scopeSpring2.0前，Bean容器仅有2种作用域类型，即singleton和prototype，2.0后，又引入了3种web相关的scope类型，即request、session、global session。 singleton 对象实例 容器中只存在一个共享实例。 对象存活时间 第一次请求被实例化到容器销毁或者退出。 prototype 对象实例 容器中存在多个实例。 对象存活时间 每次请求即创建1个新的实例，对象实例返回给请求方之后，容器就不再拥有当前返回对象的引用，请求方需要自己负责当前返回对象的后继生命周期的管理工作，包括该对象的销毁。 request Spring容器，即XmlWebApplicationContext会为每个HTTP请求创建一个全新的Request-Processor对象供当前请求使用，当请求结束后，该对象实例的生命周期即告结束。当同时有10个HTTP请求进来的时候，容器会分别针对这10个请求返回10个全新的RequestProcessor 对象实例，且它们之间互不干扰。 session Spring容器会为每个独立的session创建属于它们自己的全新的UserPreferences对象实例。与request相比，除了拥有session scope的bean的实例具有比request scope的bean可能更长的存活时间，其他方面真是没什么差别。 global session global session只有应用在基于portlet的Web应用程序中才有意义，它映射到portlet的global范围的session。如果在普通的基于servlet的Web应用中使用了这个类型的scope，容器会将其作为普通的session类型的scope对待。 自定义scope 在Spring 2.0之后的版本中，容器提供了对scope的扩展点，这样，你可以根据自己的需要或者应用的场景，来添加自定义的scope类型。需要说明的是，默认的singleton和prototype是硬编码到代码中的，而request、session和global session，包括自定义scope类型，则属于可扩展的scope行列，它们都实现了org.springframework.beans.factory.config.Scope接口。 具体如何进行自定义scope的设计开发，以后我们专门写篇文章介绍。 下面看一个有意思的东西: 去除掉MainEngine的toString()方法，并将mainEngine的scope设置为prototype。 1234567891011 &lt;bean id=&quot;mainEngine&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.MainEngine&quot; scope=&quot;prototype&quot;&gt; &lt;constructor-arg name=&quot;cost&quot;&gt; &lt;value&gt;3600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;type&quot;&gt; &lt;value&gt;T600&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;name&quot;&gt; &lt;value&gt;戴尔&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 修改主函数: 12345678public class IocXmlTest &#123; public static void main(String[] args) &#123; XmlBeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;spring-beans.xml&quot;)); Computer computer = (Computer) beanFactory.getBean(&quot;computer&quot;); System.out.println(computer.getMainEngine()); System.out.println(computer.getMainEngine()); &#125;&#125; 运行: 12com.ruanshubin.springboot.ioc.entity.MainEngine@4dfa3a9dcom.ruanshubin.springboot.ioc.entity.MainEngine@4dfa3a9d 显然，2次获取的MainEngine实例是同一个。 那么，如何在每次获取MainEngine时，总返回新创建的实例呢，可以使用标签: 123456&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;组装机1&quot;/&gt; &lt;property name=&quot;mainEngine&quot; ref=&quot;mainEngine&quot;/&gt; &lt;property name=&quot;display&quot; ref=&quot;display&quot;/&gt; &lt;lookup-method name=&quot;getMainEngine&quot; bean=&quot;mainEngine&quot;/&gt;&lt;/bean&gt; 再次运行主函数: 12com.ruanshubin.springboot.ioc.entity.MainEngine@480bdb19com.ruanshubin.springboot.ioc.entity.MainEngine@2a556333 达到目的。 同时，可以对Computer的getMainEngine进行改造，使其每次从BeanFactory中取MainEngine得实例，操作方法是使Computer实现BeanFactoryAware接口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Computer implements BeanFactoryAware &#123; private BeanFactory beanFactory; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = beanFactory; &#125; // 名称 private String name; // 主机 private MainEngine mainEngine; // 显示器 private Display display; public Computer() &#123; &#125; public Computer(String name, MainEngine mainEngine, Display display) &#123; this.name = name; this.mainEngine = mainEngine; this.display = display; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public MainEngine getMainEngine() &#123; return beanFactory.getBean(&quot;mainEngine&quot;, MainEngine.class); &#125; public void setMainEngine(MainEngine mainEngine) &#123; this.mainEngine = mainEngine; &#125; public Display getDisplay() &#123; return display; &#125; public void setDisplay(Display display) &#123; this.display = display; &#125;&#125; 此时，去掉以下配置，运行上述主程序: 1&lt;lookup-method name=&quot;getMainEngine&quot; bean=&quot;mainEngine&quot;/&gt; 运行结果为: 12com.ruanshubin.springboot.ioc.entity.MainEngine@402a079ccom.ruanshubin.springboot.ioc.entity.MainEngine@59ec2012 仍然可达到目的。 当然，如果不想实现BeanFactoryAware接口，也可以采用ObjectFactoryCreatingFactoryBean方式。 ObjectFactoryCreatingFactoryBean是Spring提供的一个FactoryBean实现，它返回一个ObjectFactory实例。从ObjectFactoryCreatingFactoryBean返回的这个ObjectFactory实例可以为我们返回容器管理的相关对象。 首先，在spring-beans.xml里配置ObjectFactoryCreatingFactoryBean，并注入主机类。 12345678910111213&lt;bean id=&quot;objectFactory&quot; class=&quot;org.springframework.beans.factory.config.ObjectFactoryCreatingFactoryBean&quot;&gt; &lt;property name=&quot;targetBeanName&quot;&gt; &lt;idref bean=&quot;mainEngine&quot;/&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;computer&quot; class=&quot;com.ruanshubin.springboot.ioc.entity.Computer&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;组装机1&quot;/&gt; &lt;property name=&quot;display&quot; ref=&quot;display&quot;/&gt; &lt;property name=&quot;objectFactory&quot;&gt; &lt;ref bean=&quot;objectFactory&quot;/&gt; &lt;/property&gt;&lt;/bean&gt; 同时修改Computer类: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Computer&#123; private ObjectFactory objectFactory; public void setObjectFactory(ObjectFactory objectFactory) &#123; this.objectFactory = objectFactory; &#125; // 名称 private String name; // 主机 private MainEngine mainEngine; // 显示器 private Display display; public Computer() &#123; &#125; public Computer(String name, MainEngine mainEngine, Display display) &#123; this.name = name; this.mainEngine = mainEngine; this.display = display; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public MainEngine getMainEngine() &#123; return (MainEngine) objectFactory.getObject(); &#125; public void setMainEngine(MainEngine mainEngine) &#123; this.mainEngine = mainEngine; &#125; public Display getDisplay() &#123; return display; &#125; public void setDisplay(Display display) &#123; this.display = display; &#125;&#125; 运行结果为: 12com.ruanshubin.springboot.ioc.entity.MainEngine@5cb9f472com.ruanshubin.springboot.ioc.entity.MainEngine@56ef9176 写着写着就写多了，更多Spring-IOC容器XML配置的东西，我们后面有机会再讲。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring容器之BeanFactory]]></title>
    <url>%2F2019%2F06%2F04%2FSpring%E5%AE%B9%E5%99%A8%E4%B9%8BBeanFactory%2F</url>
    <content type="text"><![CDATA[引言Spring提供了两种容器类型: BeanFactory ApplicationContext 其中ApplicationContext间接继承自BeanFactory，两者最大的不同是容器初始化策略。 BeanFactory采用懒加载(lazy-load)策略，即当客户端需要访问容器内的某个对象时，才对该对象进行初始化以及依赖注入操作。所以该模式下，启动速度较快，适用于资源有限，对功能要求不是很严格的场景。 ApplicationContext所管理的对象，默认启动之后全部初始化并绑定完成，故启动速度较慢，但其除了拥有BeanFactory的所有支持，还提供事件发布、国际化信息支持等，所以适用于系统资源充足，并且要求更多功能的场景。 本文首先讲解BeanFactory。 BeanFactory、BeanDefinitionRegistry和Bean的关系BeanFactory主要完成2项工作: 业务对象的初始化及注册； 对象间依赖关系的绑定。 看一下BeanFactory的源码： 12345678910111213141516171819202122232425262728public interface BeanFactory &#123; String FACTORY_BEAN_PREFIX = &quot;&amp;&quot;; Object getBean(String var1) throws BeansException; &lt;T&gt; T getBean(String var1, @Nullable Class&lt;T&gt; var2) throws BeansException; Object getBean(String var1, Object... var2) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; var1) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; var1, Object... var2) throws BeansException; boolean containsBean(String var1); boolean isSingleton(String var1) throws NoSuchBeanDefinitionException; boolean isPrototype(String var1) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String var1, ResolvableType var2) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String var1, @Nullable Class&lt;?&gt; var2) throws NoSuchBeanDefinitionException; @Nullable Class&lt;?&gt; getType(String var1) throws NoSuchBeanDefinitionException; String[] getAliases(String var1);&#125; 可以发现，BeanFactory接口只定义了查询相关的方法，例如: 取得某个对象的方法（getBean）、查询某个对象是否存在于容器中的方法（containsBean），或者取得某个bean的状态或者类型的方法等。 而对象的注册管理及依赖绑定则交给BeanFactory的接口实现类来完成，如常见的DefaultListableBeanFactory。 12345public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; ...&#125; DefaultListableBeanFactory还实现了BeanDefinitionRegistry接口，来完成Bean的注册管理。 简单阐释一下BeanFactory、BeanDefinitionRegistry和Bean的关系： Bean是图书，BeanFactory相当于图书馆，而BeanDefinitionRegistry则相当于图书馆的书架。虽然还书和借书均是跟图书馆(BeanFactory)打交道，但是图书馆实际存储书的地方是书架(BeanDefinitionRegistry)。 每个Bean交给BeanFactory管理时，均会包装成BeanDefination接口的实例，BeanDefination实例负责保存Bean所有必要的信息，包括Class类型、是否是抽象类、构造方法参数及其他属性等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement &#123; String SCOPE_SINGLETON = &quot;singleton&quot;; String SCOPE_PROTOTYPE = &quot;prototype&quot;; int ROLE_APPLICATION = 0; int ROLE_SUPPORT = 1; int ROLE_INFRASTRUCTURE = 2; void setParentName(@Nullable String var1); @Nullable String getParentName(); void setBeanClassName(@Nullable String var1); @Nullable String getBeanClassName(); void setScope(@Nullable String var1); @Nullable String getScope(); void setLazyInit(boolean var1); boolean isLazyInit(); void setDependsOn(@Nullable String... var1); @Nullable String[] getDependsOn(); void setAutowireCandidate(boolean var1); boolean isAutowireCandidate(); void setPrimary(boolean var1); boolean isPrimary(); void setFactoryBeanName(@Nullable String var1); @Nullable String getFactoryBeanName(); void setFactoryMethodName(@Nullable String var1); @Nullable String getFactoryMethodName(); ConstructorArgumentValues getConstructorArgumentValues(); default boolean hasConstructorArgumentValues() &#123; return !this.getConstructorArgumentValues().isEmpty(); &#125; MutablePropertyValues getPropertyValues(); default boolean hasPropertyValues() &#123; return !this.getPropertyValues().isEmpty(); &#125; boolean isSingleton(); boolean isPrototype(); boolean isAbstract(); int getRole(); @Nullable String getDescription(); @Nullable String getResourceDescription(); @Nullable BeanDefinition getOriginatingBeanDefinition();&#125; RootBeanDefinition和ChildBeanDefinition是BeanDefinition的两个主要实现类。 BeanFactory的对象注册与依赖绑定方式假设我们有一家饭店，需要有蔬菜采购和厨师做菜，则Restaurant类定义如下: 123456789public class Restaurant &#123; // 厨师 private Chef chef; // 蔬菜 private Vegetable vegetable; 构造方法... get/set方法...&#125; 蔬菜存在多种，我们抽象出Vegetable接口，并存在购买行为。 123public interface Vegetable &#123; public String buy();&#125; 编写2个Vegetable接口的实现类Tomato、Cabbage: 123456789101112131415public class Tomato implements Vegetable &#123; @Override public String buy() &#123; System.out.println(&quot;采购员买来了番茄!&quot;); return &quot;Tomato&quot;; &#125;&#125;public class Cabbage implements Vegetable &#123; @Override public String buy() &#123; System.out.println(&quot;采购员买来了卷心菜!&quot;); return &quot;Cabbage&quot;; &#125;&#125; 厨师也可能有多种，抽象出Chef接口如下: 123public interface Chef &#123; public void cook(String vegetableName);&#125; 并编写2个Chef的实现类: 1234567891011121314public class ChineseChef implements Chef &#123; @Override public void cook(String vegetableName) &#123; System.out.println(&quot;中国厨师正在做&quot; + vegetableName + &quot;!&quot;); &#125;&#125;public class ForeignChef implements Chef &#123; @Override public void cook(String vegetableName) &#123; System.out.println(&quot;外国厨师正在做&quot; + vegetableName + &quot;!&quot;); &#125;&#125; 假设我们现在要开这样一家饭店，需要中国厨师和番茄，那么如何完成对象的注册管理和依赖绑定呢? 直接编码形式所谓直接编码形式，即用Spring的底层容器类来进行Bean的注册和管理，虽然不常用，但却有助于我们了解Spring的IOC是如何运作的。 12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; public static void main(String[] args) &#123; DefaultListableBeanFactory beanRegistry = new DefaultListableBeanFactory(); BeanFactory container = bindViaCode(beanRegistry); // 测试Bean的装配 Restaurant chineseRestaurant = (Restaurant) container.getBean(&quot;chineseRestaurant&quot;); Vegetable vegetable = chineseRestaurant.getVegetable(); String vegetableName = vegetable.buy(); Chef chef = chineseRestaurant.getChef(); chef.cook(vegetableName); // 测试Bean的管理 Chef chef1 = (Chef) container.getBean(&quot;chineseChef&quot;); chef1.cook(&quot;干锅花菜&quot;); &#125; public static BeanFactory bindViaCode(BeanDefinitionRegistry registry)&#123; AbstractBeanDefinition restaurant = new RootBeanDefinition(Restaurant.class); AbstractBeanDefinition chef = new RootBeanDefinition(ChineseChef.class); AbstractBeanDefinition vegetable = new RootBeanDefinition(Tomato.class); // 将Bean注册到容器中 registry.registerBeanDefinition(&quot;chineseRestaurant&quot;, restaurant); registry.registerBeanDefinition(&quot;chineseChef&quot;, chef); registry.registerBeanDefinition(&quot;tomato&quot;, vegetable); // 1. 指定依赖关系(构造方法注入) ConstructorArgumentValues argValues = new ConstructorArgumentValues(); argValues.addIndexedArgumentValue(0, chef); argValues.addIndexedArgumentValue(1, vegetable); restaurant.setConstructorArgumentValues(argValues); // 2. 指定依赖关系(setter方法注入) MutablePropertyValues propertyValues = new MutablePropertyValues(); propertyValues.addPropertyValue(new PropertyValue(&quot;chef&quot;, chef)); propertyValues.addPropertyValue(new PropertyValue(&quot;vegetable&quot;, vegetable)); restaurant.setPropertyValues(propertyValues); // 绑定完成 return (BeanFactory) registry; &#125;&#125; 运行结果如下: 123采购员买来了番茄!中国厨师正在做Tomato!中国厨师正在做干锅花菜! 外部配置文件形式其实就是将Bean的依赖关系放在配置文件中，然后Spring解析配置文件，得到各对象的依赖关系，进而完成对象的注册和依赖管理。 整体的流程如下: BeanDefinitionReader实现类读取配置文件内容，并映射得到待管理Bean的BeanDefinition; BeanDefinitionReader根据配置文件内容定义的依赖关系，通过BeanDefinition指定Bean之间的依赖关系; 将映射后的BeanDefinition注册到BeanDefinitionRegistry中。 上述大部分的工作，如解析文件格式、装配BeanDefinition之类的工作，均由BeanDefinitionReader实现类来完成，BeanDefinitionRegistry仅是负责Bean的保管而已。 整个过程类似于如下代码: 1234BeanDefinitionRegistry beanRegistry = &lt;某个 BeanDefinitionRegistry 实现类，通常为DefaultListableBeanFactory&gt;;BeanDefinitionReader beanDefinitionReader = new BeanDefinitionReaderImpl(beanRegistry);beanDefinitionReader.loadBeanDefinitions(&quot;配置文件路径&quot;);// 现在我们就取得了一个可用的BeanDefinitionRegistry实例 看一下BeanDefinitionReader： 12345678910111213141516171819public interface BeanDefinitionReader &#123; BeanDefinitionRegistry getRegistry(); @Nullable ResourceLoader getResourceLoader(); @Nullable ClassLoader getBeanClassLoader(); BeanNameGenerator getBeanNameGenerator(); int loadBeanDefinitions(Resource var1) throws BeanDefinitionStoreException; int loadBeanDefinitions(Resource... var1) throws BeanDefinitionStoreException; int loadBeanDefinitions(String var1) throws BeanDefinitionStoreException; int loadBeanDefinitions(String... var1) throws BeanDefinitionStoreException;&#125; 可以看出，BeanDefinitionReader通过getRegistry()获取BeanDefinitionRegistry，getResourceLoader()加载配置文件资源用于解析Bean的注册和依赖关系，getBeanClassLoader()获取类加载器用于类的加载，loadBeanDefinitions(..)方法主要运用反射将待管理的Bean封装成BeanDefinition，最后注册到BeanDefinitionRegistry中。 由上图可以看出，Spring的IOC容器默认支持3种文件格式: Properties文件格式 XML文件格式 Groovy文件格式 本文主要讨论前2种文件格式: Properties文件首先在resources目录下创建beans.properties文件: 12345678910# bean的name.(class)=实现类的全路径chef.(class)=com.ruanshubin.springboot.ioc.service.impl.ChineseChefvegetable.(class)=com.ruanshubin.springboot.ioc.service.impl.Tomatorestaurant.(class)=com.ruanshubin.springboot.ioc.domain.Restaurant# 通过构造方法注入restaurant.$0(ref)=chefrestaurant.$1(ref)=vegetable# 通过setter方法注入# restaurant.setChef(ref)=chef# restaurant.setVegetable(ref)=vegetable 然后编写主函数: 123456789101112131415161718192021public class FileTest &#123; public static void main(String[] args) &#123; DefaultListableBeanFactory beanRegistry = new DefaultListableBeanFactory(); BeanFactory container = bindViaPropertiesFile(beanRegistry); // 测试Bean的装配 Restaurant chineseRestaurant = (Restaurant) container.getBean(&quot;restaurant&quot;); Vegetable vegetable = chineseRestaurant.getVegetable(); String vegetableName = vegetable.buy(); Chef chef = chineseRestaurant.getChef(); chef.cook(vegetableName); // 测试Bean的管理 Chef chef1 = (Chef) container.getBean(&quot;chef&quot;); chef1.cook(&quot;蒜蓉空心菜!&quot;); &#125; public static BeanFactory bindViaPropertiesFile(BeanDefinitionRegistry registry)&#123; PropertiesBeanDefinitionReader reader = new PropertiesBeanDefinitionReader(registry); reader.loadBeanDefinitions(&quot;classpath:beans.properties&quot;); return (BeanFactory) registry; &#125;&#125; 运行结果如下: 123采购员买来了番茄!中国厨师正在做Tomato!中国厨师正在做蒜蓉空心菜! XML文件XML配置格式是Spring支持最完整，功能最强大的表达方式，主要得益于: XML良好的语意表达能力； Spring框架从开始就自始至终保持XML配置加载的统一性。 Spring 2.x之前，XML配置文件采用DTD（Document Type Definition）实现文档的格式约束。2.x之后，引入了基于XSD（XML Schema Definition）的约束方式。不过，原来的基于DTD的方式依然有效，因为从DTD转向XSD只是“形式”上的转变。 首先在resources目录下创建beans.xml文件: 1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-//SPRING//DTD BEAN//EN&quot; &quot;http://www.springframework.org/dtd/spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;bean id=&quot;restaurant&quot; class=&quot;com.ruanshubin.springboot.ioc.domain.Restaurant&quot;&gt; &lt;constructor-arg index=&quot;0&quot;&gt; &lt;ref bean=&quot;chef&quot;/&gt; &lt;/constructor-arg&gt; &lt;constructor-arg index=&quot;1&quot;&gt; &lt;ref bean=&quot;vegetable&quot;/&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=&quot;chef&quot; class=&quot;com.ruanshubin.springboot.ioc.service.impl.ForeignChef&quot;/&gt; &lt;bean id=&quot;vegetable&quot; class=&quot;com.ruanshubin.springboot.ioc.service.impl.Cabbage&quot;/&gt;&lt;/beans&gt; 主函数: 123456789101112131415161718192021222324public class FileTest &#123; public static void main(String[] args) &#123; DefaultListableBeanFactory beanRegistry = new DefaultListableBeanFactory(); BeanFactory container = bindViaXmlFile(beanRegistry); // 测试Bean的装配 Restaurant chineseRestaurant = (Restaurant) container.getBean(&quot;restaurant&quot;); Vegetable vegetable = chineseRestaurant.getVegetable(); String vegetableName = vegetable.buy(); Chef chef = chineseRestaurant.getChef(); chef.cook(vegetableName); // 测试Bean的管理 Chef chef1 = (Chef) container.getBean(&quot;chef&quot;); chef1.cook(&quot;法式焗蜗牛&quot;); &#125; public static BeanFactory bindViaXmlFile(BeanDefinitionRegistry registry)&#123; XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(registry); reader.loadBeanDefinitions(&quot;classpath:beans.xml&quot;); return (BeanFactory) registry; // 或者直接如下: // return new XmlBeanFactory(new ClassPathResource(&quot;beans.xml&quot;)); &#125;&#125; 运行结果如下: 123采购员买来了卷心菜!外国厨师正在做Cabbage!外国厨师正在做法式焗蜗牛! 当然，如果你想使用其他格式的配置文件来进行Bean的注册和依赖管理，可以实现自定义的BeanDefinitionReader来达到自定义文件加载的目的。 注解形式基于注解的方式，主要是通过@Autowired及@Component对相关类进行标记，然后通过AbstractApplicationContext借助classpath-scanning功能来完成Bean的注册和依赖管理。 首先为相关类添加注解: 1234567891011121314151617181920@Componentpublic class Restaurant &#123; // 厨师 @Autowired private Chef chef; // 蔬菜 @Autowired private Vegetable vegetable; ... &#125; @Componentpublic class Tomato implements Vegetable &#123; ...&#125;@Componentpublic class ChineseChef implements Chef &#123; ...&#125; @Autowired用于依赖注入，@Component用于Bean注册，接下来配置注解扫描。 在resources目录下新建spring.xml: 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;com.ruanshubin.springboot.ioc&quot;/&gt;&lt;/beans&gt; 会到指定的包（package）下面扫描标注有@Component的类，如果找到，则将它们添加到容器进行管理，并根据它们所标注的@Autowired为这些类注入符合条件的依赖对象。 主函数: 12345678910111213public class AnnotationTest &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;spring.xml&quot;); Restaurant chineseRestaurant = (Restaurant) ctx.getBean(&quot;restaurant&quot;); Vegetable vegetable = chineseRestaurant.getVegetable(); String vegetableName = vegetable.buy(); Chef chef = chineseRestaurant.getChef(); chef.cook(vegetableName); // 测试Bean的管理 Chef chef1 = (Chef) ctx.getBean(&quot;chineseChef&quot;); chef1.cook(&quot;鸡蛋韭菜水饺&quot;); &#125;&#125; 运行结果为: 123采购员买来了番茄!中国厨师正在做Tomato!中国厨师正在做鸡蛋韭菜水饺! 我们再配置Bean时，只是在实体类上加了@Component注解，并没有指定Bean的id或name，ApplicationContext默认采用实体类的小驼峰作为id，如ChineseChef的id为chineseChef，Tomato的id为tomato。 同时，在配置Bean依赖时，@Autowired加在接口之上，如: 12@Autowiredprivate Chef chef; 由于我们只在ChineseChef添加了@Component注解，所以Spring容器里只有1个Chef的实现类，此时，ApplicationContext直接将ChineseChef注入到Restaurant中。 假如Spring容器里有2个Chef的实现类.会出现什么情况呢? 只需要在ForeignChef上添加@Component即可。 1234@Componentpublic class ForeignChef implements Chef &#123; ... &#125; 重新运行主函数，报错: 12Exception in thread &quot;main&quot; org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;restaurant&apos;: Unsatisfied dependency expressed through field &apos;chef&apos;; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type &apos;com.ruanshubin.springboot.ioc.service.Chef&apos; available: expected single matching bean but found 2: chineseChef,foreignChef ... 错误信息很明显，说进行Restaurant依赖注入的时候，发现Chef接口有2个实现类:chineseChef、foreignChef，程序不知道该选择哪个进行注入。 解决上述错误的方式有很多，后面我们专门用1篇文章进行讲解。 参考文献: 王福强. Spring揭秘[M]. 2009. 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程-valatile关键字]]></title>
    <url>%2F2019%2F05%2F28%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-valatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[引言很久之前就想写volatile关键字，但是迟迟没有动笔，主要是volatile涉及到的东西有点多，讲不清楚倒还好，就怕反而把读者绕晕了，哈哈。 volatile关键字是为了保证内存可见性及有序性的，首先介绍并发编程中涉及到的3个问题: 并发编程规则原子性原子具有不可分割性，所谓原子性，指的是一个或多个操作，要么全部执行且执行过程不会被任何因素打断，要么就全部执行，其与事务的语义是一致的。 比如经典的转账问题: 小明给小强转账1000元，该操作分为2步: 小明的账户减少1000元； 小强的账户增加1000元。 如果上述操作是非原子的，假如步骤1执行成功，而步骤2则异常中断，此时就会造成小明平白无故丢失了1000元。 在Java中，主要通过synchronized关键字、Lock接口来实现多个操作的原子性。 可见性所谓可见性，指的线程之间的可见性，一个线程修改的状态对另外的线程是可见的。 在Java中valatile、synchronized和final实现了可见性。 有序性即程序执行的顺序按照代码的先后顺序执行。 1234int i = 0;boolean flag = false;i =1; // 语句1flag = true; // 语句2 程序本来就是按照代码顺序来执行的呀，为啥还要保证？一切因为指令重排序(Instruction Reorder)的存在。 处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 也就是说，语句2可能会在语句1之前执行。 接着看下面的操作: 1234int a = 6; // 语句1int b = 2; // 语句2a = a + 3; // 语句3b = a * a; // 语句4 现在问题来了，语句4可能在语句3之前执行吗? 答案是不可能，因为指令重排序会分析语句间的数据依赖性，假设语句B依赖于语句A，即语句B需要使用语句A的结果，则不会发生指令重排序。 所以，单线程环境下，指令重排序只是为了提高运行速度，并不会影响运算结果，但多线程环境下呢，看以下语句: 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2//线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 在Java中synchronized、Lock、volatile实现了有序性。 volatile关键字是与Java内存模型紧密相关的，所以我们先简单讲解一下Java的内存模型。 Java内存模型众所周知，CPU在执行程序指令的过程中，势必涉及到数据的读取和存入，运行过程中的中间数据存储在物理内存中。 物理内存的数据存取速度和CPU的运行速度相比，基本等同于蜗牛和波音747，所以高速缓存出现了。 高速缓存的速度虽然还是比不上CPU，但是比物理内存(主内存)还是要快多了。 所以程序进行计算时，会将需要用到的数据先从主内存取到高速缓存中，然后CPU从高速缓存中取数据进行计算，计算的中间结果存入高速缓存，计算结束后将结果由高速缓存刷新到主内存。 上述模式在单线程环境下没有问题，但是多线程下可能就会出问题，比如简单的i++操作: 12i=0;i++; 假设线程A和线程B分别执行了i++操作，理论上最终结果应该为2，但实际上也可能为1。 原因是i++操作实际上分为2步: 将主内存中i的值取到高速缓存； CPU从高速缓存取出i，完成+1操作后，存入高速缓存，并刷新到主内存。 如果线程A和B同时执行了步骤1，此时线程A和B的高速缓存中的值均为0，完成+1操作后分别刷新到主内存中，最终结果为1，即出现了缓存一致性问题。 为解决缓存一致性问题，一般采取两种方式： 在总线上加LOCK#锁； 缓存一致性协议。 上述两种方式均是基于硬件指令实现的。 在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 Java内存模型具备一些先天的有序性，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为happens-before原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 happens-before原则主要包括: 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作。 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作。 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作。 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行。 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始。 后4项原则是必然的，具体看一下前4项。 程序次序规则保证了单线程环境下，指令重排序不会影响运行结果。 锁定规则也很显然，当某线程获取对象锁之前，必须先等待其他线程释放锁。 volatile变量规则指的是如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 传递规则实际上就是体现happens-before原则具备传递性。 介绍了并发编程规则及Java的内存模型，下面我们深入分析一下volatile关键字: volatile关键字基本语义 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 禁止进行指令重排序。 第1个语义不多讲，其与缓存一致性协议基本类似，下面看一下第2个语义： 还是沿用上面的例子: 123456789//线程1:context = loadContext(); //语句1volatile inited = true; //语句2//线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); inited由volatile修饰后，则语句1和语句2不会发生重排序，保证inited = true时，运行上下文context必定加载完毕，从而避免了上述多线程下的运行异常。 实现机制下面这段话摘自《深入理解Java虚拟机》： 观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令。 lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 它会强制将对缓存的修改操作立即写入主存； 如果是写操作，它会导致其他CPU中对应的缓存行无效。 应用场景 状态变量 123456789//线程1:context = loadContext(); //语句1volatile inited = true; //语句2//线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 单例模式的双重校验 1234567891011121314public class Singleton &#123; private Singleton() &#123; &#125; private volatile static Singleton instance; public Singleton getInstance()&#123; if(instance==null)&#123; synchronized (Singleton.class)&#123; if(instance==null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 之所以instance需要使用volatile修饰，是因为下述语句可能会发生指令重排序: 1instance = new Singleton(); 上述操作分为2步: 初始化对象； 将对象指针赋给instance。 假设步骤1、2发生了重排序，即步骤2在步骤1之前执行，当其他读取线程进行单例读取时，此时步骤2已执行完成，读取线程判断instance非null，故进行读取，但此时步骤1可能还未完成，即对象还未初始化完成，从而导致读取线程发生异常。 instance添加volatile关键字后，步骤1和2禁止指令重排序，从而避免了上述问题。 ConcurrentHashMap volatile关键字在ConcurrentHashMap中的应用，可以参见我的另外一篇文章: ConcurrentHashMap揭秘-JDK1.7 参考文献： https://www.cnblogs.com/zhengbin/p/5654805.html https://www.cnblogs.com/dolphin0520/p/3920373.html https://blog.csdn.net/u013412772/article/details/80109727 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap揭秘-JDK1.7]]></title>
    <url>%2F2019%2F05%2F28%2FConcurrentHashMap%E6%8F%AD%E7%A7%98-JDK1.7%2F</url>
    <content type="text"><![CDATA[引言HashMap是非线程安全的，而HashTable是线程安全的，但是HashTable实现同步的方法比较暴力，即在所有方法体上添加synchronized关键字，相当于所有读写线程均去读取一把锁，效率比较低下。 另外一种同步Map的方法是使用Collections工具类： 1Collections.synchronized（new HashMap() 该种方法与HashTable实现方式类似，也是通过锁住整表来实现同步的。 而ConcurrentHashMap则避免了上述两种Map同步方式锁住全表的问题。 众所周知，HashMap是根据散列值分段存储的，同步Map在同步的时候锁住了所有的段，而ConcurrentHashMap加锁的时候根据散列值锁住了散列值锁对应的那段，因此提高了并发性能。ConcurrentHashMap也增加了对常用复合操作的支持，比如”若没有则添加”：putIfAbsent()，替换：replace()。这2个操作都是原子操作。 ConcurrentHashMap可以做到读取数据不加锁，并且其内部的结构可以让其在进行写操作的时候能够将锁的粒度保持地尽量地小，不用对整个ConcurrentHashMap加锁。 再次声明，本文介绍的ConcurrentHashMap是JDK1.7版本的，JDK1.8对ConcurrentHashMap做了较多改进，后面会专门写一篇文章介绍。 ConcurrentHashMap的内部结构 可以看到，ConcurrentHashMap内部采用了一种叫Segment的数据结构，很明显它就是一个数组table(哈希桶)，数据的元素就是大家熟悉的HashEntry(哈希链)。 简单来讲，就是ConcurrentHashMap比HashMap多了一次hash过程，第1次hash定位到Segment，第2次hash定位到HashEntry，然后链表搜索找到指定节点。 该种实现方式的缺点是hash过程比普通的HashMap要长，但是优点也很明显，在进行写操作时，只需锁住写元素所在的Segment即可，其他Segment无需加锁，提高了并发读写的效率。 Segment1234567static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; transient volatile int count; transient int modCount; transient int threshold; transient volatile HashEntry&lt;K,V&gt;[] table; final float loadFactor;&#125; 可以看出，Segment继承了ReentrantLock并实现了序列化接口，说明Segment的锁是可重入的。 count: Segment中元素的数量，由volatile修饰，支持内存可见性； modCount: 对table的大小造成影响的操作的数量（比如put或者remove操作）; threshold：扩容阈值; table：链表数组，数组中的每一个元素代表了一个链表的头部; loadFactor: 负载因子。 可以发现，Segment的数据结构与普通的HashMap基本类似，只是通过继承ReentrantLock可实现加锁操作。 HashEntrySegment中的元素是以HashEntry的形式存放在链表数组中的，其结构与普通HashMap的HashEntry基本一致，不同的是Segment的HashEntry，其value由volatile修饰，以支持内存可见性，即写操作对其他读线程即时可见。 123456static final class HashEntry&lt;K,V&gt; &#123; final K key; final int hash; volatile V value; final HashEntry&lt;K,V&gt; next;&#125; 看完数据结构，接着看初始化过程： ConcurrentHashMap的初始化直接跟源码: 123456789101112131415161718192021222324252627282930313233343536373839404142// initialCapacity: 初始容量// loadFactor: 负载因子// concurrencyLevel： ConcurrentHashMap内部的Segment的数量public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); // 若concurrencyLevel大于MAX_SEGMENTS，则concurrencyLevel=MAX_SEGMENTS if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // 求解concurrencyLevel与2的几次方最近(天花板方向) // 如concurrencyLevel=5 则天花板方向上离2^3=8最近，则sshift=3，ssize=8 int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; // segmentShift和segmentMask主要用于元素的hash segmentShift = 32 - sshift; segmentMask = ssize - 1; // 可以看到，实际segment的数量为ssize this.segments = Segment.newArray(ssize); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; // 若initialCapacity / ssize不整除，则将c=c+1 if (c * ssize &lt; initialCapacity) ++c; int cap = 1; // cap为每个segment的初始容量，其值为离c天花板方向最近的2^n // 例：c为5，cap则为2^3=8；c为12，cap则为2^4=16 while (cap &lt; c) cap &lt;&lt;= 1; // 创建Segment for (int i = 0; i &lt; this.segments.length; ++i) this.segments[i] = new Segment&lt;K,V&gt;(cap, loadFactor);&#125; 需要注意的是，concurrencyLevel一经指定，便不能再次改变，原因也很简单，简化元素增多时的rehash过程，若Segment的数量也随元素的增加而进行扩容，则需要进行两次rehash，需要处理全部元素，效率较低。 随着元素的增加，ConcurrentHashMap不会增加Segment的数量，而只会增加Segment中链表数组的容量大小，这样的好处是扩容过程不需要对整个ConcurrentHashMap做rehash，而只需要对Segment里面的元素做一次rehash就可以了。 ConcurrentHashMap的get操作1234567public V get(Object key) &#123; // 首先计算key的hash值 int hash = hash(key.hashCode()); // segmentFor(hash): 定位到key在哪个segment // 调用segment的get(key, hash)获取到指定key的value return segmentFor(hash).get(key, hash);&#125; 接着跟进segmentFor(hash): 123final Segment&lt;K,V&gt; segmentFor(int hash) &#123; return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];&#125; 重新回顾一下，ConcurrentHashMap初始化时，确定的2个参数： 12segmentShift = 32 - sshift;segmentMask = ssize - 1; 其中，ssize = 2^sshift，ssize即为Segment的数量。 我们知道： 12// 通过位运算简化求余操作hash % (2^n) = hash &amp; (2^n -1 ) 可以看出，ConcurrentHashMap的第1次hash没有直接采用key的hash值来进行求余操作，而是采用hash值的高sshift位来进行求余操作的。 而hash值的高sshift位为: 1hash &gt;&gt;&gt; (32-sshift) = hash &gt;&gt;&gt; segmentShift 至此，第1次hash操作就完成了。 下面，我们继续看Segment的get(key, hash)方法，即第2次hash过程： 1234567891011121314151617V get(Object key, int hash) &#123; if (count != 0) &#123; // read-volatile // 取得链表的头部，就是第2次hash过程 HashEntry&lt;K,V&gt; e = getFirst(hash); // 链表搜索，直到hash与key均相等时，返回节点的value while (e != null) &#123; if (e.hash == hash &amp;&amp; key.equals(e.key)) &#123; V v = e.value; if (v != null) return v; return readValueUnderLock(e); // recheck &#125; e = e.next; &#125; &#125; return null;&#125; 首先对count做了非零判断，前边讲解Segment的数据结构时，指出count是volatile修饰的，put、remove等操作会更新count的值，所以当竞争发生的时候，volatile的语义可以保证写操作在读操作之前，也就保证了写操作对后续的读操作都是可见的，这样后面get的后续操作就可以拿到完整的元素内容。 getFirst(hash)完成了第2次hash过程，跟进去： 123456HashEntry&lt;K,V&gt; getFirst(int hash) &#123; // 获取Segment的数组结构 HashEntry&lt;K,V&gt;[] tab = table; // 第2次hash过程，确定key位于哪一个HashEntry return tab[hash &amp; (tab.length - 1)];&#125; 可以看出，第2次hash与第1次hash基本类似，只不过直接用的hash值与Segment的数组大小进行求余，而没有采取hash值高n位的方式。 ConcurrentHashMap的put操作put操作也涉及2次hash定位过程，但是比get操作多了是否扩容、rehash等过程。 put操作的第1次hash与get类似，不再赘述，主要看如何将元素put到Segment中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; // 加锁 lock(); try &#123; int c = count; // 对c进行+1操作，获取新的数组容量 // 如果新的数组容量高于阈值，则先进行扩容操作 if (c++ &gt; threshold) // ensure capacity rehash(); // 获取Segment的数组table HashEntry&lt;K,V&gt;[] tab = table; // 确定在数组中的位置index，即第2次hash过程 int index = hash &amp; (tab.length - 1); // 获取index位置的头结点 HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; // 沿链表遍历，直到找到与元素key或者hash值相同的节点 while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue; // 若key或者hash值相同的节点存在，则进行更新操作 if (e != null) &#123; // value也是volatile修饰的，所以内存即时可见 oldValue = e.value; if (!onlyIfAbsent) e.value = value; &#125; // 若key或者hash值相同的节点不存在，则新建节点，追加到当前链表的头部(头插法) else &#123; oldValue = null; // 更新modCount的值，记录对table的大小造成影响的操作的数量 ++modCount; tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); // 更新count的值，内存即时可见 count = c; // write-volatile &#125; // 返回旧值 return oldValue; &#125; finally &#123; // 释放锁，与synchronize关键字不同，Lock必须显示释放 unlock(); &#125;&#125; 可以看到，Segment的put过程与普通的HashMap基本类似。 ConcurrentHashMap的remove操作与put操作基本类似，首先根据hash值的高sshift位与Segment的数量ssize求余定位到具体的Segment，然后在Segment上执行具体的remove操作。 下面我们看一下Segment如何实现remove操作的。 话不多说，直接怼源码： 12345678910111213141516171819202122232425262728293031323334353637383940V remove(Object key, int hash, Object value) &#123; // 加锁，除了读取操作，其他操作均需要加锁 lock(); try &#123; // 计算新的Segment元素数量 int c = count - 1; // 获取Segment的数组table HashEntry&lt;K,V&gt;[] tab = table; // 第2次hash，确定在table的哪个位置 int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; // 沿链表遍历，直到找到与元素key或者hash值相同的节点 while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue = null; if (e != null) &#123; V v = e.value; if (value == null || value.equals(v)) &#123; oldValue = v; // 更新modCount值 ++modCount; HashEntry&lt;K,V&gt; newFirst = e.next; // 将待删除元素的前面的元素全部复制一遍，然后头插到链表上去 for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value); tab[index] = newFirst; // 更新新的Segment元素数量，内存即时可见 count = c; // write-volatile &#125; &#125; // 返回旧值 return oldValue; &#125; finally &#123; // 释放锁 unlock(); &#125;&#125; 由于，HashEntry中的next是final的，一经赋值以后就不可修改，在定位到待删除元素的位置以后，程序就将待删除元素前面的那一些元素全部复制一遍，然后再一个一个重新接到链表上去。 如: 1234// 原有链表：1--&gt;2--&gt;3--&gt;4--&gt;5// 删除节点3，新的链表为：2--&gt;1--&gt;4--&gt;5 至此，JDK1.7版本的ConcurrentHashMap的基础方法介绍完毕，其他方法的实现方式，读者可自行阅读源码获取，再次不做过多阐述。 参考文献: https://www.cnblogs.com/dolphin0520/p/3932905.html http://ifeve.com/ConcurrentHashMap/ https://www.iteye.com/topic/344876 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的锁机制--ReadWriteLock接口]]></title>
    <url>%2F2019%2F05%2F20%2FJava%E7%9A%84%E9%94%81%E6%9C%BA%E5%88%B6--ReadWriteLock%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[ReentrantLock是排他锁，排他锁在同一时刻仅有一个线程可以进行访问，实际上独占锁是一种相对比较保守的锁策略，独占锁模式下的读/读、读/写、写/写操作都不能同时发生，这在一定程度上降低了吞吐量。然而读操作之间不存在数据竞争问题，如果读/读操作能够以共享锁的方式进行，那会进一步提升性能。 为解决读写冲突问题，Doug Lea设计了ReadWriteLock接口，该接口只定义了两个方法: readLock()用来获取读锁，writeLock()用来获取写锁，将共享资源的读/写操作分开进行管理，类似于数据库中的S锁(共享锁)和X锁(独占锁)，其遵循如下原则： 共享资源只允许加一种锁，或读锁，或写锁，不能同时加； 共享资源可以被多个线程同时加读锁，而写锁只允许加一把； 当共享资源被读锁占用时，写线程只能等待；同样的，当共享资源被写锁占用时，读线程只能等待。 所以，读/写、写/写是互斥的，而读/读是互不影响的，大大提升了读操作的效率。 实例J.U.C中，ReentrantReadWriteLock唯一实现了ReadWriteLock接口。 首先，通过一个简单示例来说明ReentrantReadWriteLock的用法。 假如有多个线程要同时进行读操作的话，首先看synchronized达到的效果： 123456789101112131415161718192021222324252627282930313233343536373839public class SynchronsizedRead &#123; public synchronized void get(Thread thread) throws InterruptedException &#123; long start = System.currentTimeMillis(); for(int i=0; i&lt;10; i++)&#123; System.out.println(thread.getName() + &quot;正在进行读操作...&quot;); Thread.sleep(100); &#125; System.out.println(thread.getName() + &quot;读操作完毕&quot;); &#125; public static void main(String[] args) &#123; final SynchronsizedRead synchronsizedread = new SynchronsizedRead(); new Thread()&#123; @Override public void run() &#123; try &#123; synchronsizedread.get(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); new Thread()&#123; @Override public void run() &#123; try &#123; synchronsizedread.get(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125;&#125; 运行结果为: 123456789101112131415161718192021222324Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-0读操作完毕Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1读操作完毕Process finished with exit code 0 可以看到，当持有锁的线程在读取数据的时候，其他读线程只能等待。 接着用ReentrantReadWriteLock来实现上述业务： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class LockRead &#123; private ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(); public void get(Thread thread) throws InterruptedException &#123; reentrantReadWriteLock.readLock().lock(); try&#123; long start = System.currentTimeMillis(); for(int i=0; i&lt;10; i++)&#123; System.out.println(thread.getName() + &quot;正在进行读操作...&quot;); Thread.sleep(100); &#125; System.out.println(thread.getName() + &quot;读操作完毕&quot;); &#125;finally&#123; reentrantReadWriteLock.readLock().unlock(); &#125; &#125; public static void main(String[] args) &#123; final LockRead lockRead = new LockRead(); new Thread()&#123; @Override public void run() &#123; try &#123; lockRead.get(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); new Thread()&#123; @Override public void run() &#123; try &#123; lockRead.get(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125;&#125; 运行结果为: 123456789101112131415161718192021222324Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-0正在进行读操作...Thread-1正在进行读操作...Thread-0正在进行读操作...Thread-0读操作完毕Thread-1正在进行读操作...Thread-1正在进行读操作...Thread-1读操作完毕Process finished with exit code 0 可以看到，ReentrantReadWriteLock模式下，可以实现多线程下同时读取数据，从而大大提升了读操作的效率。 源码跟读ReentrantReadWriteLock和ReentrantLock类似的公平锁和非公平锁（默认构造方法是非公平锁），Sync类是一个继承于AQS的抽象类。Sync有FairSync公平锁和NonfairSync非公平锁两个子类： 123456789public ReentrantReadWriteLock() &#123; this(false);&#125; public ReentrantReadWriteLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this);&#125; ReentrantReadWriteLock中包含了下面三个对象：sync对象，读锁readerLock和写锁writerLock。 读锁： 12345678910111213141516171819202122232425262728293031323334353637383940414243public static class ReadLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = -5992448646407690164L; private final Sync sync; protected ReadLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125; public void lock() &#123; // 调用sync的acquireShared(1)方法实现共享锁的释放 sync.acquireShared(1); &#125; // 获取锁(可中断) public void lockInterruptibly() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; // 获取锁 public boolean tryLock() &#123; return sync.tryReadLock(); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; // 释放锁 public void unlock() &#123; sync.releaseShared(1); &#125; public Condition newCondition() &#123; throw new UnsupportedOperationException(); &#125; public String toString() &#123; int r = sync.getReadLockCount(); return super.toString() + &quot;[Read locks = &quot; + r + &quot;]&quot;; &#125;&#125; 写锁： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static class WriteLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = -4992448646407690164L; private final Sync sync; protected WriteLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125; public void lock() &#123; sync.acquire(1); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock( ) &#123; return sync.tryWriteLock(); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125; public String toString() &#123; Thread o = sync.getOwner(); return super.toString() + ((o == null) ? &quot;[Unlocked]&quot; : &quot;[Locked by thread &quot; + o.getName() + &quot;]&quot;); &#125; public boolean isHeldByCurrentThread() &#123; return sync.isHeldExclusively(); &#125; public int getHoldCount() &#123; return sync.getWriteHoldCount(); &#125;&#125; 可以看到，读/写锁均包含了Sync对象，首先查看Sync的构造变量： 12345678910111213// 读锁同步状态占用的位数static final int SHARED_SHIFT = 16;// 每次增加读锁同步状态，就相当于增加SHARED_UNITstatic final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);// 读锁或写锁的最大请求数量（包含重入）static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;// 低16位的MASK，用来计算写锁的同步状态static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;// 返回共享锁数static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;// 返回独占锁数static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125; 在ReentrantLock自定义同步器的实现中，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整形变量）上维护多个读线程和一个写线程的状态，那就需要按位切割使用这个状态变量，读写锁将变量切分成两部分，高16位表示读，低16位表示写，划分方式如下： 当前同步状态表示一个线程已经获取了写锁，且重进入了3次，同时也连续获取了2次读锁。同步状态是通过位运算进行更新的，假设当前同步状态是S，写状态等于S &amp; EXCLUSIVE_MASK，即S &amp; 0x0000FFFF，读状态等于S &gt;&gt;&gt; 16.当写状态加1时，等于S+1，当读状态加1时，等于S+SHARED_UNIT，即S+(1 &lt;&lt; 16)，也就是S + 0x00010000。 即读锁和写锁的状态获取和设置如下： 读锁状态的获取：S &gt;&gt; 16 读锁状态的增加：S + (1 &lt;&lt; 16) 写锁状态的获取：S &amp; 0x0000FFFF 写锁状态的增加：S + 1 Sync类内部存在两个内部类，分别为HoldCounter和ThreadLocalHoldCounter，其中HoldCounter主要与读锁配套使用，其中，HoldCounter源码如下: 12345678// 计数器static final class HoldCounter &#123; // 计数 int count = 0; // Use id, not reference, to avoid garbage retention // 获取当前线程的TID属性的值 final long tid = getThreadId(Thread.currentThread());&#125; 说明：HoldCounter主要有两个属性，count和tid，其中count表示某个读线程重入的次数，tid表示该线程的tid字段的值，该字段可以用来唯一标识一个线程。ThreadLocalHoldCounter的源码如下: 12345678// 本地线程计数器static final class ThreadLocalHoldCounter extends ThreadLocal&lt;HoldCounter&gt; &#123; // 重写初始化方法，在没有进行set的情况下，获取的都是该HoldCounter值 public HoldCounter initialValue() &#123; return new HoldCounter(); &#125;&#125; 说明：ThreadLocalHoldCounter重写了ThreadLocal的initialValue方法，ThreadLocal类可以将线程与对象相关联。在没有进行set的情况下，get到的均是initialValue方法里面生成的那个HolderCounter对象。 Sync类继承自AQS，实现了锁的获取和释放方法。 写锁的获取及释放WriteLock类中的lock和unlock方法： 1234567public void lock() &#123; sync.acquire(1);&#125;public void unlock() &#123; sync.release(1);&#125; 可以看到就是调用的独占式同步状态的获取与释放，因此真实的实现就是Sync的tryAcquire和tryRelease。 跟进tryAcquire： 12345678910111213141516171819202122232425262728293031323334protected final boolean tryAcquire(int acquires) &#123; //当前线程 Thread current = Thread.currentThread(); //获取状态 int c = getState(); //写线程数量（即获取独占锁的重入数） int w = exclusiveCount(c); //当前同步状态state != 0，说明已经有其他线程获取了读锁或写锁 if (c != 0) &#123; // 当前state不为0，此时：如果写锁状态为0说明读锁此时被占用返回false； // 如果写锁状态不为0且写锁没有被当前线程持有返回false if (w == 0 || current != getExclusiveOwnerThread()) return false; //判断同一线程获取写锁是否超过最大次数（65535），支持可重入 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); //更新状态 //此时当前线程已持有写锁，现在是重入，所以只需要修改锁的数量即可。 setState(c + acquires); return true; &#125; //到这里说明此时c=0,读锁和写锁都没有被获取 //writerShouldBlock表示是否阻塞 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; //设置锁为当前线程所有 setExclusiveOwnerThread(current); return true;&#125; 基本流程如下图： 跟进tryRelease: 12345678910111213141516protected final boolean tryRelease(int releases) &#123; //若锁的持有者不是当前线程，抛出异常 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //写锁的新线程数 int nextc = getState() - releases; //如果独占模式重入数为0了，说明独占模式被释放 boolean free = exclusiveCount(nextc) == 0; if (free) //若写锁的新线程数为0，则将锁的持有者设置为null setExclusiveOwnerThread(null); //设置写锁的新线程数 //不管独占模式是否被释放，更新独占重入数 setState(nextc); return free;&#125; 写锁的释放过程还是相对而言比较简单的：首先查看当前线程是否为写锁的持有者，如果不是抛出异常。然后检查释放后写锁的线程数是否为0，如果为0则表示写锁空闲了，释放锁资源将锁的持有线程设置为null，否则释放仅仅只是一次重入锁而已，并不能将写锁的线程清空。 读锁的获取与释放类似于写锁，读锁的lock和unlock的实际实现对应Sync的tryAcquireShared和tryReleaseShared方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647protected final int tryAcquireShared(int unused) &#123; // 获取当前线程 Thread current = Thread.currentThread(); // 获取状态 int c = getState(); //如果写锁线程数 != 0 ，且独占锁不是当前线程则返回失败，因为存在锁降级 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 读锁数量 int r = sharedCount(c); /* * readerShouldBlock():读锁是否需要等待（公平锁原则） * r &lt; MAX_COUNT：持有线程小于最大数（65535） * compareAndSetState(c, c + SHARED_UNIT)：设置读取锁状态 */ // 读线程是否应该被阻塞、并且小于最大值、并且比较设置成功 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; //r == 0，表示第一个读锁线程，第一个读锁firstRead是不会加入到readHolds中 if (r == 0) &#123; // 读锁数量为0 // 设置第一个读线程 firstReader = current; // 读线程占用的资源数为1 firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; // 当前线程为第一个读线程，表示第一个读锁线程重入 // 占用资源数加1 firstReaderHoldCount++; &#125; else &#123; // 读锁数量不为0并且不为当前线程 // 获取计数器 HoldCounter rh = cachedHoldCounter; // 计数器为空或者计数器的tid不为当前正在运行的线程的tid if (rh == null || rh.tid != getThreadId(current)) // 获取当前线程对应的计数器 cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) // 计数为0 //加入到readHolds中 readHolds.set(rh); //计数+1 rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 其中sharedCount方法表示占有读锁的线程数量，源码如下： 1static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125; 说明：直接将state右移16位，就可以得到读锁的线程数量，因为state的高16位表示读锁，对应的第十六位表示写锁数量。 读锁获取锁的过程比写锁稍微复杂些，首先判断写锁是否为0并且当前线程不占有独占锁，直接返回；否则，判断读线程是否需要被阻塞并且读锁数量是否小于最大值并且比较设置状态成功，若当前没有读锁，则设置第一个读线程firstReader和firstReaderHoldCount；若当前线程线程为第一个读线程，则增加firstReaderHoldCount；否则，将设置当前线程对应的HoldCounter对象的值。流程图如下: 读锁的释放，tryReleaseShared方法: 1234567891011121314151617181920212223242526272829303132333435363738protected final boolean tryReleaseShared(int unused) &#123; // 获取当前线程 Thread current = Thread.currentThread(); if (firstReader == current) &#123; // 当前线程为第一个读线程 // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) // 读线程占用的资源数为1 firstReader = null; else // 减少占用的资源 firstReaderHoldCount--; &#125; else &#123; // 当前线程不为第一个读线程 // 获取缓存的计数器 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) // 计数器为空或者计数器的tid不为当前正在运行的线程的tid // 获取当前线程对应的计数器 rh = readHolds.get(); // 获取计数 int count = rh.count; if (count &lt;= 1) &#123; // 计数小于等于1 // 移除 readHolds.remove(); if (count &lt;= 0) // 计数小于等于0，抛出异常 throw unmatchedUnlockException(); &#125; // 减少计数 --rh.count; &#125; for (;;) &#123; // 无限循环 // 获取状态 int c = getState(); // 获取状态 int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // 比较并进行设置 // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; &#125;&#125; 说明：此方法表示读锁线程释放锁。首先判断当前线程是否为第一个读线程firstReader，若是，则判断第一个读线程占有的资源数firstReaderHoldCount是否为1，若是，则设置第一个读线程firstReader为空，否则，将第一个读线程占有的资源数firstReaderHoldCount减1；若当前线程不是第一个读线程，那么首先会获取缓存计数器（上一个读锁线程对应的计数器 ），若计数器为空或者tid不等于当前线程的tid值，则获取当前线程的计数器，如果计数器的计数count小于等于1，则移除当前线程对应的计数器，如果计数器的计数count小于等于0，则抛出异常，之后再减少计数即可。无论何种情况，都会进入无限循环，该循环可以确保成功设置状态state。其流程图如下: 在读锁的获取、释放过程中，总是会有一个对象存在着，同时该对象在获取线程获取读锁是+1，释放读锁时-1，该对象就是HoldCounter。 要明白HoldCounter就要先明白读锁。前面提过读锁的内在实现机制就是共享锁，对于共享锁其实我们可以稍微的认为它不是一个锁的概念，它更加像一个计数器的概念。一次共享锁操作就相当于一次计数器的操作，获取共享锁计数器+1，释放共享锁计数器-1。只有当线程获取共享锁后才能对共享锁进行释放、重入操作。所以HoldCounter的作用就是当前线程持有共享锁的数量，这个数量必须要与线程绑定在一起，否则操作其他线程锁就会抛出异常。 先看读锁获取锁的部分： 1234567891011121314if (r == 0) &#123;//r == 0，表示第一个读锁线程，第一个读锁firstRead是不会加入到readHolds中 firstReader = current; firstReaderHoldCount = 1;&#125; else if (firstReader == current) &#123;//第一个读锁线程重入 firstReaderHoldCount++; &#125; else &#123; //非firstReader计数 HoldCounter rh = cachedHoldCounter;//readHoldCounter缓存 //rh == null 或者 rh.tid != current.getId()，需要获取rh if (rh == null || rh.tid != current.getId()) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); //加入到readHolds中 rh.count++; //计数+1&#125; 这里为什么要搞一个firstRead、firstReaderHoldCount呢？而不是直接使用else那段代码？这是为了一个效率问题，firstReader是不会放入到readHolds中的，如果读锁仅有一个的情况下就会避免查找readHolds。可能就看这个代码还不是很理解HoldCounter。我们先看firstReader、firstReaderHoldCount的定义： 12private transient Thread firstReader = null;private transient int firstReaderHoldCount; 这两个变量比较简单，一个表示线程，当然该线程是一个特殊的线程，一个是firstReader的重入计数。 故而，HoldCounter应该就是绑定线程上的一个计数器，而ThradLocalHoldCounter则是线程绑定的ThreadLocal。从上面我们可以看到ThreadLocal将HoldCounter绑定到当前线程上，同时HoldCounter也持有线程Id，这样在释放锁的时候才能知道ReadWriteLock里面缓存的上一个读取线程（cachedHoldCounter）是否是当前线程。这样做的好处是可以减少ThreadLocal.get()的次数，因为这也是一个耗时操作。需要说明的是这样HoldCounter绑定线程id而不绑定线程对象的原因是避免HoldCounter和ThreadLocal互相绑定而GC难以释放它们（尽管GC能够智能的发现这种引用而回收它们，但是这需要一定的代价），所以其实这样做只是为了帮助GC快速回收对象而已。 参考文献： https://www.cnblogs.com/dolphin0520/p/3923737.html https://www.cnblogs.com/shixm/p/5490026.html https://www.cnblogs.com/xiaoxi/p/9140541.html 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的锁机制--Lock接口]]></title>
    <url>%2F2019%2F05%2F20%2FJava%E7%9A%84%E9%94%81%E6%9C%BA%E5%88%B6--Lock%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[synchronized关键字虽然可以解决大部分多线程锁的问题，但是仍旧存在下述问题： 假如持有锁的某线程因等待长时IO或者其他原因阻塞，其他等待的线程无法响应中断，只能不断等待； 多线程下只有读操作是不会发生冲突的，但synchronized关键字对读和写操作均一视同仁，所以当一个线程进行读取操作时，其他线程只能不断等待； 使用synchronized关键字无法确认线程是否成功获取到锁。 针对上述问题，Doug Lea李大爷实现了一套更加灵活的Java锁机制，即J.U.C的locks包。 下面，我们打开locks包，看看有啥好东西吧。 首先看一下Lock接口： LockLock有下述6个方法，主要分为三大类: 获取锁的方法，分别为lock()、lockInterruptibly()、tryLock()、tryLock(long, TimeUnit); 释放锁的方法，unlock(); 线程协作相关的方法，newCondition()。 synchronsized关键字不需要用户手动释放锁，当synchronized修饰的方法或代码块执行完毕后，系统会自动让线程释放对锁的占用。 与synchronsized关键字不同的是，Lock必须由用户手动执行加锁/释放锁操作，当持有锁的线程发生异常时，该线程不会自动释放锁，可能会导致死锁，故Lock必须在try{}catch{}块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生。 12345678910111213// 初始化锁对象Lock lock = ...;// 加锁操作lock.lock();try&#123; // 执行相应任务 doSomething();&#125;catch(Exception e)&#123; // 处理异常&#125;finally&#123; // 释放锁 lock.unlock();&#125; 与lock()不同的是，tryLock()是由返回值的，获取到锁则返回true，否则返回false，tryLock(long, TimeUnit)为其重载方法，表示获取不到锁之后会等待一定时间，如果在时间期限内获取到锁，则返回true，否则返回false。 lockInterruptibly()方法，当线程获取不到锁，在等待的过程中是可以响应中断的。 不过需要注意的是，通过lockInterruptibly()方法获取到锁的线程，在运行过程中是不能响应中断的，仅是做一个中断标记，待释放锁之后再响应中断。 ReentrantLockJ.U.C包中Lock接口的实现类主要有5个： 除了ReentrantLock外，其他均为其他类的内部类，ReentrantLock除了实现了Lock的接口方法外，还提供了更多的方法： lock()首先看ReentrantLock如何实现Lock接口的lock()方法： 123public void lock() &#123; sync.lock();&#125; 调用的是抽象内部类Sync的lock()方法： 123abstract static class Sync extends AbstractQueuedSynchronizer &#123; abstract void lock(); ...... 既然Sync的lock()方法声明为abstract，则必定有Sync的子类来实现该方法。 ReentrantLock的内部类FairSync、NonfairSync最终实现了lock()方法。 顾名思义，FairSync、NonfairSync分别实现了公平锁和非公平锁，ReentrantLock默认构建的是非公平锁。 12345678public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; // 若fair为true则构建公平锁 sync = fair ? new FairSync() : new NonfairSync();&#125; 公平锁即尽量以请求锁的顺序来获取锁。比如同时有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该锁。 非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。 在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。 下面以NonfairSync为例： 123456789101112131415static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else // 调用AQS的acquire()模板方法 acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 可以看到，NonfairSync调用AQS的acquire(1)方法来实现获取锁操作： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; AQS把acquireQueued()、addWaiter()等相关同步逻辑的方法均实现好了，但是tryAcquire()还需要子类来实现。 ReenTrantLock的内部抽象类Sync实现了AQS非公平的tryAcquire(int)方法，即nonfairTryAcquire(int)： 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; 神奇的是，公平版的tryAcquire(int)方法实现却又不在Sync中，Doug Lea将其放在Sync的子类FairSync中实现。 12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; 可以发现，公平模式和非公平模式下的代码高度相似，只不过是在c == 0的情况下多了一次!hasQueuedPredecessors()过程(hasQueuedPredecessors是AQS的方法)。 其实，类似这样的绕来绕去，Doug Lea在AQS独占和共享模式下响应线程中断的相关代码里也玩过一次，至于为啥，小菜鸟不敢妄猜大佬的想法(主要是怕猜错了，以后被打脸，哈哈)。 最后，总结一下ReenTrantLock的lock()方法： ReenTrantLock的lock()方法是通过其内部抽象类Sync的lock()方法来实现的； Sync没有直接实现lock()方法，由其方法实现由ReentrantLock的内部类FairSync、NonfairSync来完成; Sync继承自AQS，而FairSync、NonfairSync又继承了Sync，故Sync、FairSync、NonfairSync均是AQS的子类； FairSync、NonfairSync的lock()方法是调用AQS的acquire(1)来实现的，AQS的acquire(int)方法又涉及到tryAcquire(int)方法，但是AQS没有实现tryAcquire(int)方法，是由其子类来实现的。 unlock()接着看ReenTrantLock的unlock()方法: 123public void unlock() &#123; sync.release(1);&#125; 调用的是内部抽象类Sync的release(1)方法: 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 主要涉及到tryRelease(int)和unparkSuccessor(Node)方法，AQS直接实现了unparkSuccessor(Node)方法，但只声明了tryRelease(int)方法，说明实现是交给Sync来完成的，果不其然，在Sync中找到了该方法， 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 可以看出，ReenTrantLock的unlock()与lock()一样，均是基于AQS来实现的。 同时，通过lock()和unlock()的相关实现代码，我们发现ReentrantLock与synchronized一样，是可重入锁。 tryLock()123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; 可以发现，tryLock()调用的是Sync的nonfairTryAcquire(int)方法，本质上只使用了AQS的tryAcquire(int)方法，回顾lock()，其依赖的是AQS的acquire(int)方法： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 相当于，tryLock()只走了tryAcquire()这一步，直接尝试获取锁，获取到则返回true，否则返回false；而lock()方法若第一步没有获取锁，则需要继续执行addWaiter、acquireQueued、selfInterrupt等方法。 tryLock(long, TimeUnit)1234public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125; 可以看到，tryLock(long, TimeUnit)调用的是内部抽象类Sync的tryAcquireNanos方法: 1234567public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125; 最终执行的是AQS的doAcquireNanos方法： 123456789101112131415161718192021222324252627282930private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; lockInterruptibly()123public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125; 调用的仍旧是内部抽象类Sync的方法，acquireInterruptibly(int)方法如下： 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125; 最终调用的是AQS的doAcquireInterruptibly(int)方法。 至于newCondition()方法的实现，我会在讲解线程协作的时候具体讲解，此处不再赘述。 至此，我们就把ReentrantLock如何实现Lock()接口讲解完毕了，可以发现，其各个方法的实现均强依赖AQS，所以，各位小伙伴想将ReentrantLock彻底征服，一定要将AQS吃透呀，哈哈。 跟完了源码，下面分享一下如何使用Lock。 如何使用Lock对引言中的程序通过Lock来进行改造： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class CountWithLock &#123; private volatile static int count = 0; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); Lock lock = new ReentrantLock(); // 启动线程A new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; lock.lock(); try&#123; count++; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // 启动线程B new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; lock.lock(); try&#123; count++; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // main线程等待线程A和B计算完毕 countDownLatch.await(); // main线程打印结果 System.out.println(&quot;count: &quot; + CountWithLock.count); &#125;&#125; 多次运行该程序，其结果均是: 123count: 200000Process finished with exit code 0 接着测试一下lockInterruptibly()： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class LockInterruptTest &#123; // 线程工具，用于中断等待的线程 static class ThreadUtil extends Thread&#123; private Thread thread; public ThreadUtil(Thread thread) &#123; this.thread = thread; &#125; @Override public void run() &#123; // 3秒后中断传入的线程 try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread.interrupt(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; // 创建Lock final Lock lock = new ReentrantLock(); lock.lock(); // 主线程休眠1秒，保证主线程在子线程之前获取到锁 Thread.sleep(1000); System.out.println(&quot;主线程获取到锁&quot;); // 创建子线程 Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; long start = System.currentTimeMillis(); try &#123; System.out.println(Thread.currentThread().getName() + &quot; 启动&quot;); lock.lockInterruptibly(); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getName() + &quot; interrupted&quot;); &#125; long end = System.currentTimeMillis(); long use_time = (end - start) / 1000; System.out.println(Thread.currentThread().getName() + &quot; 等待了&quot; + use_time + &quot;秒&quot;); &#125; &#125;); t1.start(); // 3秒后中断等待的子线程t1 new ThreadUtil(t1).start(); System.out.println(&quot;主线程即将进行1000秒的IO操作&quot;); Thread.sleep(1000000); &#125;&#125; 输出结果为: 12345主线程获取到锁主线程即将进行1000秒的IO操作Thread-0 启动Thread-0 interruptedThread-0 等待了3秒 可以看出，lockInterruptibly()方法可以使等待获取锁的线程响应中断，避免长时等待。 上述程序如果采用lock()方法，则等待线程是不会响应中断的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class LockInterruptTest &#123; // 线程工具，用于中断等待的线程 static class ThreadUtil extends Thread&#123; private Thread thread; public ThreadUtil(Thread thread) &#123; this.thread = thread; &#125; @Override public void run() &#123; // 3秒后中断传入的线程 try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread.interrupt(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; // 创建Lock final Lock lock = new ReentrantLock(); lock.lock(); // 主线程休眠1秒，保证主线程在子线程之前获取到锁 Thread.sleep(1000); System.out.println(&quot;主线程获取到锁&quot;); // 创建子线程 Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; long start = System.currentTimeMillis(); try &#123; System.out.println(Thread.currentThread().getName() + &quot; 启动&quot;); lock.lock(); &#125; catch (Exception e) &#123; System.out.println(Thread.currentThread().getName() + &quot; interrupted&quot;); &#125; long end = System.currentTimeMillis(); long use_time = (end - start) / 1000; System.out.println(Thread.currentThread().getName() + &quot; 等待了&quot; + use_time + &quot;秒&quot;); &#125; &#125;); t1.start(); // 3秒后中断等待的子线程t1 new ThreadUtil(t1).start(); System.out.println(&quot;主线程即将进行1000秒的IO操作&quot;); Thread.sleep(1000000); &#125;&#125; 等待3秒之后，结果为： 123主线程获取到锁主线程即将进行1000秒的IO操作Thread-0 启动 说明等待获取锁的线程是不会响应中断。 参考文献： https://www.cnblogs.com/dolphin0520/p/3923737.html https://www.cnblogs.com/shixm/p/5490026.html https://www.cnblogs.com/xiaoxi/p/9140541.html 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的锁机制--synchronsized关键字]]></title>
    <url>%2F2019%2F05%2F20%2FJava%E7%9A%84%E9%94%81%E6%9C%BA%E5%88%B6--synchronsized%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[引言高并发环境下，多线程可能需要同时访问一个资源，并交替执行非原子性的操作，很容易出现最终结果与期望值相违背的情况，或者直接引发程序错误。 举个简单示例，存在一个初始静态变量count=0，两个线程分别对count进行100000次加1操作，期望的结果是200000，实际是这样的吗？写个程序跑下看看： 1234567891011121314151617181920212223242526272829303132333435363738public class CountWithoutSyn &#123; private volatile static int count = 0; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); // 启动线程A new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; count++; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // 启动线程B new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; count++; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // main线程等待线程A和B计算完毕 countDownLatch.await(); // main线程打印结果 System.out.println(&quot;count: &quot; + CountWithoutSyn.count); &#125;&#125; 多次运行上述程序，会发现最终结果可能出现不是200000的情况，如： 123count: 150218Process finished with exit code 0 之所以出现这种情况的原因是，count++不是一个原子性的操作，所谓原子性，说的就是操作不可分割。 count++分为3个步骤： 从内存读取count的值； 对count值执行+1操作； 将count的值写回内存； 比如当前count累加到了101，此时，线程A和B同时拿到了count的值为101，线程A对count加1后将102写回内存，同时线程B也对count加1后将102写回内存，而实际结果应该为103，所以丢失了1次更新。 故高并发环境下，多线程同时对共享变量执行非原子的操作，很容易出现丢失更新的问题。 解决办法很简单，将整个非原子的操作加锁，从而变成原子性的操作就可以了。 Java加锁的方式主要有2种，synchronnized关键字和Lock接口。 下面分别阐述这两种方式，本文先讲解synchronnized。 synchronized在Java中，每一个对象都有一个锁标记(monitor)，也称之为监视器，多线程同时访问某个对象时，线程只有获取了该对象的锁才能访问。 该锁属于典型的互斥锁，即一旦一个线程获取到锁之后，其他线程只能等待。 synchronize关键字可以标记方法或者代码块，当某个线程调用该对象的synchronize方法或者访问synchronize代码块时，该线程便获得了该对象的锁，其他线程暂时无法访问这个方法，只有等待这个方法执行完毕或者代码块执行完毕，该线程才会释放该对象的锁，其他线程才能执行这个方法或者代码块。 对引言中的程序通过synchronized来进行改造： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class CountWithSyn &#123; private volatile static int count = 0; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); Object lock = new Object(); // 启动线程A new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock)&#123; for(int i=0; i&lt;100000; i++)&#123; count++; &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // 启动线程B new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock)&#123; for(int i=0; i&lt;100000; i++)&#123; count++; &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // main线程等待线程A和B计算完毕 countDownLatch.await(); // main线程打印结果 System.out.println(&quot;count: &quot; + CountWithSyn.count); &#125;&#125; 多次运行该程序，其结果均是: 123count: 200000Process finished with exit code 0 synchronized代码块使用起来比synchronized方法要灵活得多。因为也许一个方法中只有一部分代码只需要同步，如果此时对整个方法用synchronized进行同步，会影响程序执行效率。而使用synchronized代码块就可以避免这个问题，synchronized代码块可以实现只对需要同步的地方进行同步。 因为上述程序的非原子操作仅是count++，所以synchronized仅修饰count++即可实现线程安全。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class CountWithSyn &#123; private volatile static int count = 0; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); Object lock = new Object(); // 启动线程A new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; synchronized (lock)&#123; count++; &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // 启动线程B new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i=0; i&lt;100000; i++)&#123; synchronized (lock)&#123; count++; &#125; &#125; countDownLatch.countDown(); &#125; &#125;).start(); // main线程等待线程A和B计算完毕 countDownLatch.await(); // main线程打印结果 System.out.println(&quot;count: &quot; + CountWithSyn.count); &#125;&#125; 需要注意的是： 当一个线程正在访问一个对象的synchronized方法，那么其他线程不能访问该对象的其他synchronized方法。这个原因很简单，因为一个对象只有一把锁，当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的其他synchronized方法。 当一个线程正在访问一个对象的synchronized方法，那么其他线程能访问该对象的非synchronized方法。这个原因很简单，访问非synchronized方法不需要获得该对象的锁，假如一个方法没用synchronized关键字修饰，说明它不会使用到临界资源，那么其他线程是可以访问这个方法的， 如果一个线程A需要访问对象object1的synchronized方法fun1，另外一个线程B需要访问对象object2的synchronized方法fun1，即使object1和object2是同一类型），也不会产生线程安全问题，因为他们访问的是不同的对象，所以不存在互斥问题。 那么，synchronized关键字底层是如何实现的呢？反编译它的字节码看一下，如下述代码的字节码为： 123456789101112131415161718public class SynCode &#123; private Object lock = new Object(); public void method1()&#123; synchronized (lock)&#123; &#125; &#125; public synchronized void method2()&#123; &#125; public void method3()&#123; &#125;&#125; 从反编译获得的字节码可以看出，synchronized代码块实际上多了monitorenter和monitorexit两条指令。monitorenter指令执行时会让对象的锁计数加1，而monitorexit指令执行时会让对象的锁计数减1，其实这个与操作系统里面的PV操作很像，操作系统里面的PV操作就是用来控制多个线程对临界资源的访问。 对于synchronized方法，执行中的线程识别该方法的method_info结构是否有ACC_SYNCHRONIZED标记设置，然后它自动获取对象的锁，调用方法，最后释放锁。如果有异常发生，线程自动释放锁。 对于synchronized方法或者synchronized代码块，当出现异常时，JVM会自动释放当前线程占用的锁，因此不会由于异常导致出现死锁现象。 参考文献： https://www.cnblogs.com/dolphin0520/p/3923737.html https://www.cnblogs.com/shixm/p/5490026.html https://www.cnblogs.com/xiaoxi/p/9140541.html 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈线程间的协作机制]]></title>
    <url>%2F2019%2F05%2F07%2F%E6%B5%85%E8%B0%88%E7%BA%BF%E7%A8%8B%E9%97%B4%E7%9A%84%E5%8D%8F%E4%BD%9C%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[注意：如无特殊说明，本文源码分析基于的Java JDK版本均为1.8。 等待/通知机制假设这样的情景，只要线程A修改了某值value，则线程B则对新的value值进行某些操作，比较容易想到的方法是，线程B不断循环访问value，一旦感知到变化，则执行相应逻辑。 123456789// 线程Aset value = newValue// 线程Bfor(;;)&#123; while(newValue != oldValue)&#123; doSomething(newValue); &#125;&#125; 如果value值发生变化的频率较低，则线程B不断自旋获取value的值，过多的无效尝试极大地浪费系统处理资源。 改进的方法是，每一段时间(如1s)去访问一下： 1234567891011121314// 线程Aset value = newValue// 线程Bfor(;;)&#123; while(newValue != oldValue)&#123; doSomething(newValue); &#125; try &#123; Thread.sleep(1000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 改进后，较少了较多的无效尝试，降低了对处理器资源的浪费，但是休眠时间的大小难以确定： 休眠时间太大，不能在休眠期间及时感知数据的变化，实时性较差； 休眠时间过小，实时性提高的同时，增加了无效尝试的次数，造成了系统处理资源的浪费。 考虑到上述监听机制上述的困境，线程间协作采用的是等待/通知机制。 原理就是，当线程A完成对数据的修改之后，会通过一定的机制通知线程B来获取新的数据值来进行相关业务处理，线程B处理完之后挂起等待后续线程A的通知。 等待/通知机制是所有Java对象均具备的，因为相关方法是定义在所有对象的超类java.lang.Object上的。 相关方法描述如下： 方法名称 描述 notify() 通知一个在对象上等待的线程，使其从wait()返回，而返回的前提是该线程获取到对象的锁 notifyAll() 通知所有等待在该对象上的线程 wait() 调用wait()方法后，会释放对象的锁，并进入WAITING状态 wait(long) 超时等待一段时间，如果没有通知就超时返回 wait(long, int) 超时时间更细粒度的控制，可以达到毫秒 wait()/notify()入门实例1234567891011121314151617181920212223242526272829303132333435363738394041424344public class WaitAndNotifyDemo &#123; public static void main(String[] args) &#123; Object lock = new Object(); // 线程A new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;线程A等待获取锁&quot;); synchronized (lock) &#123; try &#123; System.out.println(&quot;线程A获取锁&quot;); Thread.sleep(3000); System.out.println(&quot;线程A将要运行wait()进入等待&quot;); lock.wait(); System.out.println(&quot;线程A等待结束&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); // 线程B new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;线程B等待获取锁&quot;); synchronized (lock) &#123; try &#123; System.out.println(&quot;线程B获取锁&quot;); Thread.sleep(3000); System.out.println(&quot;线程B将要运行notify()唤醒其他wait状态的线程&quot;); lock.notify(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125;&#125; 运行结果为： 123456789线程A等待获取锁线程A获取锁线程B等待获取锁线程A将要运行wait()进入等待线程B获取锁线程B将要运行notify()唤醒其他wait状态的线程线程A等待结束Process finished with exit code 0 需要注意的是：Thread的sleep()方法仅是让出CPU时间片，让其他线程有机会执行，但是sleep()方法不会释放其持有的对象锁，仅当调用对象的wait()方法才会释放对象锁。 wait()方法进入到Object的wait()方法： 123public final void wait() throws InterruptedException &#123; wait(0);&#125; 可以看出，其底层调用的是Object的重载方法wait(long): 1public final native void wait(long timeout) throws InterruptedException; 重载方法wait(long)是native方法，方法实现可通过OpenJDK来查看(Object.c)来找到： 1234567static JNINativeMethod methods[] = &#123; &#123;&quot;hashCode&quot;, &quot;()I&quot;, (void *)&amp;JVM_IHashCode&#125;, &#123;&quot;wait&quot;, &quot;(J)V&quot;, (void *)&amp;JVM_MonitorWait&#125;, &#123;&quot;notify&quot;, &quot;()V&quot;, (void *)&amp;JVM_MonitorNotify&#125;, &#123;&quot;notifyAll&quot;, &quot;()V&quot;, (void *)&amp;JVM_MonitorNotifyAll&#125;, &#123;&quot;clone&quot;, &quot;()Ljava/lang/Object;&quot;, (void *)&amp;JVM_Clone&#125;,&#125;; 其中，JVM_MonitorWait和JVM_MonitorNotify分别对应于wait()和notify()方法，JVM_MonitorWait方法声明是在jvm.h中，如下所示： 12JNIEXPORT void JNICALLJVM_MonitorWait(JNIEnv *env, jobject obj, jlong ms); 方法实现为: 12345678910JVM_ENTRY(void, JVM_MonitorWait(JNIEnv* env, jobject handle, jlong ms)) JVMWrapper(&quot;JVM_MonitorWait&quot;); Handle obj(THREAD, JNIHandles::resolve_non_null(handle)); assert(obj-&gt;is_instance() || obj-&gt;is_array(), &quot;JVM_MonitorWait must apply to an object&quot;); JavaThreadInObjectWaitState jtiows(thread, ms != 0); if (JvmtiExport::should_post_monitor_wait()) &#123; JvmtiExport::post_monitor_wait((JavaThread *)THREAD, (oop)obj(), ms); &#125; ObjectSynchronizer::wait(obj, ms, CHECK);JVM_END JVM_MonitorWait方法最终调用了ObjectSynchronizer的wait方法: 123456789101112131415161718void ObjectSynchronizer::wait(Handle obj, jlong millis, TRAPS) &#123; if (UseBiasedLocking) &#123; BiasedLocking::revoke_and_rebias(obj, false, THREAD); assert(!obj-&gt;mark()-&gt;has_bias_pattern(), &quot;biases should be revoked by now&quot;); &#125; if (millis &lt; 0) &#123; TEVENT (wait - throw IAX) ; THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), &quot;timeout value is negative&quot;); &#125; ObjectMonitor* monitor = ObjectSynchronizer::inflate(THREAD, obj()); DTRACE_MONITOR_WAIT_PROBE(monitor, obj(), THREAD, millis); monitor-&gt;wait(millis, true, THREAD); /* This dummy call is in place to get around dtrace bug 6254741. Once that&apos;s fixed we can uncomment the following line and remove the call */ // DTRACE_MONITOR_PROBE(waited, monitor, obj(), THREAD); dtrace_waited_probe(monitor, obj, THREAD);&#125; 最终，是通过调用ObjectMonitor的wait()方法来实现等待的，其主要代码如下: 1234567891011121314151617181920212223242526272829303132333435363738void ObjectMonitor::wait(jlong millis, bool interruptible, TRAPS) &#123; ... // create a node to be put into the queue // Critically, after we reset() the event but prior to park(), we must check // for a pending interrupt. ObjectWaiter node(Self); node.TState = ObjectWaiter::TS_WAIT ; Self-&gt;_ParkEvent-&gt;reset() ; OrderAccess::fence(); // ST into Event; membar ; LD interrupted-flag // Enter the waiting queue, which is a circular doubly linked list in this case // but it could be a priority queue or any data structure. // _WaitSetLock protects the wait queue. Normally the wait queue is accessed only // by the the owner of the monitor *except* in the case where park() // returns because of a timeout of interrupt. Contention is exceptionally rare // so we use a simple spin-lock instead of a heavier-weight blocking lock. Thread::SpinAcquire (&amp;_WaitSetLock, &quot;WaitSet - add&quot;) ; AddWaiter (&amp;node) ; Thread::SpinRelease (&amp;_WaitSetLock) ; if ((SyncFlags &amp; 4) == 0) &#123; _Responsible = NULL ; &#125; intptr_t save = _recursions; // record the old recursion count _waiters++; // increment the number of waiters _recursions = 0; // set the recursion level to be 1 exit (Self) ; // exit the monitor guarantee (_owner != Self, &quot;invariant&quot;) ; ... if (node._notified != 0 &amp;&amp; _succ == Self) &#123; node._event-&gt;unpark(); &#125; // The thread is on the WaitSet list - now park() it. ...&#125; 整个调用链路可以总结如下： 1Object.wait()--&gt;Object.wait(long)--&gt;JVM_MonitorWait--&gt;ObjectSynchronizer::wait--&gt;ObjectMonitor::wait 说明对象的Object最终调用的是底层native方法ObjectMonitor::wait，下面介绍一下ObjectMonitor::wait的基本步骤： 将调用wait()方法的线程封装为ObjectWaiter类的对象node； ObjectWriter类声明为： 123456789101112131415161718class ObjectWaiter : public StackObj &#123; public: enum TStates &#123; TS_UNDEF, TS_READY, TS_RUN, TS_WAIT, TS_ENTER, TS_CXQ &#125; ; enum Sorted &#123; PREPEND, APPEND, SORTED &#125; ; ObjectWaiter * volatile _next; ObjectWaiter * volatile _prev; Thread* _thread; ParkEvent * _event; volatile int _notified ; volatile TStates TState ; Sorted _Sorted ; // List placement disposition bool _active ; // Contention monitoring is enabled public: ObjectWaiter(Thread* thread); void wait_reenter_begin(ObjectMonitor *mon); void wait_reenter_end(ObjectMonitor *mon);&#125;; 可以看出，ObjectWaiter是双向链表结构，保存了当前线程_thread及当前的状态TState等数据，每个等待锁的线程都会被封装成ObjectWaiter对象。 通过ObjectMonitor::AddWaiter方法将node添加到_WaitSet列表中; 12345678910111213141516171819inline void ObjectMonitor::AddWaiter(ObjectWaiter* node) &#123; assert(node != NULL, &quot;should not dequeue NULL node&quot;); assert(node-&gt;_prev == NULL, &quot;node already in list&quot;); assert(node-&gt;_next == NULL, &quot;node already in list&quot;); // put node at end of queue (circular doubly linked list) if (_WaitSet == NULL) &#123; _WaitSet = node; node-&gt;_prev = node; node-&gt;_next = node; &#125; else &#123; ObjectWaiter* head = _WaitSet ; ObjectWaiter* tail = head-&gt;_prev; assert(tail-&gt;_next == head, &quot;invariant check&quot;); tail-&gt;_next = node; head-&gt;_prev = node; node-&gt;_next = head; node-&gt;_prev = tail; &#125;&#125; 调用此方法前后需要获取和释放_WaitSet列表的_WaitSetLock锁。从注释中可以看到，_WaitSet列表其实是一个双向循环链表。 通过ObjectMonitor::exit方法释放当前的ObjectMonitor对象，这样其它竞争线程就可以获取该ObjectMonitor对象; 123456789101112131415161718192021222324252627void ATTR ObjectMonitor::exit(TRAPS) &#123; Thread * Self = THREAD ; if (THREAD != _owner) &#123; if (THREAD-&gt;is_lock_owned((address) _owner)) &#123; // Transmute _owner from a BasicLock pointer to a Thread address. // We don&apos;t need to hold _mutex for this transition. // Non-null to Non-null is safe as long as all readers can // tolerate either flavor. assert (_recursions == 0, &quot;invariant&quot;) ; _owner = THREAD ; _recursions = 0 ; OwnerIsThread = 1 ; &#125; else &#123; // NOTE: we need to handle unbalanced monitor enter/exit // in native code by throwing an exception. // TODO: Throw an IllegalMonitorStateException ? TEVENT (Exit - Throw IMSX) ; assert(false, &quot;Non-balanced monitor enter/exit!&quot;); if (false) &#123; THROW(vmSymbols::java_lang_IllegalMonitorStateException()); &#125; return; &#125; &#125; ...&#125; 最终通过底层的park()方法挂起当前线程。 notify()方法与wait()方法类似，最终也是调用的底层native方法:ObjectMonitor::notify(TRAPS)。 12345678910111213141516171819202122232425262728293031323334353637void ObjectMonitor::notify(TRAPS) &#123; CHECK_OWNER(); if (_WaitSet == NULL) &#123; TEVENT (Empty-Notify) ; return ; &#125; DTRACE_MONITOR_PROBE(notify, this, object(), THREAD); int Policy = Knob_MoveNotifyee ; Thread::SpinAcquire (&amp;_WaitSetLock, &quot;WaitSet - notify&quot;) ; ObjectWaiter * iterator = DequeueWaiter() ; if (iterator != NULL) &#123; TEVENT (Notify1 - Transfer) ; guarantee (iterator-&gt;TState == ObjectWaiter::TS_WAIT, &quot;invariant&quot;) ; guarantee (iterator-&gt;_notified == 0, &quot;invariant&quot;) ; if (Policy != 4) &#123; iterator-&gt;TState = ObjectWaiter::TS_ENTER ; &#125; iterator-&gt;_notified = 1 ; ObjectWaiter * List = _EntryList ; if (List != NULL) &#123; assert (List-&gt;_prev == NULL, &quot;invariant&quot;) ; assert (List-&gt;TState == ObjectWaiter::TS_ENTER, &quot;invariant&quot;) ; assert (List != iterator, &quot;invariant&quot;) ; &#125; if (Policy == 0) &#123; // prepend to EntryList &#125; else if (Policy == 1) &#123; // append to EntryList &#125; else if (Policy == 2) &#123; // prepend to cxq &#125; ...&#125; ObjectMonitor::notify(TRAPS)方法的基本步骤为： 若_WaitSet为NULL，即没有需要唤醒的线程，则直接退出； 通过ObjectMonitor::DequeueWaiter方法，获取_WaitSet列表中的第一个ObjectWaiter节点； 12345678inline ObjectWaiter* ObjectMonitor::DequeueWaiter() &#123; // dequeue the very first waiter ObjectWaiter* waiter = _WaitSet; if (waiter) &#123; DequeueSpecificWaiter(waiter); &#125; return waiter;&#125; 根据不同的策略，将取出来的ObjectWaiter节点，加入到_EntryList或则通过Atomic::cmpxchg_ptr指令进行自旋操作cxq。 notifyAll()方法lock.notifyAll()方法最终通过ObjectMonitor的void notifyAll(TRAPS)实现： 123456789101112131415161718192021222324252627void ObjectMonitor::notifyAll(TRAPS) &#123; ... for (;;) &#123; iterator = DequeueWaiter () ; if (iterator == NULL) break ; TEVENT (NotifyAll - Transfer1) ; ++Tally ; ... ObjectWaiter * List = _EntryList ; if (List != NULL) &#123; assert (List-&gt;_prev == NULL, &quot;invariant&quot;) ; assert (List-&gt;TState == ObjectWaiter::TS_ENTER, &quot;invariant&quot;) ; assert (List != iterator, &quot;invariant&quot;) ; &#125; if (Policy == 0) &#123; // prepend to EntryList &#125; else if (Policy == 1) &#123; // append to EntryList &#125; else if (Policy == 2) &#123; // prepend to cxq &#125; &#125;&#125; 该方法和notify()方法比较类似，不同的是，notifyAll()通过for循环取出_WaitSet的ObjectWaiter节点，并根据不同策略，加入到_EntryList或则进行自旋操作。 小结 wait()方法会释放所占有的ObjectMonitor对象； notify()和notifyAll()并不会释放所占有的ObjectMonitor对象，只是将相应的等待线程从_WaitSet转移到_EntryList中，然后等待竞争锁； 真正释放ObjectMonitor对象的时机是，退出同步代码块或同步方法时，即执行monitorexit指令时； 一旦释放ObjectMonitor对象后，_EntityList中ObjectWaiter节点所保存的线程即可以参与竞争ObjectMonitor对象了； wait()/notify()基本就是C/C++版的AQS(啥是AQS，可参见我的另外一篇文章)。 ConditionCondition出现在JDK1.5中的J.U.C包中，由Doug Lea李大爷操刀设计并开发完成。 Condition是个接口，其方法有： await()方法对应于Object的wait(); signal()方法对应于Object的notify(); signalAll()方法对应于Object的notifyAll(); 像Object的wait()/notify()方法必须在Synchronized中调用类似，Condition的await()/siganl()方法必须在Lock中调用。 Condition接口的实现类是AQS中的ConditionObject。 跟进ConditionObject的源码，查看await()的实现方式： 123456789101112131415161718public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 可以发现，其与ObjectMonitor::wait流程基本类似，都是将当前线程封装成node节点，然后添加到等待队列，最后挂起当前线程。 只不过是ConditionObject实现了Java版的wait()流程，如Object的wait()方法是通过native的park()方法挂起当前线程的，而ConditionObject则使用的则是LockSupport工具类的park()方法。 构建Condition对象可以通过Lock接口创建Condition对象，Lock接口中定义了newCondition()方法: 1Condition newCondition(); 获取方式如下所示: 123Lock lock = new ReentrantLock();Condition c1 = lock.newCondition();Condition c2 = lock.newCondition(); ReentrantLock唯一实现了Lock接口，看一下ReentrantLock的对newCondition()的实现： 123public Condition newCondition() &#123; return sync.newCondition();&#125; 发现调用的是内部类的sync的newCondition()方法: 123final ConditionObject newCondition() &#123; return new ConditionObject();&#125; 可以发现，最终创建的就是AQS中的ConditionObject，由其实现Condition接口的各个方法。 实例下面，我们通过Condition的await()/signal()来完成一个小Demo: 首先定义一个服务MyService: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class MyService &#123; // 实例化一个ReentrantLock对象 private ReentrantLock lock = new ReentrantLock(); // 为线程A注册一个Condition public Condition conditionA = lock.newCondition(); // 为线程B注册一个Condition public Condition conditionB = lock.newCondition(); public void awitA()&#123; try&#123; lock.lock(); System.out.println(Thread.currentThread().getName() + &quot;进入了awitA方法&quot;); long timeBefore = System.currentTimeMillis(); // 执行condition等待 conditionA.await(); long timeAfter = System.currentTimeMillis(); System.out.println(Thread.currentThread().getName() + &quot;等待了：&quot; + (timeAfter-timeBefore)/1000 + &quot; s&quot;); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void awitB()&#123; try&#123; lock.lock(); System.out.println(Thread.currentThread().getName() + &quot;进入了awitB方法&quot;); long timeBefore = System.currentTimeMillis(); // 执行condition等待 conditionB.await(); long timeAfter = System.currentTimeMillis(); System.out.println(Thread.currentThread().getName() + &quot;等待了：&quot; + (timeAfter-timeBefore)/1000 + &quot; s&quot;); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void signallA()&#123; try&#123; lock.lock(); System.out.println(&quot;启动唤醒程序&quot;); // 唤醒所有注册conditionA的线程 conditionA.signalAll(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void signallB()&#123; try&#123; lock.lock(); System.out.println(&quot;启动唤醒程序&quot;); // 唤醒所有注册conditionB的线程 conditionB.signalAll(); &#125;finally &#123; lock.unlock(); &#125; &#125;&#125; 然后构建两个线程，均持有MyService对象： 线程A: 12345678910111213public class MyServiceThreadA implements Runnable&#123; private MyService service; public MyServiceThreadA(MyService service) &#123; this.service = service; &#125; @Override public void run() &#123; service.awitA(); &#125;&#125; 线程B: 12345678910111213public class MyServiceThreadB implements Runnable&#123; private MyService service; public MyServiceThreadB(MyService service) &#123; this.service = service; &#125; @Override public void run() &#123; service.awitB(); &#125;&#125; 主函数为: 12345678910111213141516171819public class ApplicationCondition &#123; public static void main(String[] args) throws InterruptedException &#123; MyService service = new MyService(); Runnable runnableA = new MyServiceThreadA(service); Runnable runnableB = new MyServiceThreadB(service); new Thread(runnableA, &quot;a&quot;).start(); new Thread(runnableB, &quot;b&quot;).start(); Thread.sleep(2000); // 唤醒所有持有ConditionA的线程 service.signallA(); Thread.sleep(2000); // 唤醒所有持有ConditionB的线程 service.signallB(); &#125;&#125; 运行结果为: 12345678a进入了awitA方法b进入了awitB方法启动唤醒程序a等待了：2 s启动唤醒程序b等待了：4 sProcess finished with exit code 0 可以看到，在实现线程协作时，Condition具有更大的灵活性，比如现在有3个线程A、B、C，线程A更新了某数据，需要通知线程B去拿新数据做搞事情，而C线程继续休眠，此种情况采用Object的wait()/notify()是难以实现的，因为notify()唤醒的线程是难以控制和指定的，而Condition却可以轻松完成这一切。 总结本文主要介绍了线程协作的两种方式，分别为Object的wait()/notify()和Condition的await()/signal()。 两种方式在原理上基本类似，均实现了等待/通知机制，相比使用Object的wait()、notify()，使用Condition的await()、signal()这种方式实现线程间协作更加安全和高效。因此通常来说比较推荐使用Condition，如阻塞队列实际上使用了Condition来模拟线程间协作。 参考文献: https://www.cnblogs.com/dolphin0520/p/3920385.html http://www.importnew.com/30150.html https://blog.csdn.net/qq_38293564/article/details/80432875 https://www.cnblogs.com/superfj/p/7543927.html 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Java并发中的AQS]]></title>
    <url>%2F2019%2F05%2F05%2F%E6%B5%85%E8%B0%88Java%E5%B9%B6%E5%8F%91%E4%B8%AD%E7%9A%84AQS%2F</url>
    <content type="text"><![CDATA[所谓AQS，指的是AbstractQueuedSynchronizer，它提供了一种实现阻塞锁和一系列依赖FIFO等待队列的同步器的框架，ReentrantLock、Semaphore、CountDownLatch、CyclicBarrier等并发类均是基于AQS来实现的，具体用法是通过继承AQS实现其模板方法，然后将子类作为同步组件的内部类。 了解一个框架最好的方式是读源码，说干就干。 AQS是JDK1.5之后才出现的，由大名鼎鼎的Doug Lea李大爷来操刀设计并开发实现，全部源代码(加注释)2315行，整体难度中等。 12* @since 1.5* @author Doug Lea 基本框架在阅读源码前，首先阐述AQS的基本思想及其相关概念。 AQS基本框架如下图所示： AQS维护了一个volatile语义(支持多线程下的可见性)的共享资源变量state和一个FIFO线程等待队列(多线程竞争state被阻塞时会进入此队列)。 State首先说一下共享资源变量state，它是int数据类型的，其访问方式有3种： getState() setState(int newState) compareAndSetState(int expect, int update) 上述3种方式均是原子操作，其中compareAndSetState()的实现依赖于Unsafe的compareAndSwapInt()方法。 1234567891011121314151617private volatile int state;// 具有内存读可见性语义protected final int getState() &#123; return state;&#125;// 具有内存写可见性语义protected final void setState(int newState) &#123; state = newState;&#125;// 具有内存读/写可见性语义protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 资源的共享方式分为2种： 独占式(Exclusive) 只有单个线程能够成功获取资源并执行，如ReentrantLock。 共享式(Shared) 多个线程可成功获取资源并执行，如Semaphore/CountDownLatch等。 AQS将大部分的同步逻辑均已经实现好，继承的自定义同步器只需要实现state的获取(acquire)和释放(release)的逻辑代码就可以，主要包括下面方法： tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 AQS需要子类复写的方法均没有声明为abstract，目的是避免子类需要强制性覆写多个方法，因为一般自定义同步器要么是独占方法，要么是共享方法，只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。 当然，AQS也支持子类同时实现独占和共享两种模式，如ReentrantReadWriteLock。 CLH队列(FIFO)AQS是通过内部类Node来实现FIFO队列的，源代码解析如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364static final class Node &#123; // 表明节点在共享模式下等待的标记 static final Node SHARED = new Node(); // 表明节点在独占模式下等待的标记 static final Node EXCLUSIVE = null; // 表征等待线程已取消的 static final int CANCELLED = 1; // 表征需要唤醒后续线程 static final int SIGNAL = -1; // 表征线程正在等待触发条件(condition) static final int CONDITION = -2; // 表征下一个acquireShared应无条件传播 static final int PROPAGATE = -3; /** * SIGNAL: 当前节点释放state或者取消后，将通知后续节点竞争state。 * CANCELLED: 线程因timeout和interrupt而放弃竞争state，当前节点将与state彻底拜拜 * CONDITION: 表征当前节点处于条件队列中，它将不能用作同步队列节点，直到其waitStatus被重置为0 * PROPAGATE: 表征下一个acquireShared应无条件传播 * 0: None of the above */ volatile int waitStatus; // 前继节点 volatile Node prev; // 后继节点 volatile Node next; // 持有的线程 volatile Thread thread; // 链接下一个等待条件触发的节点 Node nextWaiter; // 返回节点是否处于Shared状态下 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; // 返回前继节点 final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; // Shared模式下的Node构造函数 Node() &#123; &#125; // 用于addWaiter Node(Thread thread, Node mode) &#123; this.nextWaiter = mode; this.thread = thread; &#125; // 用于Condition Node(Thread thread, int waitStatus) &#123; this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; 可以看到，waitStatus非负的时候，表征不可用，正数代表处于等待状态，所以waitStatus只需要检查其正负符号即可，不用太多关注特定值。 获取资源(独占模式)acquire(int)首先讲解独占模式(Exclusive)下的获取/释放资源过程，其入口方法为: 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; tryAcquire(arg)为线程获取资源的方法函数，在AQS中定义如下： 123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 很明显，该方法是空方法，且由protected修饰，说明该方法需要由子类即自定义同步器来实现。 acquire()方法至少执行一次tryAcquire(arg)，若返回true，则acquire直接返回，否则进入acquireQueued(addWaiter(Node.EXCLUSIVE), arg)方法。 acquireQueued方法分为3个步骤： addWriter()将当前线程加入到等待队列的尾部，并标记为独占模式； acquireQueued()使线程在等待队列中获取资源，直到获取到资源返回，若整个等待过程被中断过，则返回True，否则返回False。 如果线程在等待过程中被中断过，则先标记上，待获取到资源后再进行自我中断selfInterrupt()，将中断响应掉。 下面具体看看过程中涉及到的各函数： tryAcquire(int)tryAcquire尝试以独占的模式获取资源，如果获取成功则返回True，否则直接返回False，默认实现是抛出UnsupportedOperationException，具体实现由自定义扩展了AQS的同步器来完成。 addWaiter(Node)addWaiter为当前线程以指定模式创建节点，并将其添加到等待队列的尾部，其源码为： 123456789101112131415private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 尝试将节点快速插入等待队列，若失败则执行常规插入(enq方法) Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 常规插入 enq(node); return node;&#125; 再看enq(node)方法： 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 可以看到，常规插入与快速插入相比，有2点不同： 常规插入是自旋过程(for(;;))，能够保证节点插入成功； 比快速插入多包含了1种情况，即当前等待队列为空时，需要初始化队列，即将待插入节点设置为头结点，同时为尾节点(因为只有一个嘛)。 常规插入与快速插入均依赖于CAS，其实现依赖于unsafe类，具体代码如下： 12345678private final boolean compareAndSetHead(Node update) &#123; return unsafe.compareAndSwapObject(this, headOffset, null, update);&#125;private final boolean compareAndSetTail(Node expect, Node update) &#123; return unsafe.compareAndSwapObject(this, tailOffset, expect, update);&#125; unsafe中的cas操作均是native方法，由计算机CPU的cmpxchg指令来保证其原子性。 接着看acquireQueued()方法： acquireQueued(Node, int)相关说明已在代码中注释： 12345678910111213141516171819202122232425262728293031323334353637final boolean acquireQueued(final Node node, int arg) &#123; // 标识是否获取资源失败 boolean failed = true; try &#123; // 标识当前线程是否被中断过 boolean interrupted = false; // 自旋操作 for (;;) &#123; // 获取当前节点的前继节点 final Node p = node.predecessor(); // 如果前继节点为头结点，说明排队马上排到自己了，可以尝试获取资源，若获取资源成功，则执行下述操作 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 将当前节点设置为头结点 setHead(node); // 说明前继节点已经释放掉资源了，将其next置空，以方便虚拟机回收掉该前继节点 p.next = null; // help GC // 标识获取资源成功 failed = false; // 返回中断标记 return interrupted; &#125; // 若前继节点不是头结点，或者获取资源失败， // 则需要通过shouldParkAfterFailedAcquire函数 // 判断是否需要阻塞该节点持有的线程 // 若shouldParkAfterFailedAcquire函数返回true， // 则继续执行parkAndCheckInterrupt()函数， // 将该线程阻塞并检查是否可以被中断，若返回true，则将interrupted标志置于true if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; // 最终获取资源失败，则当前节点放弃获取资源 if (failed) cancelAcquire(node); &#125;&#125; 具体看一下shouldParkAfterFailedAcquire函数： 1234567891011121314151617181920212223// shouldParkAfterFailedAcquire是通过前继节点的waitStatus值来判断是否阻塞当前节点的线程的private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 获取前继节点的waitStatus值ws int ws = pred.waitStatus; // 如果ws的值为Node.SIGNAL(-1)，则直接返回true // 说明前继节点完成资源的释放或者中断后，会通知当前节点的，回家等通知就好了，不用自旋频繁地来打听消息 if (ws == Node.SIGNAL) return true; // 如果前继节点的ws值大于0,即为1,说明前继节点处于放弃状态(Cancelled) // 那就继续往前遍历，直到当前节点的前继节点的ws值为0或负数 // 此处代码很关键，节点往前移动就是通过这里来实现的，直到节点的前继节点满足 // if (p == head &amp;&amp; tryAcquire(arg))条件，acquireQueued方法才能够跳出自旋过程 if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 将前继节点的ws值设置为Node.SIGNAL，以保证下次自旋时，shouldParkAfterFailedAcquire直接返回true compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; parkAndCheckInterrupt()函数则简单很多，主要调用LockSupport类的park()方法阻塞当前线程，并返回线程是否被中断过。 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 至此，独占模式下，线程获取资源acquire的代码就跟完了，总结一下过程： 首先线程通过tryAcquire(arg)尝试获取共享资源，若获取成功则直接返回，若不成功，则将该线程以独占模式添加到等待队列尾部，tryAcquire(arg)由继承AQS的自定义同步器来具体实现； 当前线程加入等待队列后，会通过acquireQueued方法基于CAS自旋不断尝试获取资源，直至获取到资源； 若在自旋过程中，线程被中断过，acquireQueued方法会标记此次中断，并返回true。 若acquireQueued方法获取到资源后，返回true，则执行线程自我中断操作selfInterrupt()。 123static void selfInterrupt() &#123; Thread.currentThread().interrupt();&#125; 释放资源(独占模式)讲完获取资源，对应的讲一下AQS的释放资源过程，其入口函数为： 1234567891011public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; // 获取到等待队列的头结点h Node h = head; // 若头结点不为空且其ws值非0，则唤醒h的后继节点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 逻辑并不复杂，通过tryRelease(arg)来释放资源，和tryAcquire类似，tryRelease也是有继承AQS的自定义同步器来具体实现。 tryRelease(int)该方法尝试释放指定量的资源。 123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125; unparkSuccessor(Node)该方法主要用于唤醒等待队列中的下一个阻塞线程。 1234567891011121314151617181920private void unparkSuccessor(Node node) &#123; // 获取当前节点的ws值 int ws = node.waitStatus; // 将当前节点的ws值置0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; // 若后继节点为null或者其ws值大于0(放弃状态)，则从等待队列的尾节点从后往前搜索， // 搜索到等待队列中最靠前的ws值非正且非null的节点 if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 如果后继节点非null，则唤醒该后继节点持有的线程 if (s != null) LockSupport.unpark(s.thread);&#125; 后继节点的阻塞线程被唤醒后，就进入到acquireQueued()的if (p == head &amp;&amp; tryAcquire(arg))的判断中，此时被唤醒的线程将尝试获取资源。 当然，如果被唤醒的线程所在节点的前继节点不是头结点，经过shouldParkAfterFailedAcquire的调整，也会移动到等待队列的前面，直到其前继节点为头结点。 讲解完独占模式下资源的acquire/release过程，下面开始讲解共享模式下，线程如何完成资源的获取和共享。 获取资源(共享模式)理解了独占模式下，资源的获取和释放过程，则共享模式下也就so easy了，首先看一下方法入口： 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 执行tryAcquireShared方法获取资源，若获取成功则直接返回，若失败，则进入等待队列，执行自旋获取资源，具体由doAcquireShared方法来实现。 tryAcquireShared(int)同样的，tryAcquireShared(int)由继承AQS的自定义同步器来具体实现。 123protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125; 其返回值为负值代表失败；0代表获取成功，但无剩余资源；正值代表获取成功且有剩余资源，其他线程可去获取。 doAcquireShared(int)1234567891011121314151617181920212223242526272829303132333435363738private void doAcquireShared(int arg) &#123; // 将线程以共享模式添加到等待队列的尾部 final Node node = addWaiter(Node.SHARED); // 初始化失败标志 boolean failed = true; try &#123; // 初始化线程中断标志 boolean interrupted = false; for (;;) &#123; // 获取当前节点的前继节点 final Node p = node.predecessor(); // 若前继节点为头结点，则执行tryAcquireShared获取资源 if (p == head) &#123; int r = tryAcquireShared(arg); // 若获取资源成功，且有剩余资源，将自己设为头结点并唤醒后续的阻塞线程 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC // 如果中断标志位为真，则线程执行自我了断 if (interrupted) selfInterrupt(); // 表征获取资源成功 failed = false; return; &#125; &#125; // houldParkAfterFailedAcquire(p, node)根据前继节点判断是否阻塞当前节点的线程 // parkAndCheckInterrupt()阻塞当前线程并检查线程是否被中断过，若被中断过，将interrupted置为true if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) // 放弃获取资源 cancelAcquire(node); &#125;&#125; 可以发现，doAcquireShared与独占模式下的acquireQueued大同小异，主要有2点不同： doAcquireShared将线程的自我中断操作放在了方法体内部； 当线程获取到资源后，doAcquireShared会将当前线程所在的节点设为头结点，若资源有剩余则唤醒后续节点，比acquireQueued多了个唤醒后续节点的操作。 上述方法体现了共享的本质，即当前线程吃饱了后，若资源有剩余，会招呼后面排队的来一起吃，好东西要大家一起分享嘛，哈哈。 下面具体看一下setHeadAndPropagate(Node, int)函数： 1234567891011121314private void setHeadAndPropagate(Node node, int propagate) &#123; // 记录原来的头结点，下面过程会用到 Node h = head; // 设置新的头结点 setHead(node); // 如果资源还有剩余，则唤醒后继节点 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 可以看到，实际执行唤醒后继节点的方法是doReleaseShared()，继续追踪： 123456789101112131415161718192021private void doReleaseShared() &#123; // 自旋操作 for (;;) &#123; // 获取等待队列的头结点 Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // 唤醒后继节点的线程 unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 释放资源(共享模式)首先进入到方法入口： 123456789public final boolean releaseShared(int arg) &#123; // 尝试释放资源 if (tryReleaseShared(arg)) &#123; // 唤醒后继节点的线程 doReleaseShared(); return true; &#125; return false;&#125; 同样的，tryReleaseShared(int)由继承AQS的自定义同步器来具体实现。 doReleaseShared()上节讲解setHeadAndPropagate已说明过，不再赘述。 至此，共享模式下的资源获取/释放就讲解完了，下面以一个具体场景来概括一下： 整个获取/释放资源的过程是通过传播完成的，如最开始有10个资源，线程A、B、C分别需要5、4、3个资源。 A线程获取到5个资源，其发现资源还剩余5个，则唤醒B线程； B线程获取到4个资源，其发现资源还剩余1个，唤醒C线程； C线程尝试取3个资源，但发现只有1个资源，继续阻塞； A线程释放1个资源，其发现资源还剩余2个，故唤醒C线程； C线程尝试取3个资源，但发现只有2个资源，继续阻塞； B线程释放2个资源，其发现资源还剩余4个，唤醒C线程； C线程获取3个资源，其发现资源还剩1个，继续唤醒后续等待的D线程； …… 总结本文主要介绍了AQS在独占和共享两种模式下，如何进行资源的获取和释放(tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared)，需要注意的是，在acquire()和acquireShared()方法中，线程在阻塞过程中均是忽略中断的。 AQS也可以通过acquireInterruptibly()/acquireSharedInterruptibly()来支持线程在等待过程中响应中断。 篇幅有限，本文就讲解到这里。对于AQS其他高级特性，感兴趣的读者可跟一下源码。 参考https://www.cnblogs.com/iou123lg/p/9464385.htmlhttps://www.cnblogs.com/waterystone/p/4920797.htmlhttps://www.jianshu.com/p/0da2939391cf 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊一聊ThreadLocal是个啥东东]]></title>
    <url>%2F2019%2F04%2F30%2F%E8%81%8A%E4%B8%80%E8%81%8AThreadLocal%E6%98%AF%E4%B8%AA%E5%95%A5%E4%B8%9C%E4%B8%9C%2F</url>
    <content type="text"><![CDATA[引言 ThreadLocal提供了线程私有的局部变量，可以在整个线程存活的过程中随时取用，从而减少了在同一个线程内多个函数或者组件之间公共变量传递的复杂度。同时，由于ThreadLocal变量的线程私有性，故不存在并发线程安全的问题。 要满足上述特性，需要解决3个问题： 与线程绑定，实现私有性； 提供合适的容器，方便变量的存取； 设计合理的垃圾回收机制，避免内存泄露。 实现原理为解决前2个问题，JDK最早期的设计是在ThreadLocal类内部维护一个线程安全的Map，线程的ID作为Map的key，实例对象作为Map的value，进而达到各个线程值隔离的效果。 该种中心化的模式下，通过Map的key来进行线程的绑定，而Map同时又作为变量的容器，ThreadLocal类需要处理复杂的多线程同步及变量回收问题，笨重且效率较低，所以后期JDK换了一种去中心化的方式，将管理权下放给了下面的各个线程，下面通过源码来阐述。 首先看set方法： 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 可以看到，set方法主要分为以下两个步骤： 通过getMap()获取当前线程的ThreadLocalMap(map)； 通过map.set(this, value)将当前的ThreadLocal(this)作为key，T(value)作为value添加进获取到的ThreadLocalMap(map)中。 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; threadLocals为Thread类的的成员变量，初始化为null。 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; get方法与之类似，可以看到现在的ThreadLocal是通过ThreadLocalMap来实现线程绑定和变量容器的，每个Thread均维护一个ThreadLocalMap映射表，key为ThreadLocal实例本身，而value是真正需要存储的的Object，该种模式带来3个直接的好处： ThreadLocalMap与线程同生命周期，当Thread销毁之后，对应的ThreadLocalMap也随之销毁，减少内存使用量； 映射表的Entity数量变小了，以前是Thread的数量，现在是ThreadLocal的数量，映射表更加轻量，故性能得到有效提高； 每个线程均有自己的ThreadLocalMap，保证了并发环境下的线程安全。 ThreadLocalMapThreadLocalMap是ThreadLocal的静态内部类，它具有HashMap的部分特性，比如容量、扩容阈值等，内部通过Entity类来存储key和value，Entity的定义为： 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; Entry继承自WeakReference，通过上述源码super(k)，可以知道，ThreadLocalMap是使用ThreadLocal的弱引用作为Key的。 分析到这里，可以得到下面ThreadLocal对象之间的引用结构图（其中，实线为强引用，虚线为弱引用）： 可以看到，Java堆上的ThreadLocal对象存在两个引用链，外部声明的强引用和ThreadLocalMap的key的弱引用，考虑以下情况： 删除ThreadLocal外部声明的强引用，即将ThreadLocal Ref置为null，此时只剩ThreadLocalMap的key的弱引用，当下次GC时，Java堆上的ThreadLocal对象将被回收，ThreadLocalMap上的key变为null。 需要注意的是，由于CurrentThread-&gt;Thread-&gt;ThreadLocalMap-&gt;Entity-&gt;value强引用链的存在，即使该Entity的key已经为null，value仍旧不会被回收，只有当线程被销毁之后，value的这部分内存空间才会被回收掉。 一般情况下，上述问题影响不大，但是在线程一直运行不被销毁的环境中(如线程池中的核心线程)，会存在内存泄露的问题。 内存回收由于Entity的value是与线程同生命周期的，所以当线程持续不被回收时，会造成内存泄露，为此ThreadLocalMap通过以下机制来解决上述问题. 首先看ThreadLocalMap的getEntry(ThreadLocal&lt;?&gt; key)方法： 12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125; 首先计算key所属entity在映射表中的位置i，如果映射表中i位置的entity非空且其key与方法传入的key相等，则直接返回entity；否则，调用getEntryAfterMiss(key, i, e)方法。 12345678910111213141516private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; getEntryAfterMiss方法通过i = nextIndex(i, len)，从table的当前位置i往后遍历table中非空的entity，若entity的key与传入的key相等，则返回该entity(可以看出ThreadLocalMap是采用线性探查的方式来解决hash冲突的，探查步长为1)；若entity的key为null，则调用expungeStaleEntry(i)方法。 1234567891011121314151617181920212223242526272829303132333435private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125; expungeStaleEntry(i)首先清理掉当前key为null的entity: 1234// expunge entry at staleSlottab[staleSlot].value = null;tab[staleSlot] = null;size--; 接着进行rehash过程，其基本过程是遍历table中非null的entity，若遍历到的entity，其key为null，则清理掉该entity；若遍历到的entity的key不为null，则检查key的散列值是否属于当前位置，若不属于，将当前位置置空(tab[i] = null;)，不断往后探查，若table的某位置为null，则将entity移动到该位置： 123456tab[i] = null;// Unlike Knuth 6.4 Algorithm R, we must scan until// null because multiple entries could have been stale.while (tab[h] != null) h = nextIndex(h, len);tab[h] = e; 这里的rehash过程，其实还有一种方法，就是当key的散列值j不属于当前位置i时，将table的位置i置空(tab[i] = null;)，然后将位置i原有的entity移动到table的j位置，若发生hash冲突，则往后线性探查。读者可以思考为啥JDK没有采用这种方法。 本质上讲，rehash过程一方面释放掉了key为null的entity的内存，避免了当前线程(CurrentThread)长期存在时的内存泄露问题。同时，rehash()将不属于某位置的entity移动到其他位置，避免了后面可能存在的hash冲突。 在ThreadLocalMap的set()和getEntity()方法中，均会调用expungeStaleEntry(int staleSlot)方法，但是当我们既不添加value也不获取value时，还是可能存在内存泄露的，所以最佳实践是：当ThreadLocal不需要时，手动调用其remove()方法，来删除对应的Entity及其value： 12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; 最终调用的是ThreadLocalMap的remove函数： 1234567891011121314private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125;&#125; 若对应的key存在，remove会调用expungeStaleEntry(i)方法来删除对应的entity和value。 总结 ThreadLocal是通过ThreadLocalMap来实现线程绑定和变量存储的； ThreadLocalMap的实体结构Entity继承自WeakReference，其key是对ThreadLocal对象的弱引用； ThreadLocal的get()、set(T)、remove()均会触发ThreadLocalMap的回收机制，删除无效的Entity。 小贴士：ThreadLocal的源码加注释也就722行，难度不大，设计得很是精巧，推荐读者阅读。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务隔离那些事儿]]></title>
    <url>%2F2019%2F04%2F26%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%2F</url>
    <content type="text"><![CDATA[在高并发环境下，由于多用户同时对数据库进行读/写操作，数据的可见性和操作的原子性需要通过事务机制来保障。 下面我们通过4个典型场景来讲解数据库的事务隔离机制。 首先在Mysql数据库中创建1张表： 123456CREATE TABLE `account` ( `id` int(11) NOT NULL COMMENT &apos;ID&apos;, `name` varchar(255) DEFAULT NULL COMMENT &apos;姓名&apos;, `account` float(255,0) DEFAULT NULL COMMENT &apos;账户余额&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 插入两条测试数据： 12insert into account values(1, &quot;小明&quot;, 1000);insert into account values(1, &quot;小强&quot;, 1000); 丢失更新假设现在有2个线程操作account表: 12345678910111213 线程A 线程B 读取到小明的account=1000 读取到小明的account=1000 set account=account+200 写回account=1200 set account=account+300 写回account=1300 很明显，在这种多线程更新操作下，线程A的更新丢失了，小明本来应该收到500元，结果只收到了300元。 还我血汗钱，小明要杀程序员祭天了… 于是，聪明的程序员引入了X锁来解决更新丢失的问题。 所谓X锁，又称排他锁(Exclusive Lock)或写锁，即某线程对数据添加X锁后，则独占该数据，其他线程不能更新该数据。该线程释放X锁后，其他线程获取到X锁后才可以进行更新操作，也就是说X锁属于独占锁，比较重。 于是上述的转账操作优化为: 1234567891011121314151617181920212223 线程A 线程B 获取account的X锁(成功) 读取到小明的account=1000 获取account的X锁(失败) set account=account+200 写回account=1200 ...... 释放account的X锁 获取account的X锁(成功) 读取到小明的account=1200 set account=account+300 写回account=1500 释放account的X锁 X锁优化对应的就是数据库事务隔离的最低级别Read Uncommited。 即Read Uncommited可以避免丢失更新。 脏读Read Uncommited虽然可以解决更新丢失的问题，但是X锁并不能约束其他线程并行的读取数据。 比如下述场景： 1234567891011121314151617181920 线程A 线程B 获取account的X锁(成功) 读取到小明的account=1000 set account=account+200 写回account=1200 读取到小明的account=1200 Rollback account恢复为1000 释放account的X锁 尴尬了！ 小明现在的数据是错误的 我们用mysql模拟上述操作： 客户端A: 123mysql&gt; set session transaction isolation level read uncommitted;mysql&gt; start transaction;mysql&gt; select * from account; 再起一个客户端B: 123mysql&gt; set session transaction isolation level read uncommitted;mysql&gt; start transaction;mysql&gt; update account set account=account+200 where id=1 此时，客户端B的事务还未commit，通过客户端A执行select操作： 可以看到，客户端A的事务看到了客户端B的事务里未提交的修改数据。 此时，数据库中小明的account仍然是1000，可以起一个客户端C(未开启事务)来验证: 也就是说，客户端A中读取的数据与数据库中实际值不一致，出现了脏读。 出现脏读的原因主要是X锁仅对多线程的更新操作添加了约束，而对读取操作没做要求。 解决方法也就呼之欲出了，对读取操作也进行加锁呗。 那么是不是直接对读取操作也加X锁呢？ 这样就太重了，而且由于X锁的独占性，当多线程环境下仅有读操作时，也需要频繁的加锁和释放锁，但实际上仅有读操作时，并发环境下并不会引发脏读(因为并没有线程更改数据嘛)。 于是，聪明的程序员引入了S锁来解决脏读的问题，同时又保证了锁的轻量性。 S锁，又称共享锁(Share Lock)或读锁，S锁与X锁的关系可以用1句话总结： 如果一个数据加了X锁，就没法加S锁；同样加了S锁，就没法加X锁。 当然，加了S锁的数据还可以继续添加S锁，因为并发读是互不影响的。 同时，在高并发环境下，为了防止单个线程长时间被S锁锁住，故有如下约定: 读数据前添加S锁，读完之后立即释放。 添加S锁机制之后，上面的流程优化如下： 123456789101112131415161718192021 线程A 线程B 获取account的X锁(成功) 读取到小明的account=1000 set account=account+200 写回account=1200 获取account的S锁(失败) Rollback ...... account恢复为1000 释放account的X锁 获取account的S锁(成功)读取到小明的account=1000 很明显，S锁限制了读时写和写时读，只有当写线程commit释放X锁之后，读线程才能获取到S锁完成数据的读取。 这种只能更新数据commit之后，才能读取到最新数据的事务隔离级别称为Read Committed。 即Read Committed可以避免脏读。 不可重复读在Read Committed事务隔离级别下，我们为了防止高并发环境下读线程长时间被锁住，做了以下规定： 读数据前添加S锁，读完之后立即释放。 此时，会出现以下问题： 12345678910111213141516171819202122 线程A 线程B 获取account的S锁(成功) 读取到的account=1000 释放account的S锁 获取account的X锁(成功) set account=account+200 做其他事情... 写回account=1200 释放account的X锁 获取account的S锁(成功) 重新读取到的account=1200 What? 与之前读的不一样了？ 此时，在同一个事务中重新读取的数据发生了变化，即不可重复读。 同样用mysql数据库演示上述过程： 客户端A: 123mysql&gt; set session transaction isolation level read committed;mysql&gt; start transaction;mysql&gt; select * from account; 此时再起一个客户端B: 12345mysql&gt; set session transaction isolation level read committed;mysql&gt; start transaction;mysql&gt; update account set account=account+200 where id=1;mysql&gt; select * from account;mysql&gt; commit; 此时，在客户端A的事务中继续查询: 故客户端A同一个事务中小明的account出现了2个不同的值，即出现了不可重复读。 而解决不可重复读的方法也很简单，把S锁的规定升级一下即可： 读数据前添加S锁，事务提交之后才可以释放。 此时，上面的流程变为： 123456789101112131415161718192021222324 线程A 线程B获取account的S锁(成功)读取到的account=1000 获取account的X锁(失败) 做其他事情... 获取account的S锁(成功) 读取到的account=1000 ...... 提交事务 释放account的S锁 获取account的X锁(成功) set account=account+200 写回account=1200 释放account的X锁 此时对应的数据库事务隔离级别即为Repeatable Read。 Repeatable Read解决了不可重复读的问题。 幻读通过X锁和S锁的组合应用，我们解决了数据的更新丢失、脏读、不可重复读3个问题，但由于X锁和S锁仅是对数据的更新(修改)和读取进行了限制，而对数据的添加和删除未做限制，那么即使在Repeatable Read隔离级别下，仍然会出现如下问题： 12345678910111213141516171819202122 线程A 线程B 获取数据的S锁(成功) 查询account表 [(1, &quot;小明&quot;, 1000) (2, &quot;小强&quot;, 1000)] 做其他事情... 插入数据(3, &quot;小花&quot;, 1000) 提交 插入数据(3, &quot;小花&quot;, 1000) 报错：&apos;3&apos; for key &apos;PRIMARY&apos; 查询account表[(1, &quot;小明&quot;, 1000)(2, &quot;小强&quot;, 1000)] What?这哪里有id为3的数据，眼花了？ 线程B的插入操作让线程A出现了幻觉，所以该种异常称之为幻读。 同样用mysql数据库演示上述过程： 客户端A: 123mysql&gt; set session transaction isolation level repeatable read;mysql&gt; start transaction;mysql&gt; select * from account; 此时再起一个客户端B: 12345mysql&gt; set session transaction isolation level repeatable read;mysql&gt; start transaction;mysql&gt; insert into account values(3, &quot;小红&quot;, 1000);mysql&gt; select * from account;mysql&gt; commit; 此时，客户端A在事务中继续执行： 12mysql&gt; insert into account values(3, &quot;小阁&quot;, 1500);mysql&gt; select * from account; 还有一种幻读，指的是： 12345678910111213141516 线程A 线程B 获取数据的S锁(成功) 查询account表中的人数 返回2 做其他事情... 插入数据(3, &quot;小花&quot;, 1000) 提交查询account表中的人数 返回3 What? 刚才还是2的？ 只是MySQL的InnoDB引擎默认的Repeatable Read级别已经通过MVCC自动帮我们解决了，所以该级别下, 我们也模拟不出该种幻读的场景。 至于MVCC是啥，后面抽空再聊，哈哈… 说实话，幻读和不可重复读很容易混淆： 不可重复读，主要是说在同一事务中多次读取一条记录, 发现该记录中某些列值被修改过； 幻读，主要是说在同一事务中多次读取一个范围内的记录(包括查询所有结果或者聚合统计)、插入时，发现结果不一致。 解决幻读，只能放出我们的终极大招了，对整个事务加X锁，将事务的执行串行化，对应的数据库事务隔离级别为Serializable。 即Serializable解决了幻读的问题。 总结 Read Uncommitted通过X锁来实现，锁住数据更新的阶段; Read Committed通过X锁和S锁来实现，且读完即释放S锁; Repeatable Read通过X锁和S锁来实现，事务提交之后释放S锁; Serializeable通过X锁来实现，锁住整个事务。 隔离级别 丢失更新 脏读 不可重复读 幻读 Read Uncommitted No Yes Yes Yes Read Committed No No Yes Yes Repeatable Read No No No Yes Serializeable No No No No 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RestTemplate源码解读]]></title>
    <url>%2F2019%2F04%2F25%2FRestTemplate%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[引言SpringCloud的微服务均是以Http接口的形式来暴露自身服务的，因此在调用远程服务的时候必须使用HTTP客户端，可选的方案有JDK原生的URL Connection、Apache的Http Client、Netty的异步Http Client，Spring的RestTemplate和Fegin。 今天主要介绍一下Spring的RestTemplate。 源码跟读通过源码可以看到RestTemplate进行请求的很多方法最终调用的均是doExecute方法。 可以看出，主要分为创建请求Request，执行请求Request，处理返回结果response3个步骤。 创建请求跟进createRequest()方法，发现该方法是由HttpAccessor负责实现的。 其基本思路是传入请求地址url和请求方法method，然后由ClientHttpRequestFactory工厂负责Request的创建，ClientHttpRequestFactory为一个接口，其实现类主要有： HttpAccessor提供了get/set方法，方便传入不同的ClientHttpRequestFactory实现类，如果需要自定义ClientHttpRequestFactory工厂，直接implements ClientHttpRequestFactory复写方法，然后注入HttpAccessor即可。 HttpAccessor默认使用的是SimpleClientHttpRequestFactory工厂实现类。 继续跟进SimpleClientHttpRequestFactory工厂实现类。 它提供了两种请求创建方法，分别支持同步和异步请求： createRequest(URI uri, HttpMethod httpMethod) createAsyncRequest(URI uri, HttpMethod httpMethod) 上述两种方法均包括打开连接、准备连接、创建连接3个步骤。 先看openConnection方法，它的实现比较简单，有代理Proxy存在，则传入Proxy打开连接，否则则直接通过URL打来连接。 prepareConnection方法主要根据传入的参数，进行连接前的一些配置工作，比如设置连接超时、读取超时、根据不同请求method设置相应配置参数等。 最后创建连接的时候，根据bufferRequestBody是否为True，创建2种不同的连接，分别为批处理连接和流处理连接。 1return (ClientHttpRequest)(this.bufferRequestBody ? new SimpleBufferingClientHttpRequest(connection, this.outputStreaming) : new SimpleStreamingClientHttpRequest(connection, this.chunkSize, this.outputStreaming)); 执行请求切回到RestTemplate类的doExecute方法，可以看到建立http连接，拿到ClientHttpRequest后，执行请求的方法为execute()。 ClientHttpRequest为接口，仅有一个execute()方法，看一下ClientHttpRequest的实现类： 其中用的比较多的是AbstractClientHttpRequest抽象类，SimpleStreamingClientHttpRequest和SimpleBufferingClientHttpRequest分别继承了AbstractClientHttpRequest，复写某些方法以支持流/批处理请求。 跟进AbstractClientHttpRequest抽象类的execute()方法， execute()内部调用的是executeInternal()，由子类来具体实现，可以看一下SimpleBufferingClientHttpRequest的方法实现，其他子类实现方式大同小异。 可以看到，主要是做了一些添加请求头、返回设置等的操作，最后得到请求的返回类SimpleClientHttpResponse。 至此，我们就拿到请求的返回了，下一步就是处理返回结果了。 处理返回结果返回结果处理主要分为两步： handleResponse(url, method, response) responseExtractor.extractData(response) 其中，handleResponse(url, method, response)主要负责对请求的异常进行处理。 可以看到，handleResponse()方法首先获取请求错误的处理器errorHandler，然后把response交给它进行后续的处理。 而responseExtractor.extractData(response)主要负责返回数据的解析。 responseExtractor为接口，其实现类为： 其中ResponseEntityResponseExtractor和HeadersExtractor为RestTemplate的内部类，主要处理返回的headers和entity，我们重点关注返回消息的转化处理类HttpMessageConverterExtractor。 可以看到，extractData先将response交给responseWrapper，如果responseWrapper有消息体且非空，则进行返回消息的读取操作。 消息的读取需要借助HttpMessageConverter接口，HttpMessageConverter具有多种实现类，以完成不同格式消息的读取，相当于消息解码器或转换头。 可以看到，在构建HttpMessageConverterExtractor实例的时候，需要传入HttpMessageConverter的接口集合messageConverters，用于对不同返回格式消息的读取。 首先，得到messageConverters的迭代器，然后遍历迭代器，依次执行不同HttpMessageConverter读取操作，最终完成返回消息体的读取操作。 迭代过程中，如果当前MessageConverter属于GenericHttpMessageConverter的接口实现，则执行： 1return genericMessageConverter.read(this.responseType, (Class)null, responseWrapper); 否则： 1return messageConverter.read(this.responseClass, responseWrapper); 总结 RestTemplate是Spring提供的用于访问Rest服务的客户端； RestTemplate提供了多种便捷访问远程Http服务的方法,能够大大提高客户端的编写效率； 调用RestTemplate的默认构造函数，RestTemplate对象在底层通过使用java.net包下的实现创建HTTP请求； 可以通过使用ClientHttpRequestFactory指定不同的HTTP请求方式； 在设计模式上，主要通过工厂模式来完成各类Http客户端的创建。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Springboot</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>RestTemplate</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo框架的HelloWorld]]></title>
    <url>%2F2018%2F12%2F14%2FDubbo%E6%A1%86%E6%9E%B6%E7%9A%84HelloWorld%2F</url>
    <content type="text"><![CDATA[随着微服务的流行，Dubbo和Spring Cloud框架受到越来越多的关注，本文主要基于1个简单Demo来介绍Dubbo框架的工作流程。 Dubbo是什么? Apache Dubbo (incubating) is a high-performance, java based, open source RPC framework. Dubbo是： 一个分布式服务框架； 致力于提供高性能和透明化的RPC远程服务调用方案； 阿里巴巴SOA服务化治理方案的核心框架，每天为2,000+个服务提供3,000,000,000+次访问量支持。 注：SOA是Service-Oriented Architecture的英文简称，即面向服务的架构，其主要解决多服务凌乱的问题，因此有人也称之为服务治理。 dubbo的工作流程如下： 其中： Provider为服务提供者，负责发布服务； Consumer为服务消费者，负责调用服务； Container为Dubbo容器，其依赖于Spring容器； Registry为注册中心，当Container启动时会将所有可提供的服务在Registry进行注册，其作用是告知Consumer有哪些服务，以及服务的地址； Monitor为监听器，负责服务注册、调用等流程的监控； 其中虚线为异步访问，实线为同步访问； 蓝色虚线代表Dubbo启动时完成的功能，红色虚线(实线)为程序运行过程中执行的功能。 注册中心Dubbo支持以下4种注册中心： Multicast 不需要启动任何中心节点，只要广播地址一样，就可以互相发现。组播受网络结构限制，只适合小规模应用或开发阶段使用。 Zookeeper 其优点是支持网络集群。 Redis 使用Redis的Key/Map结构存储数据； 主Key为服务名和类型； Map中的Key为URL地址； Map中的Value为过期时间，用于判断脏数据，脏数据由监控中心删除。(注意：服务器时间必需同步，否则过期检测会不准确)； 使用Redis的Publish/Subscribe事件通知数据变更； Simple 本身为普通的Dubbo服务，可以减少第三方依赖，使整体通讯方式一致，不支持集群，可作为自定义注册中心的参考，但不适合直接用于生产环境。 负载均衡策略Dubbo支持以下4种负载均衡策略： Random LoadBalance 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance 轮询，按公约后的权重设置轮询比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive LoadBalance 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance 一致性 Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 算法参见：http://en.wikipedia.org/wiki/Consistent_hashing 缺省只对第一个参数 Hash，如果要修改，请配置 缺省用 160 份虚拟节点，如果要修改，请配置 示例编写下面通过1个简单Demo实际体验一把Dubbo。 构建环境 Java 1.8.0_191 Zookeeper-3.4.10 dubbo 2.5.9 dubbo-monitor-simple-2.5.3 IntelliJ IDEA 2018.1 dubbo_service首先，基于Maven构建dubbo_service工程，其作用仅是定义服务的接口。 对应的pom.xml文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;groupId&gt;com.ruanshubin&lt;/groupId&gt; &lt;artifactId&gt;dubbo_service&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.5.9&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.101tec/zkclient --&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.11&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; DemoService 12345package com.ruanshubin.service;public interface DemoService &#123; String sayHello(String name);&#125; dubbo_providerdubbo_provider为服务提供者，故其需要实现前面定义的服务接口。 其pom.xml文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;groupId&gt;com.ruanshubin&lt;/groupId&gt; &lt;artifactId&gt;dubbo_provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruanshubin&lt;/groupId&gt; &lt;artifactId&gt;dubbo_service&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- 打包操作 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;mainClass&gt;&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 接口实现类DemoServiceImpl 123456789101112package com.ruanshubin.service.Impl;import com.ruanshubin.service.DemoService;public class DemoServiceImpl implements DemoService &#123; @Override public String sayHello(String name) &#123; System.out.println(&quot;服务被调用！&quot;); return &quot;Hello &quot; + name; &#125;&#125; 下面需要编写Container的启动类Provider。 1234567891011121314package com.ruanshubin.dubbo;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;public class Provider &#123; public static void main(String[] args) throws IOException &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;provider.xml&quot;); context.start(); System.out.println(&quot;服务启动成功！&quot;); System.in.read(); // 按任意键退出，该行代码的目的是保持容器的启动状态 &#125;&#125; 其中，provider.xml为Provider端的启动配置文件，具体为： 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=&quot;hello-world-app&quot; /&gt; &lt;!-- 配置注册中心 --&gt; &lt;dubbo:registry address=&quot;10.194.224.61:2181?backup=10.194.224.62:2181,10.194.224.63:2181&quot; protocol=&quot;zookeeper&quot;/&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt; &lt;!-- 声明需要暴露的服务接口 --&gt; &lt;dubbo:service interface=&quot;com.ruanshubin.service.DemoService&quot; ref=&quot;demoService&quot; /&gt; &lt;!-- 和本地bean一样实现服务 --&gt; &lt;bean id=&quot;demoService&quot; class=&quot;com.ruanshubin.service.Impl.DemoServiceImpl&quot; /&gt;&lt;/beans&gt; dubbo_consumerdubbo_consumer为服务消费方，先从注册中心拉取服务列表，然后调用相应服务。 其启动类Consumer如下： 123456789101112131415161718package com.ruanshubin.dubbo;import com.ruanshubin.service.DemoService;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Consumer &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;consumer.xml&quot;); // 获取服务实例 DemoService service = context.getBean(&quot;demoService&quot;, DemoService.class); // 调取服务的方法，调用10次来测试负载均衡 for(int i=0; i&lt;10; i++)&#123; String result = service.sayHello(args[0]); System.out.println(result); &#125; &#125;&#125; 其中，consumer.xml为Consumer端的启动配置文件，具体为： 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=&quot;hello-world-app&quot; /&gt; &lt;!-- 配置注册中心 --&gt; &lt;dubbo:registry address=&quot;10.194.224.61:2181?backup=10.194.224.62:2181,10.194.224.63:2181&quot; protocol=&quot;zookeeper&quot;/&gt; &lt;!-- 声明需要调用的服务接口 --&gt; &lt;dubbo:reference interface=&quot;com.ruanshubin.service.DemoService&quot; id=&quot;demoService&quot; /&gt;&lt;/beans&gt; 对dubbo_service执行install后，然后分别对dubbo_provider和dubbo_consumer执行package打包。 示例测试监控中心及管理控制台为方便查看服务的启动和调用(消费)情况，需要安装监控中心及管理控制台，其具体安装步骤如下： 监控中心 12345678910111213141516171819202122232425262728# 创建安装目录[root@slave1 software]# mkdir dubbo# 上传安装包、解压[root@slave1 ~]# mv dubbo-monitor-simple-2.5.3-assembly.tar.gz /usr/software/dubbo/tar -zxvf dubbo-monitor-simple-2.5.3-assembly.tar.gz# 修改配置文件，主要是修改注册中心的地址dubbo.registry.address# 这里填上设置好的Zookeeper集群地址[root@slave1 dubbo-monitor-simple-2.5.3]# vim conf/dubbo.propertiesdubbo.container=log4j,spring,registry,jettydubbo.application.name=simple-monitordubbo.application.owner=#dubbo.registry.address=multicast://224.5.6.7:1234dubbo.registry.address=zookeeper://slave1:2181?backup=slave2:2181,slave3:2181#dubbo.registry.address=redis://127.0.0.1:6379#dubbo.registry.address=dubbo://127.0.0.1:9090dubbo.protocol.port=7070dubbo.jetty.port=9090dubbo.jetty.directory=$&#123;user.home&#125;/monitordubbo.charts.directory=$&#123;dubbo.jetty.directory&#125;/chartsdubbo.statistics.directory=$&#123;user.home&#125;/monitor/statisticsdubbo.log4j.file=logs/dubbo-monitor-simple.logdubbo.log4j.level=WARN# 修改完配置文件，然后启动bin/start.sh 管理控制台1234567891011121314151617181920212223242526272829# 首先安装tomcat容器# 创建安装目录mkdir /usr/software/tomcat# 将安装包移动到安装目录mv ~/apache-tomcat-8.5.35.tar.gz /usr/software/tomcat# 切换到安装目录并解压cd /usr/software/tomcat tar -zxvf apache-tomcat-8.5.35.tar.gz# 启动bin/startup.sh# 登录界面 IP:8080# 清空tomcat/webapps/ROOT目录[root@slave1 apache-tomcat-8.5.35]# rm -rf webapps/ROOT/*# 解压dubbo-admin.war至tomcat/webapps/ROOT[root@slave1 apache-tomcat-8.5.35]# mv ~/dubbo-admin-2.5.4-jdk1.8.war /usr/software/dubbo/apache-tomcat-8.5.35[root@slave1 apache-tomcat-8.5.35]# unzip dubbo-admin-2.5.4-jdk1.8.war -d webapps/ROOT/# 修改配置文件，主要是配置管理控制台的注册中心地址，及用户名密码[root@slave1 apache-tomcat-8.5.35]# cd webapps/ROOT/WEB-INF/[root@slave1 WEB-INF]# vim dubbo.propertiesdubbo.registry.address=zookeeper://slave1:2181?backup=slave2:2181,slave3:2181dubbo.admin.root.password=rootdubbo.admin.guest.password=guest# 启动tomcatbin/startup.sh 管理控制台默认Web端口号为8080。 部署测试首先，将Provider端部署包dubbo_provider-1.0-SNAPSHOT.jar上传到相应机器，这里我上传了4台机器： 在4台机器上分别执行下述命令： 1java -jar dubbo_provider-1.0-SNAPSHOT.jar 注意：部署的机器须保证有对应版本的Java环境。 登录Dubbo的管理控制台，可以看到DemoService服务已经存在，并存在于4台机器上。 随便找一台与之前4台机器联网、有Java环境的机器，打开终端输入以下命令： 1java -jar dubbo_consumer-1.0-SNAPSHOT.jar World 可以看出，调用远程服务成功。 下面看看4台机器被调用的次数： 1号机器调用5次： 2号机器被调用3次： 3号机器被调用2次： 4号机器被调用0次： 之所以这样的原因是：Dubbo默认的负载均衡策略为Random。 Dubbo有4种均衡策略，其具体的工作机制是怎么样的呢，篇幅有限，我们下次出一篇专门讲。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文搞懂原码、反码、补码]]></title>
    <url>%2F2018%2F12%2F10%2F%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%8E%9F%E7%A0%81%E3%80%81%E5%8F%8D%E7%A0%81%E3%80%81%E8%A1%A5%E7%A0%81%2F</url>
    <content type="text"><![CDATA[计算机底层均是以二进制表示的，数字也不例外，本文旨在探讨一下数字的原码、反码和补码。 概念需要声明的是，本文涉及到的数字及运算均基于8位bit下的值。 原码最高位为符号位，0代表正数，1代表负数，非符号位为该数字绝对值的二进制表示。 如： 127的原码为0111 1111-127的原码为1111 1111 反码正数的反码与原码一致； 负数的反码是对原码按位取反，只是最高位(符号位)不变。 如: 127的反码为0111 1111-127的反码为1000 0000 补码正数的补码与原码一致； 负数的补码是该数的反码加1。 如： 127的补码为0111 1111-127的补码为1000 0001 总结一下就是： 正数的原码、反码、补码是一致的； 负数的补码是反码加1，反码是对原码按位取反，只是最高位(符号位)不变； 计算机数字运算均是基于补码的。 下面就来探讨一下，为啥要用补码来表示数字。 补码有啥好？如果计算机内部采用原码来表示数，那么在进行加法和减法运算的时候，需要转化为两个绝对值的加法和减法运算； 计算机既要实现加法器，又要实现减法器，代价有点大，那么可不可以只用一种类型的运算器来实现加和减的远算呢？ 很容易想到的就是化减为加，举一个生活中的例子来说明这个问题： 时钟一圈是360度，当然也存在365度，但其实它和5度是一样的； 相同的道理，-30度表示逆时针旋转30度，其与顺时针旋转330度是一样的； 这里数字360表示时钟的一圈，在计算机里类似的概念叫模，它可以实现化减为加，本质上是将溢出的部分舍去而不改变结果。 易得，单字节(8位)运算的模为256=2^8。 在没有符号位的情况下，127+2=129，即： 这时，我们将最高位作为符号位，计算机数字均以补码来表示，则1000 0001的原码为减1后按位取反得1111 1111，也就是-127。 也就是说，计算机里的129即表示-127，相当于模256为一圈，顺时针的129则和逆时针127即-127是一样的。 故可以得到以下结论： 负数的补码为模减去该数的绝对值。 如-5的补码为： -5=256-5=251=1111 1011(二进制) 同样的，临界值-128也可以表示出来： -128=256-128=128=1000 0000(二进制) 但是正128就会溢出了，故单字节(8位)表示的数字范围为-128—127。 最后，我们来看一下，补码是如何通过模的溢出舍弃操作来完成化减为加的！ 16-5=16+(-5)=11 1 0000 1011将溢出位舍去，得0000 1011(二进制)=11。 好的，本文分享就到这里，希望能够帮助到大家。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git教程--本地库提交到GitHub远程库]]></title>
    <url>%2F2018%2F12%2F09%2FGit%E6%95%99%E7%A8%8B--%E6%9C%AC%E5%9C%B0%E5%BA%93%E6%8F%90%E4%BA%A4%E5%88%B0GitHub%E8%BF%9C%E7%A8%8B%E5%BA%93%2F</url>
    <content type="text"><![CDATA[Git操作安装Git客户端客户端下载地址 Git配置 打开Git Bash，键入以下配置信息。 12git config --global user.name &quot;You Name&quot;git config --global user.email &quot;yourmail@server.com&quot; 初始化本地库 创建本地库文件夹并切换到该文件夹： 12mkdir MyGitcd MyGit 初始化 1git init 提交代码 创建代码文件后，将本地文件添加到Git版本库中： 12git add filenamegit commit -m &quot;First commit&quot; Github配置生成公开密钥 注册GitHub账号后，打开Git Bash，键入以下命令生成公开密钥。 1ssh-keygen -C &apos;yourmail@server.com&apos; -t rsa 一路回车即可以，然后会在C:\Users\你的Windows用户名\目录下出现.ssh文件夹，包含id_rsa和id_rsa.pub两个文件，其中id_rsa.pub即为公开密钥，用Notepad++打开，复制其中内容； GitHub上设置公开密钥回到 GitHub 个人首页，点击 Account Settings -&gt; SSH and GPG key -&gt; New SSH key。title 可以随便取名字，Key 里面添加的内容为 id_rsa.pub 文件内所有的代码，然后点击 Apply 即可。 测试与GitHub是否连接成功 打开Git Bash，键入以下代码： 1ssh -T git@github.com 若返回以下内容，则说明连接成功。 1Hi Your Name! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 推送项目文件至GitHub 打开Git Bash，键入以下代码： 12git remote add origin git@github.com:youusername/MyGit.gitgit push -u origin master 推送成功后，即可在GitHub上看到Push上的项目文件。 若出现以下错误： 1fatal: remote origin already exists. 则执行以下代码后，再执行上述代码即可解决上述问题。 1git remote rm origin 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Spark Streaming处理Kafka数据流]]></title>
    <url>%2F2018%2F12%2F08%2F%E4%BD%BF%E7%94%A8Spark%20Streaming%E5%A4%84%E7%90%86Kafka%E6%95%B0%E6%8D%AE%E6%B5%81%2F</url>
    <content type="text"><![CDATA[Kafka作为优秀的日志采集系统，可以作为Spark Streaming的高级数据源，本文主要介绍如何使用Spark Streaming实时处理Kafka传递过来的数据流。 系统软件本文实验基于的各软件版本如下： Java 1.8.0_191 Scala 2.11 hadoop-3.0.3 zookeeper-3.4.10 Spark 2.3.2 kafka_2.12-2.0.1 kafka-manager-1.3.3.17 具体步骤启动Kafka集群启动Kafka集群之前首先启动Zookeeper集群： 在安装有Zookeeper的机器上执行下述命令： 12cd /usr/software/zookeeper/zookeeper-3.4.10/bin/./zkServer.sh start 另外打开一个终端，输入以下命令启动Kafka集群： 12cd /usr/software/kafka/kafka_2.12-2.0.1/bin./kafka-server-start.sh ../config/server.properties 测试Kafka集群是否可以正常使用 12345cd /usr/software/kafka/kafka_2.12-2.0.1./bin/kafka-topics.sh --create --zookeeper slave1:2181,slave2:2181,slave3:2181 --replication-factor 3 --partitions 3 --topic wordsender//这个topic叫wordsender，2181是zookeeper默认的端口号，partition是topic里面的分区数，replication-factor是备份的数量//可以用list列出所有创建的topics,来查看上面创建的topic是否存在./bin/kafka-topics.sh --list --zookeeper slave1:2181,slave2:2181,slave3:2181 Kafka脚本测试数据的生成和消费下面使用Kafka的producer脚本生成一些数据： 1234567cd /usr/software/kafka/kafka_2.12-2.0.1/bin./kafka-console-producer.sh --broker-list master:9092 --topic wordsender执行上述命令后，即进入producer的console界面，输入一些数据：Hello WorldHello SparkHello Kafka 另外打开一个终端使用Kafka的consumer脚本消费上述producer脚本生成的数据： 12cd /usr/software/kafka/kafka_2.12-2.0.1/bin/./kafka-console-consumer.sh --bootstrap-server master:9092 --topic wordsender --from-beginning 需要注意的是，在旧版本的kafka-console-consumer.sh中，是通过—zookeeper来消费数据的，而新版本的kafka则删除了该方法，统一使用—bootstrap-server，后面跟的是broker-list参数。 编写相应程序测试Kafka的数据生产及消费本实验基于Maven作为项目构建工具，选择的IDE为IntelliJ IDEA 2018.1 ，采用的编程语言为Scala。 创建Maven工程后，项目处右键Add Frameworks Support: 首先，我们来编写producer端的代码： pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.ruanshubin&lt;/groupId&gt; &lt;artifactId&gt;SparkAndKafka&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;spark.version&gt;2.3.2&lt;/spark.version&gt; &lt;scala.version&gt;2.11&lt;/scala.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-core_$&#123;scala.version&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-streaming_$&#123;scala.version&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-sql_$&#123;scala.version&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-streaming-kafka-0-8_2.11&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.scala-tools&lt;/groupId&gt; &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt; &lt;version&gt;2.15.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;createDependencyReducedPom&gt;false&lt;/createDependencyReducedPom&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;mainClass&gt;com.ruanshubin.kafka.KafkaWordCount&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 必须使用spark-streaming-kafka-0-8_2.11，不能使用spark-streaming-kafka_2.11，因为该Jar打包的时候会遗漏org.apache.spark.Logging相关包。 spark-streaming-kafka-0-8_2.11的版本号一定与Scala和Spark版本严格对应，否则会报错。 KafkaWordProducer.scala 1234567891011121314151617181920212223242526272829303132333435package com.ruanshubin.kafkaimport java.utilimport org.apache.kafka.clients.producer.&#123;KafkaProducer, ProducerConfig, ProducerRecord&#125;object KafkaWordProducer &#123; def main(args: Array[String]): Unit = &#123; if(args.length &lt; 4)&#123; System.err.println(&quot;Usage: KafkaWordCountProducer &lt;metadataBrokerList&gt; &lt;topic&gt; +&quot; + &quot;&lt;messagePerSec&gt; &lt;wordPerMessage&gt;&quot;) System.exit(1) &#125; val Array(brokers, topic, messagesPerSec, wordPerMessage) = args val props = new util.HashMap[String, Object]() props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokers) props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;) props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;) val producer = new KafkaProducer[String, String](props) while(true)&#123; (1 to messagesPerSec.toInt).foreach&#123; messageNum =&gt; val str = (1 to wordPerMessage.toInt).map(x =&gt; scala.util.Random.nextInt(10) .toString).mkString(&quot; &quot;) print(str) println() val message = new ProducerRecord[String, String](topic, null, str) producer.send(message) &#125; Thread.sleep(1000) &#125; &#125;&#125; 上述程序的作用就是每秒钟产生messagesPerSec条消息，每条消息包含wordPerMessage个单词(这里用10以内的随机整数代替单词)。 数据产生端producer有了，下面我们编写消费端consumer的代码： KafkaWordCount 消费者主要将生产者传递过来的消息执行WordCount操作: 12345678910111213141516171819202122232425262728293031323334package com.ruanshubin.kafkaimport org.apache.spark.SparkConfimport org.apache.spark.streaming.kafka.KafkaUtilsimport org.apache.spark.streaming.&#123;Minutes, Seconds, StreamingContext&#125;// spark-streaming-kafka-0-8_2.11的版本号一定要与Scala版本和Spark版本号对应起来object KafkaWordCount &#123; def main(args: Array[String]): Unit = &#123; LoggerPro.setStreamingLogLevels() val sc = new SparkConf().setAppName(&quot;KafkaWordCount&quot;).setMaster(&quot;local[2]&quot;) val ssc = new StreamingContext(sc, Seconds(10)) // 设置检查点 ssc.checkpoint(&quot;/root/spark/checkpoint&quot;) // Zookeeper服务器地址 val zkQuorum = &quot;slave1:2181,slave2:2181,slave3:2181&quot; // consumer所在的group，可在一个group中设置多个consumer，加快消息消费的速度 val group = &quot;handsome_boy&quot; // topic的名称 val topics = &quot;wordsender&quot; // 每个topic的分区数 val numThreads = 3 val topicMap = topics.split(&quot;,&quot;).map((_,numThreads.toInt)).toMap val lineMap = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap) val lines = lineMap.map(_._2) val words = lines.flatMap(_.split(&quot; &quot;)) val pair = words.map(x =&gt; (x, 1)) val wordCounts = pair.reduceByKeyAndWindow(_ + _, _ - _,Minutes(2), Seconds(10), 3) wordCounts.print ssc.start ssc.awaitTermination &#125;&#125; LoggerPro的目的是设置日志的打印级别，从而让结果输出的更为清晰，避免被大量的打印信息淹没。 1234567891011121314151617package com.ruanshubin.kafkaimport org.apache.log4j.&#123;Level, Logger&#125;import org.apache.spark.internal.Loggingobject LoggerPro extends Logging&#123; def setStreamingLogLevels(): Unit =&#123; val log4jInitialized = Logger.getRootLogger.getAllAppenders.hasMoreElements if(!log4jInitialized)&#123; logInfo(&quot;Setting log level to [ERROR] for streaming example.&quot; + &quot; To override add a custom log4j.properties to the classPath&quot;) Logger.getRootLogger.setLevel(Level.ERROR) &#125; &#125;&#125; 最终的项目结构如下图所示： 打包、提交集群运行 Maven打包 提交服务器 将项目target目录下生成的可执行Jar包上传到服务器指定目录，这里我上传到/usr/software/spark/mycode/streaming。 启动Kafka Manager 为了直观观察到数据流的流转，我们启动Kafka Manager： 12cd /usr/software/kafka/kafka-manager-1.3.3.17/bin./kafka-manager -Dhttp.port=9002 运行 首先启动Producer端： 12cd /usr/software/spark/spark-2.3.2-bin-hadoop2.7/bin/./spark-submit --class &quot;com.ruanshubin.kafka.KafkaWordProducer&quot; /usr/software/spark/mycode/streaming/SparkAndKafka-1.0-SNAPSHOT.jar slave1:9092,slave2:9092,slave3:9092 wordsender 3 5 新打开一个终端,启动消费者： 12cd /usr/software/spark/spark-2.3.2-bin-hadoop2.7/bin/./spark-submit --class &quot;com.ruanshubin.kafka.KafkaWordCount&quot; /usr/software/spark/mycode/streaming/SparkAndKafka-1.0-SNAPSHOT.jar 可以看到，Spark Streaming在实时消费Kafka里传过来的数据。 同时，查看Kafka Manger也可以看到数据在实时得产生和消费。 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Bigdata</category>
      </categories>
      <tags>
        <tag>Spark Streaming</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据环境搭建（Hadoop,Spark,Zookeeper,Hbase,Kafka）]]></title>
    <url>%2F2018%2F12%2F07%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%EF%BC%88Hadoop%2CSpark%2CZookeeper%2CHbase%2CKafka%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本教程基于4台机器(预装有CentOS7 Linux系统)完成Hadoop集群及其相关组件的搭建，1个master，3个slave。 Linux环境准备基础设置 修改主机名 12hostnamectl set-hostname masterreboot 依次将其他3台机器设置为slave1,slave2,slave3。 修改IP地址 123456789101112131415161718192021222324vim /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=&quot;Ethernet&quot;PROXY_METHOD=&quot;none&quot;BROWSER_ONLY=&quot;no&quot;BOOTPROTO=&quot;static&quot;DEFROUTE=&quot;yes&quot;IPV4_FAILURE_FATAL=&quot;no&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;IPV6_DEFROUTE=&quot;yes&quot;IPV6_FAILURE_FATAL=&quot;no&quot;IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot;NAME=&quot;ens33&quot;UUID=&quot;c35b7341-8921-48f5-ad7a-08cb5af4ba54&quot;DEVICE=&quot;ens33&quot;ONBOOT=&quot;yes&quot;IPADDR=xxx.xxx.xxx.xxxNETMASK=255.255.255.0GATEWAY=xxx.xxx.xxx.xxxDNS1=8.8.8.8DNS2=8.8.4.4service network restart 关闭防火墙 12systemctl stop firewalldsystemctl disable firewalld ssh通信 12345678// 生成密钥ssh-keygen -t rsa// 将公钥追加到验证表中cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys // 将公钥追加到其他主机验证表中ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave1ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave2ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave3 网络配置 推荐使用桥接模式，且IP与宿主机处于同一区段，网关、子页掩码、DNS与宿主机保持一致，IP采用静态或DHCP均可，推荐使用静态模式，以防IP经常变化，频繁修改/etc/hosts等配置文件。需要注意的是，IP设置使用静态模式时，需要在宿主机上ping一下相关IP，以防IP已被占用，设置之后引起冲突。 配置hosts，以便DNS解析主机名 1234567891011vim /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6xxx.xxx.xxx.xxx masterxxx.xxx.xxx.xxx slave1xxx.xxx.xxx.xxx slave2xxx.xxx.xxx.xxx slave3拷贝给其他主机:scp /etc/hosts root@slave1:/etc/ Java环境安装包拷贝、解压将压缩包拷贝至Linux系统中，移动到/usr/software/java目录下,并解压： 12mv jdk-8u191-linux-x64.tar.gz /usr/software/javatar -zxvf jdk-8u191-linux-x64.tar.gz 设置环境变量123456vim /etc/profileexport JAVA_HOME=/usr/software/java/jdk1.8.0_191export JRE_HOME=$JAVA_HOME/jreexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport CLASS_PATH=.:$JAVA_HOME/lib:$JRE_HOME/lib Esc[:wq]保存后，执行以下命令让其当即生效： 1source /etc/profile 输入： 123456java -version出现以下信息则表明hadoop安装成功：java version &quot;1.8.0_191&quot;Java(TM) SE Runtime Environment (build 1.8.0_191-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode) Hadoop全家桶Hadoop集群安装包拷贝、解压将压缩包拷贝至Linux系统中，移动到/usr/software/hadoop目录下,并解压： 12mv hadoop-3.0.3.tar.gz /usr/software/hadooptar -zxvf hadoop-3.0.3.tar.gz 设置环境变量1234vim /etc/profileexport HADOOP_INSTALL=/usr/software/hadoop/hadoop-3.0.3export PATH=$PATH:$HADOOP_INSTALL/bin:$HADOOP_INSTALL/sbin Esc[:wq]保存后，执行以下命令让其当即生效： 1source /etc/profile 修改启动文件主要为hadoop指定java环境： 1234567vim vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/hadoop-env.sh添加如下内容后保存：JAVA_HOME=/usr/software/java/jdk1.8.0_191使其当即生效：source /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/hadoop-env.sh 输入： 123456789hadoop version出现以下信息则表明hadoop安装成功：Hadoop 3.0.3Source code repository https://yjzhangal@git-wip-us.apache.org/repos/asf/hadoop.git -r 37fd7d752db73d984dc31e0cdfd590d252f5e075Compiled by yzhang on 2018-05-31T17:12ZCompiled with protoc 2.5.0From source with checksum 736cdcefa911261ad56d2d120bf1faThis command was run using /usr/software/hadoop/hadoop-3.0.3/share/hadoop/common/hadoop-common-3.0.3.jar 修改配置文件 core-site.xml 主要配置HDFS的地址和端口号。 1234567891011121314vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/core-site.xml&lt;configuration&gt; &lt;!-- 指定HDFS老大(namenode)的通信地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定hadoop运行时产生文件的存储路径 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/software/hadoop/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml 主要配置分布式文件系统。 1234567891011121314151617181920212223242526272829vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/hdfs-site.xml&lt;configuration&gt; &lt;!-- 设置namenode的http通讯地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address&lt;/name&gt; &lt;value&gt;master:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置secondary namenode的http通讯地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;slave1:50090&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置namenode的存放路径 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/usr/software/hadoop/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置datanode的存放路径 --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/usr/software/hadoop/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置hdfs副本数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml 主要是配置JobTracker的地址和端口。 123456789vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/mapred-site.xml&lt;configuration&gt; &lt;!-- 设置框架MR使用YARN --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn-site.xml 主要设置resourcemanager以及reducer取数据的方式。 1234567891011121314151617181920vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/yarn-site.xml&lt;configuration&gt; &lt;!-- 设置resourcemanager在哪个节点 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置reducer取数据的方式是mapreduce_shuffle --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; master和slaves 12345678910111213vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/mastermaster#######################################################vim /usr/software/hadoop/hadoop-3.0.3/etc/hadoop/slavesslave1slave2slave3# 需要注意的是：hadoop3.0之后，默认配置文件中无slaves，以workers替代，设置方式与slaves等同。 启动集群 格式化集群的文件系统 1hadoop namenode -format 启动hadoop集群 1start-all.sh 关闭hadoop集群 1stop-all.sh HDFS的web界面端口：50070 YARN的web界面端口：8088 Spark安装Scala环境 安装包拷贝、解压 将压缩包拷贝至Linux系统中，移动到/usr/software/scala目录下,并解压： 12mv scala-2.12.7.tgz /usr/software/scalatar -zxvf scala-2.12.7.tgz 设置环境变量 1234vim /etc/profileexport SCALA_HOME=/usr/software/scala/scala-2.12.7export PATH=$PATH:$SCALA_HOME/bin Esc[:wq]保存后，执行以下命令让其当即生效： 1source /etc/profile 输入： 12345678scala出现以下信息则表明hadoop安装成功：Welcome to Scala 2.12.7 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_191).Type in expressions for evaluation. Or try :help.scala&gt; Spark集群 安装包拷贝、解压 将压缩包拷贝至Linux系统中，移动到/usr/software/spark目录下,并解压： 12mv spark-2.3.2-bin-hadoop2.7.tgz /usr/software/sparktar -zxvf spark-2.3.2-bin-hadoop2.7.tgz 设置环境变量 1234vim /etc/profileexport SPARK_HOME=/usr/software/spark/spark-2.3.2-bin-hadoop2.7export PATH=$PATH:$SPARK_HOME/bin Esc[:wq]保存后，执行以下命令让其当即生效： 1source /etc/profile 配置spark参数 12345678910111213141516cd /usr/software/spark/spark-2.3.2-bin-hadoop2.7/conf/cp spark-env.sh.template spark-env.shvim spark-env.sh添加如下内容：export JAVA_HOME=/usr/software/java/jdk1.8.0_191export SCALA_HOME=/usr/software/scala/scala-2.12.7export SPARK_MASTER_IP=xxx.xxx.xxx.xxxexport SPARK_WORKER_MEMORY=8gexport HADOOP_CONF_DIR=/usr/software/hadoop/hadoop-3.0.3/etc/hadoopvim slavesslave1slave2slave3 spark集群启动1234cd /usr/software/spark/spark-2.3.2-bin-hadoop2.7/sbin/./start-all.sh注意：spark和hadoop的启动脚本名称是相同的，又因为hadoop已经将sbin目录配置进Path环境变量中去了，所以启动spark时，需要进入spark的sbin目录。 web界面端口：8080 Zookeeper集群本教程中，我们使用slave1,slave2,slave3三台机器搭建zookeeper集群。 首先在slave1上进行相关安装，然后将配置好的目录复制到其他机器上(slave2, slave3)即可。 安装包拷贝、解压 将压缩包拷贝至Linux系统中，移动到/usr/software/zookeeper目录下,并解压： 12mv zookeeper-3.4.10.tar.gz /usr/software/zookeepertar -zxvf zookeeper-3.4.10.tar.gz 配置文件修改 12345678910111213cd /usr/software/zookeeper/zookeeper-3.4.10/confcp ./zoo_sample.cfg ./zoo.cfgvim zoo.cfgtickTime=2000initLimit=10syncLimit=5dataDir=/usr/software/zookeeper/zookeeper-3.4.10/data # 修改存放zookeeper数据的目录clientPort=2181# 添加3个节点的信息server.1=slave1:2888:3888server.2=slave2:2888:3888server.3=slave3:2888:3888 配置参数说明 tickTime：zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔,也就是说每个tickTime时间就会发送一个心跳。 initLimit：配置zookeeper接受客户端（这里所说的客户端不是用户连接zookeeper服务器的客户端,而是zookeeper服务器集群中连接到leader的follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。 当已经超过10个心跳的时间（也就是tickTime）长度后 zookeeper 服务器还没有收到客户端的返回信息,那么表明这个客户端连接失败。总的时间长度就是 10*2000=20秒。 syncLimit：标识leader与follower之间发送消息,请求和应答时间长度,最长不能超过多少个tickTime的时间长度,总的时间长度就是5*2000=10秒。 dataDir：zookeeper保存数据的目录,默认情况下zookeeper将写数据的日志文件也保存在这个目录里； clientPort：客户端连接Zookeeper服务器的端口,Zookeeper会监听这个端口接受客户端的访问请求； server.A=B:C:D中的A是一个数字,表示这个是第几号服务器,B是这个服务器的IP地址，C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的leader服务器交换信息的端口，D是在leader挂掉时专门用来进行选举leader所用的端口。 创建ServerID标识 除了修改zoo.cfg配置文件外,zookeeper集群模式下还要配置一个myid文件,这个文件需要放在dataDir目录下。 12345/usr/software/zookeeper/zookeeper-3.4.10/datavim myid1[ESC] + wq保存即可 同时在slave2,slave3相同路径下创建myid文件，并分别输入2, 3保存。 集群启动 在每台机器上分别执行以下命令： 12cd /usr/software/zookeeper/zookeeper-3.4.10/bin/./zkServer.sh start 可以输入以下命令查看机器zookeeper的状态： 1234[root@slave1 bin]# ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /usr/software/zookeeper/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: follower 可以看出，当前节点为zookeeper的从节点。 Hbase集群本案例基于4台机器搭建Hbase集群： 安装包拷贝、解压 将压缩包拷贝至Linux系统中，移动到/usr/software/hbase目录下,并解压： 12mv hbase-1.2.8-bin.tar.gz /usr/software/hbasetar -zxvf hbase-1.2.8-bin.tar.gz hbase-site.xml 1234567891011121314151617181920212223242526272829303132333435cd /usr/software/hbase/hbase-1.2.8/confvim hbase-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.master&lt;/name&gt; &lt;value&gt;master:60000&lt;/value&gt; &lt;description&gt;hbase的主节点与端口号&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master.maxclockskew&lt;/name&gt; &lt;value&gt;180000&lt;/value&gt; &lt;description&gt;时间同步允许的时间差&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;description&gt;hbase共享目录，持久化hbase数据&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;是否为分布式&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;slave1,slave2,slave3&lt;/value&gt; &lt;description&gt;指定zookeeper&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;description&gt;备份数&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; regionservers 123456cd /usr/software/hbase/hbase-1.2.8/confvim regionservers slave1slave2slave3 将配置好的hbase目录同步到另外3台机器。 启动hbase 12cd /usr/software/hbase/hbase-1.2.8/bin./start-hbase.sh 启动后，在master节点jps看到HMaster进程，slave节点多出HRegionServer进程。 Hbase的Web管理界面：16010 Kafka集群本案例基于4台机器搭建Kafka集群： 安装包拷贝、解压 将压缩包拷贝至Linux系统中，移动到/usr/software/kafka目录下,并解压： 12mv kafka_2.12-2.0.1.tgz /usr/software/kafkatar -zxvf kafka_2.12-2.0.1.tgz 修改配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465cd /usr/software/kafka/kafka_2.12-2.0.1/configvim vim server.properties broker.id=0listeners=PLAINTEXT://master:9092# The number of threads that the server uses for receiving requests from the network and sending responses to the networknum.network.threads=3# The number of threads that the server uses for processing requests, which may include disk I/Onum.io.threads=8# The send buffer (SO_SNDBUF) used by the socket serversocket.send.buffer.bytes=102400# The receive buffer (SO_RCVBUF) used by the socket serversocket.receive.buffer.bytes=102400# The maximum size of a request that the socket server will accept (protection against OOM)socket.request.max.bytes=104857600############################# Log Basics ############################## A comma separated list of directories under which to store log fileslog.dirs=/usr/software/kafka/kafka_2.12-2.0.1/logs# The default number of log partitions per topic. More partitions allow greater# parallelism for consumption, but this will also result in more files across# the brokers.num.partitions=1# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.# This value is recommended to be increased for installations with data dirs located in RAID array.num.recovery.threads.per.data.dir=1############################# Internal Topic Settings ############################## The replication factor for the group metadata internal topics &quot;__consumer_offsets&quot; and &quot;__transaction_state&quot;# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1# The minimum age of a log file to be eligible for deletion due to agelog.retention.hours=168sage.max.byte=5242880 # 消息保存的最大值5Mdefault.replication.factor=3 # kafka保存消息的副本数，如果一个副本失效了，另两个还可以继续提供服务replica.fetch.max.bytes=5242880 # 取消息的最大直接数# A size-based retention policy for logs. Segments are pruned from the log unless the remaining# segments drop below log.retention.bytes. Functions independently of log.retention.hours.#log.retention.bytes=1073741824# The maximum size of a log segment file. When this size is reached a new log segment will be created.log.segment.bytes=1073741824# The interval at which log segments are checked to see if they can be deleted according# to the retention policieslog.retention.check.interval.ms=300000############################# Zookeeper ############################## Zookeeper connection string (see zookeeper docs for details).# This is a comma separated host:port pairs, each corresponding to a zk# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.# You can also append an optional chroot string to the urls to specify the# root directory for all kafka znodes.zookeeper.connect=slave1:2181,slave2:2181,slave3:2181# Timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000############################# Group Coordinator Settings ############################## The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.# The default value for this is 3 seconds.# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.group.initial.rebalance.delay.ms=0# 主要修改broker.id，log.dirs，zookeeper.connect 将配置好的hbase目录同步到另外3台机器，并修改配置文件中的broker.id。 启动 12/usr/software/kafka/kafka_2.12-2.0.1/bin./kafka-server-start.sh -daemon ../config/server.properties kafka manager安装 安装详情 kafka manager安装时默认的Web端口为9000,与hadoop的RPC端口冲突，故启动时需要指定另外一个端口号，如： 1bin/kafka-manager -Dhttp.port=9002 欢迎您扫一扫上面的二维码，关注我的微信公众号！]]></content>
      <categories>
        <category>Bigdata</category>
      </categories>
      <tags>
        <tag>Bigdata</tag>
        <tag>环境搭建</tag>
      </tags>
  </entry>
</search>
